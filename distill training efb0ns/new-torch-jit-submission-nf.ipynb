{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1e4786",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-02T13:39:02.448192Z",
     "iopub.status.busy": "2024-05-02T13:39:02.447439Z",
     "iopub.status.idle": "2024-05-02T13:39:12.870508Z",
     "shell.execute_reply": "2024-05-02T13:39:12.869411Z"
    },
    "papermill": {
     "duration": 10.43239,
     "end_time": "2024-05-02T13:39:12.873431",
     "exception": false,
     "start_time": "2024-05-02T13:39:02.441041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torchdata\n",
    "from torchaudio.transforms import AmplitudeToDB, MelSpectrogram\n",
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "import concurrent.futures\n",
    "import shutil\n",
    "import albumentations as A\n",
    "import torchaudio\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "864f398e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:39:12.883751Z",
     "iopub.status.busy": "2024-05-02T13:39:12.883121Z",
     "iopub.status.idle": "2024-05-02T13:39:12.907792Z",
     "shell.execute_reply": "2024-05-02T13:39:12.906371Z"
    },
    "papermill": {
     "duration": 0.032688,
     "end_time": "2024-05-02T13:39:12.910502",
     "exception": false,
     "start_time": "2024-05-02T13:39:12.877814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../input/birdclef-2024/sample_submission.csv\")\n",
    "target_columns_ = sub.columns.tolist()\n",
    "target_columns = sub.columns.tolist()[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51bb4bcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:39:12.920212Z",
     "iopub.status.busy": "2024-05-02T13:39:12.919816Z",
     "iopub.status.idle": "2024-05-02T13:39:12.928713Z",
     "shell.execute_reply": "2024-05-02T13:39:12.927659Z"
    },
    "papermill": {
     "duration": 0.016904,
     "end_time": "2024-05-02T13:39:12.931476",
     "exception": false,
     "start_time": "2024-05-02T13:39:12.914572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOTAL_SECONDS_CHUNKS = 48\n",
    "test_path = \"/home/simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/birdclef-2024/test_soundscapes/\"\n",
    "files = glob.glob(f'{test_path}*')\n",
    "if len(files) == 1:\n",
    "    TOTAL_SECONDS_CHUNKS = 2\n",
    "\n",
    "seconds = [i for i in range(5, (TOTAL_SECONDS_CHUNKS*5) + 5, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30f3ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/home/simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3e3acd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:39:12.941586Z",
     "iopub.status.busy": "2024-05-02T13:39:12.940939Z",
     "iopub.status.idle": "2024-05-02T13:39:12.966132Z",
     "shell.execute_reply": "2024-05-02T13:39:12.964932Z"
    },
    "papermill": {
     "duration": 0.033367,
     "end_time": "2024-05-02T13:39:12.969097",
     "exception": false,
     "start_time": "2024-05-02T13:39:12.935730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/simon/Code/kaggle_competion_list/Birdclef/birdclef-2024//working/\n"
     ]
    }
   ],
   "source": [
    "test_path = f\"{ROOT}/input/birdclef-2024/test_soundscapes/\"\n",
    "\n",
    "files = glob.glob(f'{test_path}*')\n",
    "if len(files) == 1:\n",
    "    shutil.copy(f'{ROOT}/input/birdclef-2024/train_audio/redspu1/XC312771.ogg', f'{ROOT}/working/soundscape_1446779.ogg')\n",
    "    shutil.copy(f'{ROOT}/input/birdclef-2024/train_audio/redspu1/XC312771.ogg', f'{ROOT}/working/soundscape_1442779.ogg')\n",
    "    shutil.copy(f'{ROOT}/input/birdclef-2024/train_audio/redspu1/XC312771.ogg', f'{ROOT}/working/soundscape_1446779.ogg')\n",
    "    shutil.copy(f'{ROOT}/input/birdclef-2024/train_audio/redspu1/XC312771.ogg', f'{ROOT}/working/soundscape_1446379.ogg')\n",
    "    shutil.copy(f'{ROOT}/input/birdclef-2024/train_audio/redspu1/XC312771.ogg', f'{ROOT}/working/soundscape_1146779.ogg')\n",
    "    shutil.copy(f'{ROOT}/input/birdclef-2024/train_audio/redspu1/XC312771.ogg', f'{ROOT}/working/soundscape_1426779.ogg')\n",
    "    shutil.copy(f'{ROOT}/input/birdclef-2024/train_audio/redspu1/XC312771.ogg', f'{ROOT}/working/soundscape_1441779.ogg')\n",
    "    shutil.copy(f'{ROOT}/input/birdclef-2024/train_audio/redspu1/XC312771.ogg', f'{ROOT}/working/soundscape_1446179.ogg')\n",
    "    shutil.copy(f'{ROOT}/input/birdclef-2024/train_audio/redspu1/XC312771.ogg', f'{ROOT}/working/soundscape_1446719.ogg')\n",
    "    shutil.copy(f'{ROOT}/input/birdclef-2024/train_audio/redspu1/XC312771.ogg', f'{ROOT}/working/soundscape_1446771.ogg')\n",
    "    shutil.copy(f'{ROOT}/input/birdclef-2024/train_audio/redspu1/XC312771.ogg', f'{ROOT}/working/soundscape_1446789.ogg')\n",
    "    shutil.copy(f'{ROOT}/input/birdclef-2024/train_audio/redspu1/XC312771.ogg', f'{ROOT}/working/soundscape_1448779.ogg')\n",
    "    test_path = f\"{ROOT}/working/\"\n",
    "    \n",
    "print (test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cba9eca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:39:12.980112Z",
     "iopub.status.busy": "2024-05-02T13:39:12.979114Z",
     "iopub.status.idle": "2024-05-02T13:39:12.985692Z",
     "shell.execute_reply": "2024-05-02T13:39:12.984757Z"
    },
    "papermill": {
     "duration": 0.014537,
     "end_time": "2024-05-02T13:39:12.988046",
     "exception": false,
     "start_time": "2024-05-02T13:39:12.973509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mel_spec_params = {\n",
    "    \"sample_rate\": 32000,\n",
    "    \"n_mels\": 128,\n",
    "    \"f_min\": 20,\n",
    "    \"f_max\": 16000,\n",
    "    \"n_fft\": 2048,\n",
    "    \"hop_length\": 512,\n",
    "    \"normalized\": True,\n",
    "    \"center\" : True,\n",
    "    \"pad_mode\" : \"constant\",\n",
    "    \"norm\" : \"slaney\",\n",
    "    \"onesided\" : True,\n",
    "    \"mel_scale\" : \"slaney\"\n",
    "}\n",
    "top_db = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f8fd912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:39:12.998685Z",
     "iopub.status.busy": "2024-05-02T13:39:12.998264Z",
     "iopub.status.idle": "2024-05-02T13:39:13.006472Z",
     "shell.execute_reply": "2024-05-02T13:39:13.005232Z"
    },
    "papermill": {
     "duration": 0.016218,
     "end_time": "2024-05-02T13:39:13.008667",
     "exception": false,
     "start_time": "2024-05-02T13:39:12.992449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_melspec(X, eps=1e-6):\n",
    "    mean = X.mean((1, 2), keepdim=True)\n",
    "    std = X.std((1, 2), keepdim=True)\n",
    "    Xstd = (X - mean) / (std + eps)\n",
    "\n",
    "    norm_min, norm_max = (\n",
    "        Xstd.min(-1)[0].min(-1)[0],\n",
    "        Xstd.max(-1)[0].max(-1)[0],\n",
    "    )\n",
    "    fix_ind = (norm_max - norm_min) > eps * torch.ones_like(\n",
    "        (norm_max - norm_min)\n",
    "    )\n",
    "    V = torch.zeros_like(Xstd)\n",
    "    if fix_ind.sum():\n",
    "        V_fix = Xstd[fix_ind]\n",
    "        norm_max_fix = norm_max[fix_ind, None, None]\n",
    "        norm_min_fix = norm_min[fix_ind, None, None]\n",
    "        V_fix = torch.max(\n",
    "            torch.min(V_fix, norm_max_fix),\n",
    "            norm_min_fix,\n",
    "        )\n",
    "        V_fix = (V_fix - norm_min_fix) / (norm_max_fix - norm_min_fix)\n",
    "        V[fix_ind] = V_fix\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8d9742c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:39:13.019008Z",
     "iopub.status.busy": "2024-05-02T13:39:13.018638Z",
     "iopub.status.idle": "2024-05-02T13:39:13.023491Z",
     "shell.execute_reply": "2024-05-02T13:39:13.022471Z"
    },
    "papermill": {
     "duration": 0.012543,
     "end_time": "2024-05-02T13:39:13.025440",
     "exception": false,
     "start_time": "2024-05-02T13:39:13.012897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms_val = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77388e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:39:13.036094Z",
     "iopub.status.busy": "2024-05-02T13:39:13.034887Z",
     "iopub.status.idle": "2024-05-02T13:39:13.044908Z",
     "shell.execute_reply": "2024-05-02T13:39:13.044004Z"
    },
    "papermill": {
     "duration": 0.017748,
     "end_time": "2024-05-02T13:39:13.047394",
     "exception": false,
     "start_time": "2024-05-02T13:39:13.029646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(torchdata.Dataset):\n",
    "    def __init__(self, \n",
    "                 df: pd.DataFrame, \n",
    "                 clip: np.ndarray,\n",
    "                ):\n",
    "        \n",
    "        self.df = df\n",
    "        self.clip = clip\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(**mel_spec_params)\n",
    "        self.db_transform = torchaudio.transforms.AmplitudeToDB(stype='power', top_db=top_db)\n",
    "        self.transform = transforms_val\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "\n",
    "        sample = self.df.loc[idx, :]\n",
    "        row_id = sample.row_id\n",
    "\n",
    "        end_seconds = int(sample.seconds)\n",
    "        start_seconds = int(end_seconds - 5)\n",
    "        \n",
    "        wave = self.clip[:, 32000 * start_seconds : 32000 * end_seconds]\n",
    "        \n",
    "        mel_spectrogram = normalize_melspec(self.db_transform(self.mel_transform(wave)))\n",
    "        mel_spectrogram = mel_spectrogram * 255\n",
    "        mel_spectrogram = mel_spectrogram.expand(3, -1, -1).permute(1, 2, 0).numpy()\n",
    "        \n",
    "        res = self.transform(image=mel_spectrogram)\n",
    "        spec = res['image'].astype(np.float32)\n",
    "        spec = spec.transpose(2, 0, 1)\n",
    "        \n",
    "        return {\n",
    "            \"row_id\": row_id,\n",
    "            \"wave\": spec,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc3819ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:39:13.057636Z",
     "iopub.status.busy": "2024-05-02T13:39:13.057237Z",
     "iopub.status.idle": "2024-05-02T13:39:13.068148Z",
     "shell.execute_reply": "2024-05-02T13:39:13.067109Z"
    },
    "papermill": {
     "duration": 0.018917,
     "end_time": "2024-05-02T13:39:13.070633",
     "exception": false,
     "start_time": "2024-05-02T13:39:13.051716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction_for_clip(audio_path):\n",
    "    \n",
    "    prediction_dict = {}\n",
    "    \n",
    "    wav, org_sr = torchaudio.load(audio_path, normalize=True)\n",
    "    clip = torchaudio.functional.resample(wav, orig_freq=org_sr, new_freq=32000)\n",
    "    \n",
    "    name_ = audio_path.split(\".ogg\")[0].split(\"/\")[-1]\n",
    "    row_ids = [name_+f\"_{second}\" for second in seconds]\n",
    "\n",
    "    test_df = pd.DataFrame({\n",
    "        \"row_id\": row_ids,\n",
    "        \"seconds\": seconds,\n",
    "    })\n",
    "    \n",
    "    dataset = TestDataset(\n",
    "        df=test_df, \n",
    "        clip=clip,\n",
    "    )\n",
    "        \n",
    "    loader = torchdata.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=4, \n",
    "        num_workers=os.cpu_count(),\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    for inputs in loader:\n",
    "\n",
    "        row_ids = inputs['row_id']\n",
    "        inputs.pop('row_id')\n",
    "\n",
    "        for row_id in row_ids:\n",
    "            if row_id not in prediction_dict:\n",
    "                prediction_dict[str(row_id)] = []\n",
    "\n",
    "        probas = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs[\"wave\"])\n",
    "\n",
    "        for row_id_idx, row_id in enumerate(row_ids):\n",
    "            prediction_dict[str(row_id)].append(output[row_id_idx, :].sigmoid().detach().numpy())\n",
    "                                                        \n",
    "    for row_id in list(prediction_dict.keys()):\n",
    "        logits = prediction_dict[row_id]\n",
    "        logits = np.array(logits)[0]#.mean(0)\n",
    "        prediction_dict[row_id] = {}\n",
    "        for label in range(len(target_columns)):\n",
    "            prediction_dict[row_id][target_columns[label]] = logits[label]\n",
    "\n",
    "    return prediction_dict"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8068726,
     "sourceId": 70203,
     "sourceType": "competition"
    },
    {
     "datasetId": 4841380,
     "sourceId": 8290527,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 175271735,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.647027,
   "end_time": "2024-05-02T13:39:21.450786",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-02T13:38:59.803759",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
