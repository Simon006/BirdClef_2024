{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import importlib\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "import audiomentations as AA\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torchdata\n",
    "import torch_audiomentations as TAA\n",
    "import albumentations\n",
    "\n",
    "from sklearn import metrics\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.distributions import Beta\n",
    "from torchaudio.transforms import AmplitudeToDB, MelSpectrogram\n",
    "from tqdm import tqdm\n",
    "from utils import AverageMeter\n",
    "\n",
    "sys.path.append('../configs')\n",
    "sys.path.append('./samplers')\n",
    "sys.path.append('./pcen')\n",
    "from pcen import StreamingPCENTransform\n",
    "# from sampler import MultilabelBalancedRandomSampler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "TRAIN_DATA_PATH = '../dataset/birdclef-2024/'\n",
    "\n",
    "torch.set_flush_denormal(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'asbfly': 0, 'ashdro1': 1, 'ashpri1': 2, 'ashwoo2': 3, 'asikoe2': 4, 'asiope1': 5, 'aspfly1': 6, 'aspswi1': 7, 'barfly1': 8, 'barswa': 9, 'bcnher': 10, 'bkcbul1': 11, 'bkrfla1': 12, 'bkskit1': 13, 'bkwsti': 14, 'bladro1': 15, 'blaeag1': 16, 'blakit1': 17, 'blhori1': 18, 'blnmon1': 19, 'blrwar1': 20, 'bncwoo3': 21, 'brakit1': 22, 'brasta1': 23, 'brcful1': 24, 'brfowl1': 25, 'brnhao1': 26, 'brnshr': 27, 'brodro1': 28, 'brwjac1': 29, 'brwowl1': 30, 'btbeat1': 31, 'bwfshr1': 32, 'categr': 33, 'chbeat1': 34, 'cohcuc1': 35, 'comfla1': 36, 'comgre': 37, 'comior1': 38, 'comkin1': 39, 'commoo3': 40, 'commyn': 41, 'compea': 42, 'comros': 43, 'comsan': 44, 'comtai1': 45, 'copbar1': 46, 'crbsun2': 47, 'cregos1': 48, 'crfbar1': 49, 'crseag1': 50, 'dafbab1': 51, 'darter2': 52, 'eaywag1': 53, 'emedov2': 54, 'eucdov': 55, 'eurbla2': 56, 'eurcoo': 57, 'forwag1': 58, 'gargan': 59, 'gloibi': 60, 'goflea1': 61, 'graher1': 62, 'grbeat1': 63, 'grecou1': 64, 'greegr': 65, 'grefla1': 66, 'grehor1': 67, 'grejun2': 68, 'grenig1': 69, 'grewar3': 70, 'grnsan': 71, 'grnwar1': 72, 'grtdro1': 73, 'gryfra': 74, 'grynig2': 75, 'grywag': 76, 'gybpri1': 77, 'gyhcaf1': 78, 'heswoo1': 79, 'hoopoe': 80, 'houcro1': 81, 'houspa': 82, 'inbrob1': 83, 'indpit1': 84, 'indrob1': 85, 'indrol2': 86, 'indtit1': 87, 'ingori1': 88, 'inpher1': 89, 'insbab1': 90, 'insowl1': 91, 'integr': 92, 'isbduc1': 93, 'jerbus2': 94, 'junbab2': 95, 'junmyn1': 96, 'junowl1': 97, 'kenplo1': 98, 'kerlau2': 99, 'labcro1': 100, 'laudov1': 101, 'lblwar1': 102, 'lesyel1': 103, 'lewduc1': 104, 'lirplo': 105, 'litegr': 106, 'litgre1': 107, 'litspi1': 108, 'litswi1': 109, 'lobsun2': 110, 'maghor2': 111, 'malpar1': 112, 'maltro1': 113, 'malwoo1': 114, 'marsan': 115, 'mawthr1': 116, 'moipig1': 117, 'nilfly2': 118, 'niwpig1': 119, 'nutman': 120, 'orihob2': 121, 'oripip1': 122, 'pabflo1': 123, 'paisto1': 124, 'piebus1': 125, 'piekin1': 126, 'placuc3': 127, 'plaflo1': 128, 'plapri1': 129, 'plhpar1': 130, 'pomgrp2': 131, 'purher1': 132, 'pursun3': 133, 'pursun4': 134, 'purswa3': 135, 'putbab1': 136, 'redspu1': 137, 'rerswa1': 138, 'revbul': 139, 'rewbul': 140, 'rewlap1': 141, 'rocpig': 142, 'rorpar': 143, 'rossta2': 144, 'rufbab3': 145, 'ruftre2': 146, 'rufwoo2': 147, 'rutfly6': 148, 'sbeowl1': 149, 'scamin3': 150, 'shikra1': 151, 'smamin1': 152, 'sohmyn1': 153, 'spepic1': 154, 'spodov': 155, 'spoowl1': 156, 'sqtbul1': 157, 'stbkin1': 158, 'sttwoo1': 159, 'thbwar1': 160, 'tibfly3': 161, 'tilwar1': 162, 'vefnut1': 163, 'vehpar1': 164, 'wbbfly1': 165, 'wemhar1': 166, 'whbbul2': 167, 'whbsho3': 168, 'whbtre1': 169, 'whbwag1': 170, 'whbwat1': 171, 'whbwoo2': 172, 'whcbar1': 173, 'whiter2': 174, 'whrmun': 175, 'whtkin2': 176, 'woosan': 177, 'wynlau1': 178, 'yebbab1': 179, 'yebbul3': 180, 'zitcis1': 181}\n"
     ]
    }
   ],
   "source": [
    "ROOT = \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input\"\n",
    "sub = pd.read_csv(f\"{ROOT}/birdclef-2024/sample_submission.csv\")\n",
    "target_columns = sub.columns.tolist()[1:]\n",
    "num_classes = len(target_columns)\n",
    "bird2id = {b: i for i, b in enumerate(target_columns)}\n",
    "print(bird2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/issamemari/pytorch-multilabel-balanced-sampler/blob/master/sampler.py\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "\n",
    "class MultilabelBalancedRandomSampler(Sampler):\n",
    "    \"\"\"\n",
    "    MultilabelBalancedRandomSampler: Given a multilabel dataset of length n_samples and\n",
    "    number of classes n_classes, samples from the data with equal probability per class\n",
    "    effectively oversampling minority classes and undersampling majority classes at the\n",
    "    same time. Note that using this sampler does not guarantee that the distribution of\n",
    "    classes in the output samples will be uniform, since the dataset is multilabel and\n",
    "    sampling is based on a single class. This does however guarantee that all classes\n",
    "    will have at least batch_size / n_classes samples as batch_size approaches infinity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, indices=None, class_choice=\"least_sampled\"):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            labels: a multi-hot encoding numpy array of shape (n_samples, n_classes)\n",
    "            indices: an arbitrary-length 1-dimensional numpy array representing a list\n",
    "            of indices to sample only from\n",
    "            class_choice: a string indicating how class will be selected for every\n",
    "            sample:\n",
    "                \"least_sampled\": class with the least number of sampled labels so far\n",
    "                \"random\": class is chosen uniformly at random\n",
    "                \"cycle\": the sampler cycles through the classes sequentially\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "        if self.indices is None:\n",
    "            self.indices = range(len(labels))\n",
    "\n",
    "        self.num_classes = self.labels.shape[1]\n",
    "\n",
    "        # List of lists of example indices per class\n",
    "        self.class_indices = []\n",
    "        for class_ in range(self.num_classes):\n",
    "            lst = np.where(self.labels[:, class_] == 1)[0]\n",
    "            lst = lst[np.isin(lst, self.indices)]\n",
    "            self.class_indices.append(lst)\n",
    "\n",
    "        self.counts = [0] * self.num_classes\n",
    "\n",
    "        assert class_choice in [\"least_sampled\", \"random\", \"cycle\"]\n",
    "        self.class_choice = class_choice\n",
    "        self.current_class = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.count >= len(self.indices):\n",
    "            raise StopIteration\n",
    "        self.count += 1\n",
    "        return self.sample()\n",
    "\n",
    "    def sample(self):\n",
    "        class_ = self.get_class()\n",
    "        class_indices = self.class_indices[class_]\n",
    "        chosen_index = np.random.choice(class_indices)\n",
    "        if self.class_choice == \"least_sampled\":\n",
    "            for class_, indicator in enumerate(self.labels[chosen_index]):\n",
    "                if indicator == 1:\n",
    "                    self.counts[class_] += 1\n",
    "        return chosen_index\n",
    "\n",
    "    def get_class(self):\n",
    "        if self.class_choice == \"random\":\n",
    "            class_ = random.randint(0, self.labels.shape[1] - 1)\n",
    "        elif self.class_choice == \"cycle\":\n",
    "            class_ = self.current_class\n",
    "            self.current_class = (self.current_class + 1) % self.labels.shape[1]\n",
    "        elif self.class_choice == \"least_sampled\":\n",
    "            min_count = self.counts[0]\n",
    "            min_classes = [0]\n",
    "            for class_ in range(1, self.num_classes):\n",
    "                if self.counts[class_] < min_count:\n",
    "                    min_count = self.counts[class_]\n",
    "                    min_classes = [class_]\n",
    "                if self.counts[class_] == min_count:\n",
    "                    min_classes.append(class_)\n",
    "            class_ = np.random.choice(min_classes)\n",
    "        return class_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy  \n",
    "import importlib.util  \n",
    "import os  \n",
    "  \n",
    "# 假设你的配置文件是一个 Python 模块，并且它位于某个固定的路径下  \n",
    "# 例如，配置文件名为 'config.py'，它位于与当前脚本相同的目录下  \n",
    "CONFIG_FILE_NAME = 'exp071.py'  # 配置文件名  \n",
    "CONFIG_MODULE_NAME = CONFIG_FILE_NAME.replace('.py', '')  # 转换为模块名  \n",
    "  \n",
    "# 获取当前脚本的目录（如果是从脚本运行的话）  \n",
    "# 注意：如果是从模块导入的，这个可能不是你想要的目录  \n",
    "CURRENT_DIR = \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main-20240518T060118Z-001/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main/configs\"\n",
    "CONFIG_FILE_PATH = os.path.join(CURRENT_DIR, CONFIG_FILE_NAME)  \n",
    "  \n",
    "# 检查配置文件是否存在  \n",
    "if not os.path.exists(CONFIG_FILE_PATH):  \n",
    "    raise FileNotFoundError(f\"Configuration file {CONFIG_FILE_PATH} not found.\")  \n",
    "  \n",
    "# 使用importlib导入配置文件模块  \n",
    "spec = importlib.util.spec_from_file_location(CONFIG_MODULE_NAME, CONFIG_FILE_PATH)  \n",
    "config_module = importlib.util.module_from_spec(spec)  \n",
    "spec.loader.exec_module(config_module)  \n",
    "  \n",
    "# 假设你的配置文件模块中有一个名为 'cfg' 的变量或属性  \n",
    "CFG = copy.deepcopy(getattr(config_module, 'cfg', None))  \n",
    "if CFG is None:  \n",
    "    raise AttributeError(f\"Module {CONFIG_MODULE_NAME} does not have an attribute 'cfg'.\")  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description=\"\")\n",
    "# parser.add_argument(\"-C\", \"--config\", help=\"config filename\")\n",
    "# parser_args, _ = parser.parse_known_args(sys.argv)\n",
    "# CFG = copy(importlib.import_module(parser_args.config).cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def init_logger(log_file='train.log'):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def load_wave_and_crop(filename, period, start=None):\n",
    "\n",
    "    waveform_orig, sample_rate = librosa.load(filename, sr=32000, mono=False)\n",
    "\n",
    "    wave_len = len(waveform_orig)\n",
    "    waveform = np.concatenate([waveform_orig, waveform_orig, waveform_orig])\n",
    "\n",
    "    effective_length = sample_rate * period\n",
    "    while len(waveform) < (period * sample_rate * 3):\n",
    "        waveform = np.concatenate([waveform, waveform_orig])\n",
    "    if start is not None:\n",
    "        start = start - (period - 5) / 2 * sample_rate\n",
    "        while start < 0:\n",
    "            start += wave_len\n",
    "        start = int(start)\n",
    "    else:\n",
    "        if wave_len < effective_length:\n",
    "            start = np.random.randint(effective_length - wave_len)\n",
    "        elif wave_len > effective_length:\n",
    "            start = np.random.randint(wave_len - effective_length)\n",
    "        elif wave_len == effective_length:\n",
    "            start = 0\n",
    "\n",
    "    waveform_seg = waveform[start: start + int(effective_length)]\n",
    "\n",
    "    return waveform_orig, waveform_seg, sample_rate, start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.transforms import v2 as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for wave trasnform 1d  (160000,)\n",
    "tr_transforms = albumentations.Compose(\n",
    "    [\n",
    "    #    albumentations.OneOf([\n",
    "    #         AA.Gain(min_gain_in_db=-15, max_gain_in_db=15, p=1.0),\n",
    "    #         AA.GainTransition(\n",
    "    #             min_gain_in_db=-24.0,\n",
    "    #             max_gain_in_db=6.0,\n",
    "    #             min_duration=0.2,\n",
    "    #             max_duration=6.0,\n",
    "    #             p=1.0\n",
    "    #         )\n",
    "    #     ], p=0.5,),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.CoarseDropout(max_height=int(128 * 0.375), max_width=int(128 * 0.375), max_holes=1, p=0.7),\n",
    "        # albumentations.XYMasking(\n",
    "        #         p=0.3,\n",
    "        #         num_masks_x=(1, 3),\n",
    "        #         num_masks_y=(1, 3),\n",
    "        #         mask_x_length=(1, 10),\n",
    "        #         mask_y_length=(1, 20),\n",
    "        #     ) ,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# alb_transform = [\n",
    "#         ### num_masks_x=1, num_masks_y=1 will change\n",
    "#         albumentations.XYMasking(num_masks_x=2, num_masks_y=1, \n",
    "#                                  mask_x_length=20, mask_y_length=4,\n",
    "#                                  fill_value=0, mask_fill_value=0, p=CFG.aug_spec_xymasking),\n",
    "#         albumentations.CoarseDropout(fill_value=0, min_holes=20, max_holes=50, p=CFG.aug_spec_coarsedrop),\n",
    "#         albumentations.HorizontalFlip(p=CFG.aug_spec_hflip),\n",
    "#         # albumentations.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ]\n",
    "# tr_transforms = albumentations.Compose(alb_transform)\n",
    "\n",
    "# va_transform = AA.Compose(\n",
    "#     # albumentations.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),1\n",
    "# )\n",
    "\n",
    "\n",
    "taa_augmentation = TAA.Compose(\n",
    "    transforms=[\n",
    "        TAA.PitchShift(\n",
    "            sample_rate=CFG.sample_rate,\n",
    "            mode=\"per_example\",\n",
    "            p=0.2,\n",
    "            ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BirdClef2023Dataset(torchdata.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str = 'DATA_PATH',\n",
    "        period: float = 5.0,\n",
    "        secondary_coef: float = 1.0,\n",
    "        smooth_label: float = 0.05,\n",
    "        df: pd.DataFrame = 'DATAFRAME',\n",
    "        train: bool = True,\n",
    "    ):\n",
    "\n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.filenames = df[\"filename\"]\n",
    "\n",
    "        self.primary_label = df[\"primary_label\"]\n",
    "        self.secondary_labels = (\n",
    "            df[\"secondary_labels\"]\n",
    "            .map(\n",
    "                lambda s: s.replace(\"[\", \"\")\n",
    "                .replace(\"]\", \"\")\n",
    "                .replace(\",\", \"\")\n",
    "                .replace(\"'\", \"\")\n",
    "                .split(\" \")\n",
    "            ).values\n",
    "        )\n",
    "\n",
    "        self.secondary_coef = secondary_coef\n",
    "        # self.type = df[\"type\"]\n",
    "        # self.teacher_preds = df[\"teacher_preds\"]\n",
    "        self.rating = df[\"rating\"]\n",
    "        self.period = period\n",
    "        self.smooth_label = smooth_label + 1e-6\n",
    "        self.wave_transforms = tr_transforms\n",
    "        # self.wave_transforms_val = va_transforms\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "   \n",
    "    def normalize(self, x):\n",
    "        valid_values = x[x != float('-inf')]\n",
    "        mean_value = np.mean(valid_values)\n",
    "        x[x == float('-inf')] = mean_value\n",
    "        # x[x == float('-inf')] = 0\n",
    "\n",
    "        x = x - x.min()\n",
    "        x = x / x.max()\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        filename = os.path.join(self.data_path, self.filenames[idx])\n",
    "\n",
    "        if self.train:\n",
    "            waveform, waveform_seg, sample_rate, start = load_wave_and_crop(\n",
    "                filename, self.period ,0                                     # 训练也是前5s\n",
    "            )\n",
    "            # print(f\"1----{waveform_seg.shape=}\")\n",
    "            # for i in range(len(waveform_seg )):\n",
    "            #     waveform_seg[i] = self.normalize(waveform_seg[i])\n",
    "            # print(type(waveform_seg))\n",
    "            # waveform_seg = self.wave_transforms(\n",
    "            #     # image = waveform_seg\n",
    "            #     samples=waveform_seg, sample_rate=sample_rate\n",
    "            #     )\n",
    "            waveform_seg = waveform_seg[np.newaxis,:]\n",
    "            # print(waveform_seg.shape)\n",
    "\n",
    "            res = self.wave_transforms(\n",
    "                image = waveform_seg\n",
    "                # samples=waveform_seg, sample_rate=sample_rate\n",
    "                )\n",
    "            waveform_seg = res['image'].astype(np.float32)\n",
    "            # print(\"2\",type(waveform_seg))\n",
    "            waveform_seg = waveform_seg.flatten()\n",
    "            print(\"2\",waveform_seg.shape)\n",
    "\n",
    "\n",
    "            \n",
    "            # result = self.wave_transforms(image=waveform_seg)  \n",
    "            # waveform_seg = result[\"image\"]\n",
    "            # print(f\"2------{waveform_seg.shape=}\")\n",
    "\n",
    "        else:\n",
    "            waveform, waveform_seg, sample_rate, start = load_wave_and_crop(\n",
    "                filename, self.period, 0\n",
    "            )\n",
    "            # for i in range(len(waveform_seg)):\n",
    "            #     waveform_seg[i] = self.normalize(waveform_seg[i])\n",
    "            # waveform_seg = self.wave_transforms_val(\n",
    "            #     samples=waveform_seg, sample_rate=sample_rate\n",
    "            #     )\n",
    "\n",
    "        waveform_seg = torch.from_numpy(np.nan_to_num(waveform_seg)).float()\n",
    "\n",
    "\n",
    "        rating = self.rating[idx]\n",
    "\n",
    "        # teacher_preds = torch.from_numpy(np.nan_to_num(self.teacher_preds[idx])).float()\n",
    "\n",
    "        target = np.zeros(CFG.num_classes, dtype=np.float32)\n",
    "        if self.primary_label[idx] != 'nocall':\n",
    "            primary_label = CFG.bird2id[self.primary_label[idx]]\n",
    "            target[primary_label] = 1.0\n",
    "\n",
    "            if self.train:\n",
    "                for s in self.secondary_labels[idx]:\n",
    "                    if s != \"\" and s in CFG.bird2id.keys():\n",
    "                        target[CFG.bird2id[s]] = self.secondary_coef\n",
    "\n",
    "        target = torch.from_numpy(target).float()\n",
    "        teacher_preds = target\n",
    "\n",
    "        return {\n",
    "            \"wave\": waveform_seg,\n",
    "            \"rating\": rating,\n",
    "            \"primary_targets\": (target > 0.5).float(),\n",
    "            \"loss_target\": target * (1-self.smooth_label) + self.smooth_label / target.size(-1),\n",
    "            \"teacher_preds\": teacher_preds,\n",
    "        }\n",
    "\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = torch.nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "\n",
    "def gem_freq(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), 1)).pow(1.0 / p)\n",
    "\n",
    "\n",
    "class GeMFreq(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.p = torch.nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem_freq(x, p=self.p, eps=self.eps)\n",
    "\n",
    "\n",
    "class NormalizeMelSpec(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, X):\n",
    "        mean = X.mean((1, 2), keepdim=True)\n",
    "        std = X.std((1, 2), keepdim=True)\n",
    "        Xstd = (X - mean) / (std + self.eps)\n",
    "        norm_min, norm_max = \\\n",
    "            Xstd.min(-1)[0].min(-1)[0], Xstd.max(-1)[0].max(-1)[0]\n",
    "        fix_ind = (norm_max - norm_min) > self.eps * torch.ones_like(\n",
    "            (norm_max - norm_min)\n",
    "        )\n",
    "        V = torch.zeros_like(Xstd)\n",
    "        if fix_ind.sum():\n",
    "            V_fix = Xstd[fix_ind]\n",
    "            norm_max_fix = norm_max[fix_ind, None, None]\n",
    "            norm_min_fix = norm_min[fix_ind, None, None]\n",
    "            V_fix = torch.max(\n",
    "                torch.min(V_fix, norm_max_fix),\n",
    "                norm_min_fix,\n",
    "            )\n",
    "            V_fix = (V_fix - norm_min_fix) / (norm_max_fix - norm_min_fix)\n",
    "            V[fix_ind] = V_fix\n",
    "        return V\n",
    "\n",
    "\n",
    "class Mixup(nn.Module):\n",
    "    def __init__(self, mix_beta):\n",
    "\n",
    "        super(Mixup, self).__init__()\n",
    "        self.beta_distribution = Beta(mix_beta, mix_beta)\n",
    "\n",
    "    def forward(self, X, Y, weight=None, teacher_preds=None):\n",
    "\n",
    "        bs = X.shape[0]\n",
    "        n_dims = len(X.shape)\n",
    "        perm = torch.randperm(bs)\n",
    "        coeffs = self.beta_distribution.rsample(torch.Size((bs,))).to(X.device)\n",
    "\n",
    "        if n_dims == 2:\n",
    "            X = coeffs.view(-1, 1) * X + (1 - coeffs.view(-1, 1)) * X[perm]\n",
    "        elif n_dims == 3:\n",
    "            X = coeffs.view(-1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1)) * X[perm]\n",
    "        else:\n",
    "            X = coeffs.view(-1, 1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1, 1)) * X[perm]\n",
    "\n",
    "        Y = coeffs.view(-1, 1) * Y + (1 - coeffs.view(-1, 1)) * Y[perm]\n",
    "\n",
    "        if weight is None:\n",
    "            return X, Y\n",
    "        else:\n",
    "            weight = coeffs.view(-1) * weight + (1 - coeffs.view(-1)) * weight[perm]\n",
    "            teacher_preds = coeffs.view(-1, 1) * teacher_preds + (1 - coeffs.view(-1, 1)) * teacher_preds[perm]\n",
    "            return X, Y, weight, teacher_preds\n",
    "\n",
    "\n",
    "class AttModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone=\"resnet34\",\n",
    "        num_class=397,\n",
    "        train_period=15.0,\n",
    "        infer_period=5.0,\n",
    "        in_chans=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if CFG.use_pcen:\n",
    "            self.pcen = StreamingPCENTransform(\n",
    "                n_mels=CFG.n_mels,\n",
    "                n_fft=CFG.n_fft,\n",
    "                hop_length=CFG.hop_length,\n",
    "                trainable=True,\n",
    "                use_cuda_kernel=False\n",
    "                )\n",
    "            self.pcen.last_state = torch.zeros([55, 1, 128])\n",
    "        else:\n",
    "            self.logmelspec_extractor = nn.Sequential(\n",
    "                MelSpectrogram(\n",
    "                    sample_rate=CFG.sample_rate,\n",
    "                    n_mels=CFG.n_mels,\n",
    "                    f_min=CFG.fmin,\n",
    "                    f_max=CFG.fmax,\n",
    "                    n_fft=CFG.n_fft,\n",
    "                    hop_length=CFG.hop_length,\n",
    "                    normalized=True,\n",
    "                ),\n",
    "                AmplitudeToDB(top_db=80.0),\n",
    "                NormalizeMelSpec(),\n",
    "            )\n",
    "\n",
    "        base_model = timm.create_model(\n",
    "            backbone,\n",
    "            features_only=False,\n",
    "            pretrained=CFG.use_imagenet_weights,\n",
    "            in_chans=CFG.in_channels,\n",
    "        )\n",
    "\n",
    "        layers = list(base_model.children())[:-2]\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "        if \"efficientnet\" in CFG.backbone:\n",
    "            dense_input = base_model.num_features\n",
    "        elif \"swin\" in CFG.backbone:\n",
    "            dense_input = base_model.num_features\n",
    "        elif hasattr(base_model, \"fc\"):\n",
    "            dense_input = base_model.fc.in_features\n",
    "        else:\n",
    "            dense_input = base_model.feature_info[-1][\"num_chs\"]\n",
    "\n",
    "        self.train_period = train_period\n",
    "        self.infer_period = infer_period\n",
    "\n",
    "        self.factor = int(self.train_period / self.infer_period)\n",
    "        self.mixup = Mixup(mix_beta=1)\n",
    "        self.global_pool = GeM()\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(p) for p in np.linspace(0.1, 0.5, 5)])\n",
    "        self.head = nn.Linear(dense_input, num_class)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        if self.training:\n",
    "            x = input['wave']\n",
    "            bs, time = x.shape\n",
    "            x = x.reshape(bs * self.factor, time // self.factor)\n",
    "            y = input[\"loss_target\"]\n",
    "            weight = input[\"rating\"]\n",
    "            teacher_preds = input[\"teacher_preds\"]\n",
    "        else:\n",
    "            x = input['wave']\n",
    "            y = input[\"loss_target\"]\n",
    "            weight = input[\"rating\"]\n",
    "            teacher_preds = input[\"teacher_preds\"]\n",
    "\n",
    "        if CFG.use_pcen:\n",
    "            x = self.pcen(x).unsqueeze(1)\n",
    "            self.pcen.reset()\n",
    "        else:\n",
    "            x = self.logmelspec_extractor(x)[:, None]\n",
    "\n",
    "        if self.training:\n",
    "            if np.random.random() <= 0.5:\n",
    "                y2 = torch.repeat_interleave(y, self.factor, dim=0)\n",
    "                weight2 = torch.repeat_interleave(weight, self.factor, dim=0)\n",
    "                teacher_preds2 = torch.repeat_interleave(\n",
    "                    teacher_preds, self.factor, dim=0\n",
    "                    )\n",
    "\n",
    "                for i in range(0, x.shape[0], self.factor):\n",
    "                    x[i: i + self.factor], _, _, _ = self.mixup(\n",
    "                        x[i: i + self.factor],\n",
    "                        y2[i: i + self.factor],\n",
    "                        weight2[i: i + self.factor],\n",
    "                        teacher_preds2[i: i + self.factor],\n",
    "                    )\n",
    "\n",
    "            # # aug \n",
    "            # print(f\"1---{x.shape=}\")\n",
    "            # result = tr_transforms(image=x)  \n",
    "            # x= result[\"image\"]\n",
    "\n",
    "\n",
    "            b, c, f, t = x.shape\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            print(f\"2---{x.shape=}\")\n",
    "            x = x.reshape(b // self.factor, self.factor * t, c, f)\n",
    "\n",
    "            if np.random.random() <= CFG.mixup_p:\n",
    "                x, y, weight, teacher_preds = self.mixup(x, y, weight, teacher_preds)\n",
    "\n",
    "            x = x.reshape(b, t, c, f)\n",
    "            x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        if self.training:\n",
    "            b, c, f, t = x.shape\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            x = x.reshape(b // self.factor, self.factor * t, c, f)\n",
    "            x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x[:, :, 0, 0]\n",
    "        logit = sum([self.head(dropout(x)) for dropout in self.dropouts]) / 5\n",
    "\n",
    "        return {\"logit\": logit, \"target\": y, \"rating\": weight, \"teacher_preds\": teacher_preds}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_focal_loss(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    alpha: float = 0.25,\n",
    "    gamma: float = 2,\n",
    "    reduction: str = \"none\",\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
    "\n",
    "    Args:\n",
    "        inputs (Tensor): A float tensor of arbitrary shape.\n",
    "                The predictions for each example.\n",
    "        targets (Tensor): A float tensor with the same shape as inputs. Stores the binary\n",
    "                classification label for each element in inputs\n",
    "                (0 for the negative class and 1 for the positive class).\n",
    "        alpha (float): Weighting factor in range (0,1) to balance\n",
    "                positive vs negative examples or -1 for ignore. Default: ``0.25``.\n",
    "        gamma (float): Exponent of the modulating factor (1 - p_t) to\n",
    "                balance easy vs hard examples. Default: ``2``.\n",
    "        reduction (string): ``'none'`` | ``'mean'`` | ``'sum'``\n",
    "                ``'none'``: No reduction will be applied to the output.\n",
    "                ``'mean'``: The output will be averaged.\n",
    "                ``'sum'``: The output will be summed. Default: ``'none'``.\n",
    "    Returns:\n",
    "        Loss tensor with the reduction option applied.\n",
    "    \"\"\"\n",
    "    # Original implementation from https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/focal_loss.py\n",
    "\n",
    "\n",
    "    p = torch.sigmoid(inputs)\n",
    "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "    p_t = p * targets + (1 - p) * (1 - targets)\n",
    "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
    "\n",
    "    if alpha >= 0:\n",
    "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        loss = alpha_t * loss\n",
    "\n",
    "    # Check reduction option and return loss accordingly\n",
    "    if reduction == \"none\":\n",
    "        pass\n",
    "    elif reduction == \"mean\":\n",
    "        loss = loss.mean()\n",
    "    elif reduction == \"sum\":\n",
    "        loss = loss.sum()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid Value for arg 'reduction': '{reduction} \\n Supported reduction modes: 'none', 'mean', 'sum'\"\n",
    "        )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BCEKDLoss(nn.Module):\n",
    "    def __init__(self, weights=[0.1, 0.9], class_weights=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weights = weights\n",
    "        self.T = 20\n",
    "\n",
    "    def forward(self, output):\n",
    "        input_ = output[\"logit\"]\n",
    "        target = output[\"target\"].float()\n",
    "        rating = output[\"rating\"]\n",
    "        teacher_preds = output[\"teacher_preds\"]\n",
    "\n",
    "        rating = rating.unsqueeze(1).repeat(1, CFG.num_classes)\n",
    "        loss = nn.BCEWithLogitsLoss(\n",
    "            weight=rating,\n",
    "            reduction='mean',\n",
    "        )(input_, target)\n",
    "\n",
    "        KD_loss = nn.KLDivLoss()(\n",
    "            F.log_softmax(input_ / self.T, dim=1),\n",
    "            F.softmax(teacher_preds / self.T, dim=1)\n",
    "            ) * (self.weights[1] * self.T * self.T)\n",
    "\n",
    "        return self.weights[0] * loss + KD_loss\n",
    "\n",
    "\n",
    "class FocalLossBCE(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            alpha: float = 0.25,\n",
    "            gamma: float = 2,\n",
    "            reduction: str = \"mean\",\n",
    "            bce_weight: float = 1.0,\n",
    "            focal_weight: float = 1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.bce = torch.nn.BCEWithLogitsLoss(reduction=reduction)\n",
    "        self.bce_weight = bce_weight\n",
    "        self.focal_weight = focal_weight\n",
    "\n",
    "    # def forward(self, logits, targets):\n",
    "    def forward(self,output):\n",
    "        logits = output[\"logit\"]\n",
    "        targets = output[\"target\"].float()\n",
    "        rating = output[\"rating\"]\n",
    "        teacher_preds = output[\"teacher_preds\"]\n",
    "\n",
    "        focall_loss = sigmoid_focal_loss(\n",
    "            inputs=logits,\n",
    "            targets=targets,\n",
    "            alpha=self.alpha,\n",
    "            gamma=self.gamma,\n",
    "            reduction=self.reduction,\n",
    "        )\n",
    "        bce_loss = self.bce(logits, targets.float())\n",
    "        return self.bce_weight * bce_loss + self.focal_weight * focall_loss\n",
    "\n",
    "\n",
    "\n",
    "def padded_cmap(solution, submission, padding_factor=5):\n",
    "    solution = solution  # .drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission  # .drop(['row_id'], axis=1, errors='ignore')\n",
    "    new_rows = []\n",
    "    for i in range(padding_factor):\n",
    "        new_rows.append([1 for i in range(len(solution.columns))])\n",
    "    new_rows = pd.DataFrame(new_rows)\n",
    "    new_rows.columns = solution.columns\n",
    "    padded_solution = pd.concat(\n",
    "        [solution, new_rows]).reset_index(drop=True).copy()\n",
    "    padded_submission = pd.concat(\n",
    "        [submission, new_rows]).reset_index(drop=True).copy()\n",
    "    score = metrics.average_precision_score(\n",
    "        padded_solution.values,\n",
    "        padded_submission.values,\n",
    "        average='macro',\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def map_score(solution, submission):\n",
    "    solution = solution  # .drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission  # .drop(['row_id'], axis=1, errors='ignore')\n",
    "    score = metrics.average_precision_score(\n",
    "        solution.values,\n",
    "        submission.values,\n",
    "        average='micro',  # 'macro'\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def batch_to_device(batch, device):\n",
    "    batch_dict = {key: batch[key].to(device) for key in batch}\n",
    "    return batch_dict\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    '''\n",
    "    Version of macro-averaged ROC-AUC score that ignores all classes that have no true positive labels.\n",
    "    '''\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "\n",
    "    solution_sums = solution.sum(axis=0)\n",
    "    scored_columns = list(solution_sums[solution_sums > 0].index.values)\n",
    "#     assert len(scored_columns) > 0\n",
    "\n",
    "    return sklearn.metrics.roc_auc_score(solution[scored_columns].values, submission[scored_columns].values, average='macro')\n",
    "\n",
    "def calculate_competition_metrics(gt, preds, target_columns, one_hot=True):\n",
    "    if not one_hot:\n",
    "        ground_truth = np.argmax(gt, axis=1)\n",
    "        gt = np.zeros((ground_truth.size, len(target_columns)))\n",
    "        gt[np.arange(ground_truth.size), ground_truth] = 1\n",
    "    val_df = pd.DataFrame(gt, columns=target_columns)\n",
    "    pred_df = pd.DataFrame(preds, columns=target_columns)\n",
    "    # cmAP_1 = padded_cmap(val_df, pred_df, padding_factor=1)\n",
    "    # cmAP_5 = padded_cmap(val_df, pred_df, padding_factor=5)\n",
    "    val_df['id'] = [f'id_{i}' for i in range(len(val_df))]\n",
    "    pred_df['id'] = [f'id_{i}' for i in range(len(pred_df))]\n",
    "    train_score = score(val_df, pred_df, row_id_column_name='id')\n",
    "    return {\n",
    "    #   \"cmAP_1\": cmAP_1,\n",
    "    #   \"cmAP_5\": cmAP_5,\n",
    "      \"ROC\": train_score,\n",
    "    }\n",
    "\n",
    "def train_fn(data_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    scaler = GradScaler(enabled=CFG.apex)\n",
    "    iters = len(data_loader)\n",
    "    gt = []\n",
    "    preds = []\n",
    "\n",
    "    with tqdm(enumerate(data_loader), total=len(data_loader)) as t:\n",
    "\n",
    "        for i, (data) in t:\n",
    "            inputs = batch_to_device(data, device)\n",
    "            targets = data['primary_targets'].to(device)\n",
    "\n",
    "            inputs['wave'] = taa_augmentation(inputs['wave'].unsqueeze(1))\n",
    "            inputs['wave'] = inputs['wave'].squeeze(1)\n",
    "\n",
    "            with autocast(enabled=CFG.apex):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs)\n",
    "\n",
    "            losses.update(loss.item(), inputs['wave'].size(0))\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), max_norm=CFG.max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scheduler.step(epoch + i / iters)\n",
    "            t.set_postfix(\n",
    "                loss=losses.avg,\n",
    "                grad=grad_norm.item(),\n",
    "                lr=optimizer.param_groups[0][\"lr\"]\n",
    "                )\n",
    "\n",
    "            gt.append(targets.cpu().detach().numpy())\n",
    "            preds.append(outputs[\"logit\"].sigmoid().cpu().detach().numpy())\n",
    "\n",
    "    val_df = pd.DataFrame(\n",
    "        np.concatenate(gt), columns=CFG.target_columns[:182])\n",
    "    pred_df = pd.DataFrame(\n",
    "        np.concatenate(preds), columns=CFG.target_columns[:182])\n",
    "    cmAP_1 = padded_cmap(val_df, pred_df, padding_factor=1)\n",
    "    cmAP_5 = padded_cmap(val_df, pred_df, padding_factor=5)\n",
    "    mAP = map_score(val_df, pred_df)\n",
    "\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "    # print(gt, preds.shape, target_columns)\n",
    "    gt = np.array(gt, dtype=np.int32)\n",
    "    scores = calculate_competition_metrics(gt, preds, target_columns)\n",
    "\n",
    "\n",
    "    return losses.avg, cmAP_1, cmAP_5, mAP, scores\n",
    "\n",
    "\n",
    "import sklearn\n",
    "\n",
    "\n",
    "def valid_fn(data_loader, model, criterion, epoch):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    gt = []\n",
    "    preds = []\n",
    "\n",
    "    with tqdm(enumerate(data_loader), total=len(data_loader)) as t:\n",
    "        for i, (data) in t:\n",
    "            inputs = batch_to_device(data, device)\n",
    "            targets = data['primary_targets'].to(device)\n",
    "\n",
    "            with autocast(enabled=CFG.apex):\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs)\n",
    "\n",
    "            losses.update(loss.item(), inputs['wave'].size(0))\n",
    "            t.set_postfix(loss=losses.avg)\n",
    "\n",
    "            gt.append(targets.cpu().detach().numpy())\n",
    "            preds.append(outputs[\"logit\"].sigmoid().cpu().detach().numpy())\n",
    "\n",
    "    val_df = pd.DataFrame(np.concatenate(gt), columns=CFG.target_columns[:182])\n",
    "    pred_df = pd.DataFrame(np.concatenate(preds), columns=CFG.target_columns[:182])\n",
    "    cmAP_1 = padded_cmap(val_df, pred_df, padding_factor=1)\n",
    "    cmAP_5 = padded_cmap(val_df, pred_df, padding_factor=5)\n",
    "    mAP = map_score(val_df, pred_df)\n",
    "\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    # print(gt, preds.shape, target_columns)\n",
    "    gt = np.array(gt, dtype=np.int32)\n",
    "    scores = calculate_competition_metrics(gt, preds, target_columns)\n",
    "\n",
    "    return losses.avg, cmAP_1, cmAP_5, mAP,scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    criterion,\n",
    "    epochs=10,\n",
    "    fold=None,\n",
    "):\n",
    "\n",
    "    best_score = 0.0\n",
    "    patience = CFG.early_stopping\n",
    "    n_patience = 0\n",
    "\n",
    "    for epoch in range(epochs): \n",
    "        # train for one epoch\n",
    "        train_loss, train_cmAP1, train_cmAP5, train_mAP,train_scores = train_fn(\n",
    "            train_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_loss, val_cmAP1, val_cmAP5, val_mAP,scores = valid_fn(\n",
    "            val_loader, model, criterion, epoch,)\n",
    "        \n",
    "        train_score = train_scores[\"ROC\"]\n",
    "        val_score = scores[\"ROC\"]\n",
    "        logger.info(f\"Epoch {epoch} - Train loss: {train_loss:.4f}, Train cmAP1: {train_cmAP1:.4f}, Train cmAP5: {train_cmAP5:.4f}, Train mAP: {train_mAP:.4f}, \\n Valid loss: {val_loss:.4f}, Valid cmAP1: {val_cmAP1:.4f}, Valid cmAP5: {val_cmAP5:.4f}, Valid mAP: {val_mAP:.4f}\")\n",
    "        logger.info(f\"\\n Epoch {epoch} - train metric {train_score} val metirc {val_score}\")\n",
    "\n",
    "\n",
    "        is_better = val_score > best_score\n",
    "        best_score = max(val_score, best_score)\n",
    "\n",
    "        # Save the best model\n",
    "        if is_better:\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"best_loss\": best_score,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                # \"macro-roc-auc\":scores[\"ROC\"]\n",
    "            }\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch} - Save Best Score: {best_score:.4f} Model\\n\")\n",
    "            torch.save(\n",
    "                state,\n",
    "                os.path.join(CFG.model_output_path, f\"fold_{fold}_model.bin\")\n",
    "                )\n",
    "            \n",
    "            # # 将模型转换为TorchScript\n",
    "            # scripted_model = torch.jit.script(model)\n",
    "            # # 保存序列化的模型\n",
    "            # torch.jit.save(scripted_model, f'jit_model/fold_{fold}_model.pt')\n",
    "\n",
    "            n_patience = 0\n",
    "        else:\n",
    "            n_patience += 1\n",
    "            logger.info(\n",
    "                f\"Valid loss didn't improve last {n_patience} epochs.\\n\")\n",
    "\n",
    "        if n_patience >= patience:\n",
    "            logger.info(\n",
    "                \"Early stop, Training End.\\n\")\n",
    "            break\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "logger = init_logger(log_file=f\"../log/train_{CFG.exp_name}.log\")\n",
    "device = get_device()\n",
    "set_seed(CFG.seed)\n",
    "os.makedirs(os.path.join(CFG.model_output_path), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.read_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main-20240518T060118Z-001/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main/train_folds_0518.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # a[\"filename\"] = a[\"filename\"].apply(lambda x: x.replace(\"../dataset\",\"\"))\n",
    "# a[\"filename\"] = a[\"filename\"].apply(lambda x: \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input\"+x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.to_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main-20240518T060118Z-001/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main/train_folds_0518.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttModel(\n",
    "        backbone=CFG.backbone,\n",
    "        num_class=CFG.num_classes,\n",
    "        train_period=CFG.period,\n",
    "        infer_period=5,\n",
    "    )\n",
    "# modelpath = \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main-20240518T060118Z-001/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main/models/exp071_tf_efficientnet_b0_ns/fold_0_model.bin\"\n",
    "# len(torch.load(modelpath)[\"state_dict\"].keys())\n",
    "\n",
    "#363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(54310, 5)\n",
      "(54310, 5)\n",
      "(54310, 5)\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Fold 0 Training\n",
      "Fold 0 Training\n",
      "Fold 0 Training\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "(44599, 5)\n",
      "(44599, 5)\n",
      "(44599, 5)\n",
      "primary_label\n",
      "nocall     5755\n",
      "houspa     2078\n",
      "eaywag1    1977\n",
      "commoo3    1766\n",
      "eurcoo     1701\n",
      "           ... \n",
      "wynlau1       9\n",
      "integr        8\n",
      "wbbfly1       7\n",
      "niwpig1       6\n",
      "asiope1       5\n",
      "Name: count, Length: 183, dtype: int64\n",
      "primary_label\n",
      "nocall     5755\n",
      "houspa     2078\n",
      "eaywag1    1977\n",
      "commoo3    1766\n",
      "eurcoo     1701\n",
      "           ... \n",
      "wynlau1       9\n",
      "integr        8\n",
      "wbbfly1       7\n",
      "niwpig1       6\n",
      "asiope1       5\n",
      "Name: count, Length: 183, dtype: int64\n",
      "primary_label\n",
      "nocall     5755\n",
      "houspa     2078\n",
      "eaywag1    1977\n",
      "commoo3    1766\n",
      "eurcoo     1701\n",
      "           ... \n",
      "wynlau1       9\n",
      "integr        8\n",
      "wbbfly1       7\n",
      "niwpig1       6\n",
      "asiope1       5\n",
      "Name: count, Length: 183, dtype: int64\n",
      "(9711, 5)\n",
      "(9711, 5)\n",
      "(9711, 5)\n",
      "primary_label\n",
      "houspa     520\n",
      "eaywag1    494\n",
      "commoo3    441\n",
      "eurcoo     426\n",
      "barswa     345\n",
      "          ... \n",
      "niwpig1      2\n",
      "asiope1      2\n",
      "blaeag1      2\n",
      "wbbfly1      2\n",
      "malwoo1      2\n",
      "Name: count, Length: 182, dtype: int64\n",
      "primary_label\n",
      "houspa     520\n",
      "eaywag1    494\n",
      "commoo3    441\n",
      "eurcoo     426\n",
      "barswa     345\n",
      "          ... \n",
      "niwpig1      2\n",
      "asiope1      2\n",
      "blaeag1      2\n",
      "wbbfly1      2\n",
      "malwoo1      2\n",
      "Name: count, Length: 182, dtype: int64\n",
      "primary_label\n",
      "houspa     520\n",
      "eaywag1    494\n",
      "commoo3    441\n",
      "eurcoo     426\n",
      "barswa     345\n",
      "          ... \n",
      "niwpig1      2\n",
      "asiope1      2\n",
      "blaeag1      2\n",
      "wbbfly1      2\n",
      "malwoo1      2\n",
      "Name: count, Length: 182, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5755, 6)\n",
      "the length of parameters is 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/696 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (160000,)\n",
      "2 (160000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/696 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (160000,)\n",
      "2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_2804520/448537581.py\", line 70, in __getitem__\n    res = self.wave_transforms(\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/albumentations/core/composition.py\", line 213, in __call__\n    data = t(**data)\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/albumentations/core/transforms_interface.py\", line 110, in __call__\n    params_dependent_on_targets = self.get_params_dependent_on_targets(targets_as_params)\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/albumentations/augmentations/dropout/coarse_dropout.py\", line 148, in get_params_dependent_on_targets\n    y1 = random.randint(0, height - hole_height)\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/random.py\", line 370, in randint\n    return self.randrange(a, b+1)\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/random.py\", line 353, in randrange\n    raise ValueError(\"empty range for randrange() (%d, %d, %d)\" % (istart, istop, width))\nValueError: empty range for randrange() (0, -46, -46)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 143\u001b[0m\n\u001b[1;32m    132\u001b[0m     scheduler \u001b[38;5;241m=\u001b[39m CosineLRScheduler(\n\u001b[1;32m    133\u001b[0m         optimizer,\n\u001b[1;32m    134\u001b[0m         t_initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m         t_in_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    140\u001b[0m     )\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# start training\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining done!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 18\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(train_loader, val_loader, model, optimizer, scheduler, criterion, epochs, fold)\u001b[0m\n\u001b[1;32m     14\u001b[0m n_patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs): \n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     train_loss, train_cmAP1, train_cmAP5, train_mAP,train_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# evaluate on validation set\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     val_loss, val_cmAP1, val_cmAP5, val_mAP,scores \u001b[38;5;241m=\u001b[39m valid_fn(\n\u001b[1;32m     23\u001b[0m         val_loader, model, criterion, epoch,)\n",
      "Cell \u001b[0;32mIn[48], line 143\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, criterion, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m    139\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(data_loader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_loader)) \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (data) \u001b[38;5;129;01min\u001b[39;00m t:\n\u001b[1;32m    144\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m batch_to_device(data, device)\n\u001b[1;32m    145\u001b[0m         targets \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprimary_targets\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_2804520/448537581.py\", line 70, in __getitem__\n    res = self.wave_transforms(\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/albumentations/core/composition.py\", line 213, in __call__\n    data = t(**data)\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/albumentations/core/transforms_interface.py\", line 110, in __call__\n    params_dependent_on_targets = self.get_params_dependent_on_targets(targets_as_params)\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/albumentations/augmentations/dropout/coarse_dropout.py\", line 148, in get_params_dependent_on_targets\n    y1 = random.randint(0, height - hole_height)\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/random.py\", line 370, in randint\n    return self.randrange(a, b+1)\n  File \"/home/simon/miniconda3/envs/kaggle/lib/python3.10/random.py\", line 353, in randrange\n    raise ValueError(\"empty range for randrange() (%d, %d, %d)\" % (istart, istop, width))\nValueError: empty range for randrange() (0, -46, -46)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (160000,)\n",
      "2 (160000,)\n",
      "2 (160000,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (160000,)\n",
      "2 (160000,)\n",
      "2 (160000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# with open(TRAIN_DATA_PATH + 'train_meta_pseudo.pickle', 'rb') as f:\n",
    "#     train = pickle.load(f)\n",
    "# train['filename'] = '../input/birdclef-2023/train_audio/' + train['filename']\n",
    "train = pd.read_csv(\"../train_folds_0518.csv\")\n",
    "train['rating'] = 1\n",
    "\n",
    "# with open('../input/xeno-canto_audio_meta_pseudo.pickle', 'rb') as f:\n",
    "#     xeno_canto_sa = pickle.load(f)\n",
    "# xeno_canto_sa[\"fold\"] = -1\n",
    "# train = pd.concat([train, xeno_canto_sa]).reset_index(drop=True)\n",
    "\n",
    "# with open('../input/xeno-canto_nd_audio_meta_pseudo.pickle', 'rb') as f:\n",
    "#     xeno_canto_nd = pickle.load(f)\n",
    "# train = pd.concat([train, xeno_canto_nd]).reset_index(drop=True)\n",
    "\n",
    "if CFG.external:\n",
    "    # with open('/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/ff1010bird_metadata_v1_pseudo.pickle', 'rb') as f:\n",
    "    #     external = pickle.load(f)\n",
    "    external = pd.read_pickle(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/ff1010bird_metadata_v1_pseudo.pickle\")\n",
    "    external[\"filename\"] = external[\"filename\"].apply(lambda x: \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/nocall_archive/ff1010bird_nocall/nocall\"+x)\n",
    "    # external[\"type\"] = '[]'\n",
    "    external[\"kfold\"] = -1\n",
    "    external[\"rating\"] = 1\n",
    "    select_cols = ['filename', 'primary_label','secondary_labels','kfold', 'rating']\n",
    "    external[\"filename\"] = '../input/birdclef-2023/train_audio/' + 'nocall/' + external['filename']\n",
    "    del external['length']\n",
    "\n",
    "    print(external.shape)\n",
    "    external.head()\n",
    "    train = pd.concat([train[select_cols], external[select_cols]]).reset_index(drop=True)\n",
    "\n",
    "# train[\"rating\"] = np.clip(train[\"rating\"] / train[\"rating\"].max(), 0.1, 1.0)\n",
    "\n",
    "logger.info(train.shape)\n",
    "train.head()\n",
    "\n",
    "# main loop\n",
    "for fold in range(5):\n",
    "\n",
    "    if fold not in CFG.folds:\n",
    "        continue\n",
    "    logger.info(\"=\" * 90)\n",
    "    logger.info(f\"Fold {fold} Training\")\n",
    "    logger.info(\"=\" * 90)\n",
    "\n",
    "    trn_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    val_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    sampler = None\n",
    "    if CFG.use_sampler:\n",
    "        one_hot_target = np.zeros(\n",
    "            (trn_df.shape[0], len(CFG.target_columns)), dtype=np.float32\n",
    "            )\n",
    "\n",
    "        for i, label in enumerate(trn_df.primary_label):\n",
    "            if label != \"nocall\":\n",
    "                primary_label = CFG.bird2id[label]\n",
    "                one_hot_target[i, primary_label] = 1.0\n",
    "\n",
    "        sampler = MultilabelBalancedRandomSampler(\n",
    "            one_hot_target,\n",
    "            trn_df.index,\n",
    "            class_choice=\"least_sampled\"\n",
    "            )\n",
    "\n",
    "    logger.info(trn_df.shape)\n",
    "    logger.info(trn_df['primary_label'].value_counts())\n",
    "    logger.info(val_df.shape)\n",
    "    logger.info(val_df['primary_label'].value_counts())\n",
    "\n",
    "    loaders = {}\n",
    "    trn_dataset = BirdClef2023Dataset(\n",
    "            data_path=CFG.train_datadir,\n",
    "            period=CFG.period,\n",
    "            secondary_coef=CFG.secondary_coef,\n",
    "            train=True,\n",
    "            df=trn_df,\n",
    "    )\n",
    "    loaders['train'] = torchdata.DataLoader(\n",
    "        trn_dataset,\n",
    "        sampler=sampler,\n",
    "        **CFG.loader_params['train']\n",
    "    )\n",
    "    val_dataset = BirdClef2023Dataset(\n",
    "            data_path=CFG.train_datadir,\n",
    "            period=5,\n",
    "            secondary_coef=CFG.secondary_coef,\n",
    "            train=False,\n",
    "            df=val_df,\n",
    "    )\n",
    "    loaders['valid'] = torchdata.DataLoader(\n",
    "        val_dataset,\n",
    "        **CFG.loader_params['valid']\n",
    "    )\n",
    "\n",
    "    model = AttModel(\n",
    "        backbone=CFG.backbone,\n",
    "        num_class=CFG.num_classes,\n",
    "        train_period=CFG.period,\n",
    "        infer_period=5,\n",
    "    )\n",
    "\n",
    "    if CFG.pretrained_weights:\n",
    "        model_path = CFG.pretrained_path\n",
    "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "        del checkpoint['state_dict']['head.weight']\n",
    "        del checkpoint['state_dict']['head.bias']\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
    "\n",
    "        params = list(model.parameters())\n",
    "        print('the length of parameters is', len(params))\n",
    "        for i in range(len(params)):\n",
    "            params[i].data = torch.round(params[i].data*10**17) / 10**17\n",
    "        del checkpoint\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # del xeno_canto_sa, xeno_canto_nd, external\n",
    "    gc.collect()\n",
    "\n",
    "    # criterion = BCEKDLoss()\n",
    "    criterion = FocalLossBCE()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CFG.lr_max,\n",
    "        betas=(0.9, 0.999),\n",
    "        eps=1e-08,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "        amsgrad=False,\n",
    "        )\n",
    "    scheduler = CosineLRScheduler(\n",
    "        optimizer,\n",
    "        t_initial=10,\n",
    "        warmup_t=1,\n",
    "        cycle_limit=40,\n",
    "        cycle_decay=1.0,\n",
    "        lr_min=CFG.lr_min,\n",
    "        t_in_epochs=True,\n",
    "    )\n",
    "\n",
    "    # start training\n",
    "    train_loop(\n",
    "        loaders['train'],\n",
    "        loaders['valid'],\n",
    "        model,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        criterion,\n",
    "        epochs=CFG.epochs,\n",
    "        fold=fold,\n",
    "        )\n",
    "\n",
    "logger.info('training done!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
