{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import importlib\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "import audiomentations as AA\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torchdata\n",
    "import torch_audiomentations as TAA\n",
    "import albumentations\n",
    "\n",
    "from sklearn import metrics\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.distributions import Beta\n",
    "from torchaudio.transforms import AmplitudeToDB, MelSpectrogram\n",
    "from tqdm import tqdm\n",
    "from utils import AverageMeter\n",
    "\n",
    "sys.path.append('../configs')\n",
    "sys.path.append('./samplers')\n",
    "sys.path.append('./pcen')\n",
    "from pcen import StreamingPCENTransform\n",
    "# from sampler import MultilabelBalancedRandomSampler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "TRAIN_DATA_PATH = '../dataset/birdclef-2024/'\n",
    "\n",
    "torch.set_flush_denormal(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'asbfly': 0, 'ashdro1': 1, 'ashpri1': 2, 'ashwoo2': 3, 'asikoe2': 4, 'asiope1': 5, 'aspfly1': 6, 'aspswi1': 7, 'barfly1': 8, 'barswa': 9, 'bcnher': 10, 'bkcbul1': 11, 'bkrfla1': 12, 'bkskit1': 13, 'bkwsti': 14, 'bladro1': 15, 'blaeag1': 16, 'blakit1': 17, 'blhori1': 18, 'blnmon1': 19, 'blrwar1': 20, 'bncwoo3': 21, 'brakit1': 22, 'brasta1': 23, 'brcful1': 24, 'brfowl1': 25, 'brnhao1': 26, 'brnshr': 27, 'brodro1': 28, 'brwjac1': 29, 'brwowl1': 30, 'btbeat1': 31, 'bwfshr1': 32, 'categr': 33, 'chbeat1': 34, 'cohcuc1': 35, 'comfla1': 36, 'comgre': 37, 'comior1': 38, 'comkin1': 39, 'commoo3': 40, 'commyn': 41, 'compea': 42, 'comros': 43, 'comsan': 44, 'comtai1': 45, 'copbar1': 46, 'crbsun2': 47, 'cregos1': 48, 'crfbar1': 49, 'crseag1': 50, 'dafbab1': 51, 'darter2': 52, 'eaywag1': 53, 'emedov2': 54, 'eucdov': 55, 'eurbla2': 56, 'eurcoo': 57, 'forwag1': 58, 'gargan': 59, 'gloibi': 60, 'goflea1': 61, 'graher1': 62, 'grbeat1': 63, 'grecou1': 64, 'greegr': 65, 'grefla1': 66, 'grehor1': 67, 'grejun2': 68, 'grenig1': 69, 'grewar3': 70, 'grnsan': 71, 'grnwar1': 72, 'grtdro1': 73, 'gryfra': 74, 'grynig2': 75, 'grywag': 76, 'gybpri1': 77, 'gyhcaf1': 78, 'heswoo1': 79, 'hoopoe': 80, 'houcro1': 81, 'houspa': 82, 'inbrob1': 83, 'indpit1': 84, 'indrob1': 85, 'indrol2': 86, 'indtit1': 87, 'ingori1': 88, 'inpher1': 89, 'insbab1': 90, 'insowl1': 91, 'integr': 92, 'isbduc1': 93, 'jerbus2': 94, 'junbab2': 95, 'junmyn1': 96, 'junowl1': 97, 'kenplo1': 98, 'kerlau2': 99, 'labcro1': 100, 'laudov1': 101, 'lblwar1': 102, 'lesyel1': 103, 'lewduc1': 104, 'lirplo': 105, 'litegr': 106, 'litgre1': 107, 'litspi1': 108, 'litswi1': 109, 'lobsun2': 110, 'maghor2': 111, 'malpar1': 112, 'maltro1': 113, 'malwoo1': 114, 'marsan': 115, 'mawthr1': 116, 'moipig1': 117, 'nilfly2': 118, 'niwpig1': 119, 'nutman': 120, 'orihob2': 121, 'oripip1': 122, 'pabflo1': 123, 'paisto1': 124, 'piebus1': 125, 'piekin1': 126, 'placuc3': 127, 'plaflo1': 128, 'plapri1': 129, 'plhpar1': 130, 'pomgrp2': 131, 'purher1': 132, 'pursun3': 133, 'pursun4': 134, 'purswa3': 135, 'putbab1': 136, 'redspu1': 137, 'rerswa1': 138, 'revbul': 139, 'rewbul': 140, 'rewlap1': 141, 'rocpig': 142, 'rorpar': 143, 'rossta2': 144, 'rufbab3': 145, 'ruftre2': 146, 'rufwoo2': 147, 'rutfly6': 148, 'sbeowl1': 149, 'scamin3': 150, 'shikra1': 151, 'smamin1': 152, 'sohmyn1': 153, 'spepic1': 154, 'spodov': 155, 'spoowl1': 156, 'sqtbul1': 157, 'stbkin1': 158, 'sttwoo1': 159, 'thbwar1': 160, 'tibfly3': 161, 'tilwar1': 162, 'vefnut1': 163, 'vehpar1': 164, 'wbbfly1': 165, 'wemhar1': 166, 'whbbul2': 167, 'whbsho3': 168, 'whbtre1': 169, 'whbwag1': 170, 'whbwat1': 171, 'whbwoo2': 172, 'whcbar1': 173, 'whiter2': 174, 'whrmun': 175, 'whtkin2': 176, 'woosan': 177, 'wynlau1': 178, 'yebbab1': 179, 'yebbul3': 180, 'zitcis1': 181}\n"
     ]
    }
   ],
   "source": [
    "ROOT = \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input\"\n",
    "sub = pd.read_csv(f\"{ROOT}/birdclef-2024/sample_submission.csv\")\n",
    "target_columns = sub.columns.tolist()[1:]\n",
    "num_classes = len(target_columns)\n",
    "bird2id = {b: i for i, b in enumerate(target_columns)}\n",
    "print(bird2id)\n",
    "id2bird ={i:b for i, b in enumerate(target_columns)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_index = [0, 6, 10, 11, 15, 18, 19, 20,\n",
    " 24, 25, 26, 28, 30, 37, 38, 39, 40, 41, 44,\n",
    " 45, 46, 47, 48, 49, 50, 53, 54, 57, 61, 62,\n",
    " 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76,\n",
    " 77, 78, 80, 82, 84, 87, 90, 91, 97, 100, 102,\n",
    " 105, 107, 108, 109, 110, 111, 112, 113, 114,\n",
    " 116, 117, 118, 119, 121, 123, 128, 129, 133,\n",
    " 136, 137, 140, 141, 143, 146, 149, 153, 155,\n",
    " 157, 161, 164, 165, 169, 173, 176, 177, 178, 180,\n",
    " 181]\n",
    "select_cv_cols = [id2bird[i] for i in  col_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/issamemari/pytorch-multilabel-balanced-sampler/blob/master/sampler.py\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "\n",
    "class MultilabelBalancedRandomSampler(Sampler):\n",
    "    \"\"\"\n",
    "    MultilabelBalancedRandomSampler: Given a multilabel dataset of length n_samples and\n",
    "    number of classes n_classes, samples from the data with equal probability per class\n",
    "    effectively oversampling minority classes and undersampling majority classes at the\n",
    "    same time. Note that using this sampler does not guarantee that the distribution of\n",
    "    classes in the output samples will be uniform, since the dataset is multilabel and\n",
    "    sampling is based on a single class. This does however guarantee that all classes\n",
    "    will have at least batch_size / n_classes samples as batch_size approaches infinity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, indices=None, class_choice=\"least_sampled\"):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            labels: a multi-hot encoding numpy array of shape (n_samples, n_classes)\n",
    "            indices: an arbitrary-length 1-dimensional numpy array representing a list\n",
    "            of indices to sample only from\n",
    "            class_choice: a string indicating how class will be selected for every\n",
    "            sample:\n",
    "                \"least_sampled\": class with the least number of sampled labels so far\n",
    "                \"random\": class is chosen uniformly at random\n",
    "                \"cycle\": the sampler cycles through the classes sequentially\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "        if self.indices is None:\n",
    "            self.indices = range(len(labels))\n",
    "\n",
    "        self.num_classes = self.labels.shape[1]\n",
    "\n",
    "        # List of lists of example indices per class\n",
    "        self.class_indices = []\n",
    "        for class_ in range(self.num_classes):\n",
    "            lst = np.where(self.labels[:, class_] == 1)[0]\n",
    "            lst = lst[np.isin(lst, self.indices)]\n",
    "            self.class_indices.append(lst)\n",
    "\n",
    "        self.counts = [0] * self.num_classes\n",
    "\n",
    "        assert class_choice in [\"least_sampled\", \"random\", \"cycle\"]\n",
    "        self.class_choice = class_choice\n",
    "        self.current_class = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.count >= len(self.indices):\n",
    "            raise StopIteration\n",
    "        self.count += 1\n",
    "        return self.sample()\n",
    "\n",
    "    def sample(self):\n",
    "        class_ = self.get_class()\n",
    "        class_indices = self.class_indices[class_]\n",
    "        chosen_index = np.random.choice(class_indices)\n",
    "        if self.class_choice == \"least_sampled\":\n",
    "            for class_, indicator in enumerate(self.labels[chosen_index]):\n",
    "                if indicator == 1:\n",
    "                    self.counts[class_] += 1\n",
    "        return chosen_index\n",
    "\n",
    "    def get_class(self):\n",
    "        if self.class_choice == \"random\":\n",
    "            class_ = random.randint(0, self.labels.shape[1] - 1)\n",
    "        elif self.class_choice == \"cycle\":\n",
    "            class_ = self.current_class\n",
    "            self.current_class = (self.current_class + 1) % self.labels.shape[1]\n",
    "        elif self.class_choice == \"least_sampled\":\n",
    "            min_count = self.counts[0]\n",
    "            min_classes = [0]\n",
    "            for class_ in range(1, self.num_classes):\n",
    "                if self.counts[class_] < min_count:\n",
    "                    min_count = self.counts[class_]\n",
    "                    min_classes = [class_]\n",
    "                if self.counts[class_] == min_count:\n",
    "                    min_classes.append(class_)\n",
    "            class_ = np.random.choice(min_classes)\n",
    "        return class_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy  \n",
    "import importlib.util  \n",
    "import os  \n",
    "  \n",
    "# 假设你的配置文件是一个 Python 模块，并且它位于某个固定的路径下  \n",
    "# 例如，配置文件名为 'config.py'，它位于与当前脚本相同的目录下  \n",
    "CONFIG_FILE_NAME = 'exp071.py'  # 配置文件名  \n",
    "CONFIG_MODULE_NAME = CONFIG_FILE_NAME.replace('.py', '')  # 转换为模块名  \n",
    "  \n",
    "# 获取当前脚本的目录（如果是从脚本运行的话）  \n",
    "# 注意：如果是从模块导入的，这个可能不是你想要的目录  \n",
    "CURRENT_DIR = \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main-20240518T060118Z-001/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main/configs\"\n",
    "CONFIG_FILE_PATH = os.path.join(CURRENT_DIR, CONFIG_FILE_NAME)  \n",
    "  \n",
    "# 检查配置文件是否存在  \n",
    "if not os.path.exists(CONFIG_FILE_PATH):  \n",
    "    raise FileNotFoundError(f\"Configuration file {CONFIG_FILE_PATH} not found.\")  \n",
    "  \n",
    "# 使用importlib导入配置文件模块  \n",
    "spec = importlib.util.spec_from_file_location(CONFIG_MODULE_NAME, CONFIG_FILE_PATH)  \n",
    "config_module = importlib.util.module_from_spec(spec)  \n",
    "spec.loader.exec_module(config_module)  \n",
    "  \n",
    "# 假设你的配置文件模块中有一个名为 'cfg' 的变量或属性  \n",
    "CFG = copy.deepcopy(getattr(config_module, 'cfg', None))  \n",
    "if CFG is None:  \n",
    "    raise AttributeError(f\"Module {CONFIG_MODULE_NAME} does not have an attribute 'cfg'.\")  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description=\"\")\n",
    "# parser.add_argument(\"-C\", \"--config\", help=\"config filename\")\n",
    "# parser_args, _ = parser.parse_known_args(sys.argv)\n",
    "# CFG = copy(importlib.import_module(parser_args.config).cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def init_logger(log_file='train.log'):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def load_wave_and_crop(filename, period, start=None):\n",
    "\n",
    "    waveform_orig, sample_rate = librosa.load(filename, sr=32000, mono=False)\n",
    "\n",
    "    wave_len = len(waveform_orig)\n",
    "    waveform = np.concatenate([waveform_orig, waveform_orig, waveform_orig])\n",
    "\n",
    "    effective_length = sample_rate * period\n",
    "    while len(waveform) < (period * sample_rate * 3):\n",
    "        waveform = np.concatenate([waveform, waveform_orig])\n",
    "    if start is not None:\n",
    "        start = start - (period - 5) / 2 * sample_rate\n",
    "        while start < 0:\n",
    "            start += wave_len\n",
    "        start = int(start)\n",
    "    else:\n",
    "        if wave_len < effective_length:\n",
    "            start = np.random.randint(effective_length - wave_len)\n",
    "        elif wave_len > effective_length:\n",
    "            start = np.random.randint(wave_len - effective_length)\n",
    "        elif wave_len == effective_length:\n",
    "            start = 0\n",
    "\n",
    "    waveform_seg = waveform[start: start + int(effective_length)]\n",
    "\n",
    "    return waveform_orig, waveform_seg, sample_rate, start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.transforms import v2 as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for wave trasnform 1d  (160000,)\n",
    "# tr_transforms = albumentations.Compose(\n",
    "#     [\n",
    "#     #    albumentations.OneOf([\n",
    "#     #         AA.Gain(min_gain_in_db=-15, max_gain_in_db=15, p=1.0),\n",
    "#     #         AA.GainTransition(\n",
    "#     #             min_gain_in_db=-24.0,\n",
    "#     #             max_gain_in_db=6.0,\n",
    "#     #             min_duration=0.2,\n",
    "#     #             max_duration=6.0,\n",
    "#     #             p=1.0\n",
    "#     #         )\n",
    "#     #     ], p=0.5,),\n",
    "#         albumentations.HorizontalFlip(p=0.5),\n",
    "#         albumentations.CoarseDropout(max_height=int(128 * 0.375), max_width=int(128 * 0.375), max_holes=1, p=0.7),\n",
    "#         # albumentations.XYMasking(\n",
    "#         #         p=0.3,\n",
    "#         #         num_masks_x=(1, 3),\n",
    "#         #         num_masks_y=(1, 3),\n",
    "#         #         mask_x_length=(1, 10),\n",
    "#         #         mask_y_length=(1, 20),\n",
    "#         #     ) ,\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "tr_transforms = AA.Compose(\n",
    "    [\n",
    "        AA.OneOf([\n",
    "            AA.Gain(min_gain_in_db=-15, max_gain_in_db=15, p=1.0),\n",
    "            AA.GainTransition(\n",
    "                min_gain_in_db=-24.0,\n",
    "                max_gain_in_db=6.0,\n",
    "                min_duration=0.2,\n",
    "                max_duration=6.0,\n",
    "                p=1.0\n",
    "            )\n",
    "        ], p=0.5,),\n",
    "        # AA.OneOf([\n",
    "        #     AA.AddGaussianNoise(p=1.0),\n",
    "        #     AA.AddGaussianSNR(p=1.0),\n",
    "        # ], p=0.3,),\n",
    "        # AA.OneOf([\n",
    "        #     AA.AddShortNoises(\n",
    "        #         sounds_path=\"../input/esc50/use_label\",\n",
    "        #         min_snr_in_db=0,\n",
    "        #         max_snr_in_db=3,\n",
    "        #         p=1.0,\n",
    "        #         lru_cache_size=10,\n",
    "        #         min_time_between_sounds=4.0,\n",
    "        #         max_time_between_sounds=16.0,\n",
    "        #     ),\n",
    "        # ], p=0.5,),\n",
    "        # AA.OneOf([\n",
    "        #     AA.AddBackgroundNoise(\n",
    "        #         sounds_path=\"../input/zenodo_nocall_30sec\",\n",
    "        #         min_snr_in_db=0,\n",
    "        #         max_snr_in_db=3,\n",
    "        #         p=1.0,\n",
    "        #         lru_cache_size=1400,),\n",
    "        # ], p=0.5,),\n",
    "        AA.LowPassFilter(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# alb_transform = [\n",
    "#         ### num_masks_x=1, num_masks_y=1 will change\n",
    "#         albumentations.XYMasking(num_masks_x=2, num_masks_y=1, \n",
    "#                                  mask_x_length=20, mask_y_length=4,\n",
    "#                                  fill_value=0, mask_fill_value=0, p=CFG.aug_spec_xymasking),\n",
    "#         albumentations.CoarseDropout(fill_value=0, min_holes=20, max_holes=50, p=CFG.aug_spec_coarsedrop),\n",
    "#         albumentations.HorizontalFlip(p=CFG.aug_spec_hflip),\n",
    "#         # albumentations.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ]\n",
    "# tr_transforms = albumentations.Compose(alb_transform)\n",
    "\n",
    "# va_transform = AA.Compose(\n",
    "#     # albumentations.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),1\n",
    "# )\n",
    "\n",
    "\n",
    "taa_augmentation = TAA.Compose(\n",
    "    transforms=[\n",
    "        TAA.PitchShift(\n",
    "            sample_rate=CFG.sample_rate,\n",
    "            mode=\"per_example\",\n",
    "            p=0.2,\n",
    "            ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BirdClef2023Dataset(torchdata.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str = 'DATA_PATH',\n",
    "        period: float = 5.0,\n",
    "        secondary_coef: float = 1.0,\n",
    "        smooth_label: float = 0.05,\n",
    "        df: pd.DataFrame = 'DATAFRAME',\n",
    "        train: bool = True,\n",
    "    ):\n",
    "\n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.filenames = df[\"filename\"]\n",
    "\n",
    "        self.primary_label = df[\"primary_label\"]\n",
    "        self.secondary_labels = (\n",
    "            df[\"secondary_labels\"]\n",
    "            .map(\n",
    "                lambda s: s.replace(\"[\", \"\")\n",
    "                .replace(\"]\", \"\")\n",
    "                .replace(\",\", \"\")\n",
    "                .replace(\"'\", \"\")\n",
    "                .split(\" \")\n",
    "            ).values\n",
    "        )\n",
    "\n",
    "        self.secondary_coef = secondary_coef\n",
    "        # self.type = df[\"type\"]\n",
    "        self.teacher_preds = df[\"teacher_preds\"]\n",
    "        self.rating = df[\"rating\"]\n",
    "        self.period = period\n",
    "        self.smooth_label = smooth_label + 1e-6\n",
    "        self.wave_transforms = tr_transforms\n",
    "        # self.wave_transforms_val = va_transforms\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "   \n",
    "    def normalize(self, x):\n",
    "        valid_values = x[x != float('-inf')]\n",
    "        mean_value = np.mean(valid_values)\n",
    "        x[x == float('-inf')] = mean_value\n",
    "        # x[x == float('-inf')] = 0\n",
    "\n",
    "        x = x - x.min()\n",
    "        x = x / x.max()\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        filename = os.path.join(self.data_path, self.filenames[idx])\n",
    "\n",
    "        if self.train:\n",
    "            waveform, waveform_seg, sample_rate, start = load_wave_and_crop(\n",
    "                filename, self.period ,0                                     # 训练也是前5s\n",
    "            )\n",
    "            # print(f\"1----{waveform_seg.shape=}\")\n",
    "            # for i in range(len(waveform_seg )):\n",
    "            #     waveform_seg[i] = self.normalize(waveform_seg[i])\n",
    "            # print(type(waveform_seg))\n",
    "            # waveform_seg = self.wave_transforms(\n",
    "            #     # image = waveform_seg\n",
    "            #     samples=waveform_seg, sample_rate=sample_rate\n",
    "            #     )\n",
    "            # waveform_seg = waveform_seg[np.newaxis,:]\n",
    "            # print(waveform_seg.shape)\n",
    "\n",
    "            res = self.wave_transforms(\n",
    "                # image = waveform_seg\n",
    "                samples=waveform_seg, sample_rate=sample_rate\n",
    "                )\n",
    "            # waveform_seg = res['image'].astype(np.float32)\n",
    "            # # print(\"2\",type(waveform_seg))\n",
    "            # waveform_seg = waveform_seg.flatten()\n",
    "            # print(\"2\",waveform_seg.shape)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        else:\n",
    "            waveform, waveform_seg, sample_rate, start = load_wave_and_crop(\n",
    "                filename, self.period, 0\n",
    "            )\n",
    "            # for i in range(len(waveform_seg)):\n",
    "            #     waveform_seg[i] = self.normalize(waveform_seg[i])\n",
    "            # waveform_seg = self.wave_transforms_val(\n",
    "            #     samples=waveform_seg, sample_rate=sample_rate\n",
    "            #     )\n",
    "\n",
    "        waveform_seg = torch.from_numpy(np.nan_to_num(waveform_seg)).float()\n",
    "\n",
    "\n",
    "        rating = self.rating[idx]\n",
    "\n",
    "        teacher_preds = torch.from_numpy(np.nan_to_num(self.teacher_preds[idx])).float()\n",
    "\n",
    "        target = np.zeros(CFG.num_classes, dtype=np.float32)\n",
    "        if self.primary_label[idx] != 'nocall':\n",
    "            primary_label = CFG.bird2id[self.primary_label[idx]]\n",
    "            target[primary_label] = 1.0\n",
    "\n",
    "            if self.train:\n",
    "                for s in self.secondary_labels[idx]:\n",
    "                    if s != \"\" and s in CFG.bird2id.keys():\n",
    "                        target[CFG.bird2id[s]] = self.secondary_coef\n",
    "\n",
    "        target = torch.from_numpy(target).float()\n",
    "        # teacher_preds = target\n",
    "\n",
    "        return {\n",
    "            \"wave\": waveform_seg,\n",
    "            \"rating\": rating,\n",
    "            \"primary_targets\": (target > 0.5).float(),\n",
    "            \"loss_target\": target * (1-self.smooth_label) + self.smooth_label / target.size(-1),\n",
    "            \"teacher_preds\": teacher_preds,\n",
    "        }\n",
    "\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = torch.nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "\n",
    "def gem_freq(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), 1)).pow(1.0 / p)\n",
    "\n",
    "\n",
    "class GeMFreq(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.p = torch.nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem_freq(x, p=self.p, eps=self.eps)\n",
    "\n",
    "\n",
    "class NormalizeMelSpec(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, X):\n",
    "        mean = X.mean((1, 2), keepdim=True)\n",
    "        std = X.std((1, 2), keepdim=True)\n",
    "        Xstd = (X - mean) / (std + self.eps)\n",
    "        norm_min, norm_max = \\\n",
    "            Xstd.min(-1)[0].min(-1)[0], Xstd.max(-1)[0].max(-1)[0]\n",
    "        fix_ind = (norm_max - norm_min) > self.eps * torch.ones_like(\n",
    "            (norm_max - norm_min)\n",
    "        )\n",
    "        V = torch.zeros_like(Xstd)\n",
    "        if fix_ind.sum():\n",
    "            V_fix = Xstd[fix_ind]\n",
    "            norm_max_fix = norm_max[fix_ind, None, None]\n",
    "            norm_min_fix = norm_min[fix_ind, None, None]\n",
    "            V_fix = torch.max(\n",
    "                torch.min(V_fix, norm_max_fix),\n",
    "                norm_min_fix,\n",
    "            )\n",
    "            V_fix = (V_fix - norm_min_fix) / (norm_max_fix - norm_min_fix)\n",
    "            V[fix_ind] = V_fix\n",
    "        return V\n",
    "\n",
    "\n",
    "class Mixup(nn.Module):\n",
    "    def __init__(self, mix_beta):\n",
    "\n",
    "        super(Mixup, self).__init__()\n",
    "        self.beta_distribution = Beta(mix_beta, mix_beta)\n",
    "\n",
    "    def forward(self, X, Y, weight=None, teacher_preds=None):\n",
    "\n",
    "        bs = X.shape[0]\n",
    "        n_dims = len(X.shape)\n",
    "        perm = torch.randperm(bs)\n",
    "        coeffs = self.beta_distribution.rsample(torch.Size((bs,))).to(X.device)\n",
    "\n",
    "        if n_dims == 2:\n",
    "            X = coeffs.view(-1, 1) * X + (1 - coeffs.view(-1, 1)) * X[perm]\n",
    "        elif n_dims == 3:\n",
    "            X = coeffs.view(-1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1)) * X[perm]\n",
    "        else:\n",
    "            X = coeffs.view(-1, 1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1, 1)) * X[perm]\n",
    "\n",
    "        Y = coeffs.view(-1, 1) * Y + (1 - coeffs.view(-1, 1)) * Y[perm]\n",
    "\n",
    "        if weight is None:\n",
    "            return X, Y\n",
    "        else:\n",
    "            weight = coeffs.view(-1) * weight + (1 - coeffs.view(-1)) * weight[perm]\n",
    "            teacher_preds = coeffs.view(-1, 1) * teacher_preds + (1 - coeffs.view(-1, 1)) * teacher_preds[perm]\n",
    "            return X, Y, weight, teacher_preds\n",
    "\n",
    "\n",
    "class AttModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone=\"resnet34\",\n",
    "        num_class=397,\n",
    "        train_period=15.0,\n",
    "        infer_period=5.0,\n",
    "        in_chans=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if CFG.use_pcen:\n",
    "            self.pcen = StreamingPCENTransform(\n",
    "                n_mels=CFG.n_mels,\n",
    "                n_fft=CFG.n_fft,\n",
    "                hop_length=CFG.hop_length,\n",
    "                trainable=True,\n",
    "                use_cuda_kernel=False\n",
    "                )\n",
    "            self.pcen.last_state = torch.zeros([55, 1, 128])\n",
    "        else:\n",
    "            self.logmelspec_extractor = nn.Sequential(\n",
    "                MelSpectrogram(\n",
    "                    sample_rate=CFG.sample_rate,\n",
    "                    n_mels=CFG.n_mels,\n",
    "                    f_min=CFG.fmin,\n",
    "                    f_max=CFG.fmax,\n",
    "                    n_fft=CFG.n_fft,\n",
    "                    hop_length=CFG.hop_length,\n",
    "                    normalized=True,\n",
    "                ),\n",
    "                AmplitudeToDB(top_db=80.0),\n",
    "                NormalizeMelSpec(),\n",
    "            )\n",
    "\n",
    "        base_model = timm.create_model(\n",
    "            backbone,\n",
    "            features_only=False,\n",
    "            pretrained=CFG.use_imagenet_weights,\n",
    "            in_chans=CFG.in_channels,\n",
    "        )\n",
    "\n",
    "        layers = list(base_model.children())[:-2]\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "        if \"efficientnet\" in CFG.backbone:\n",
    "            dense_input = base_model.num_features\n",
    "        elif \"swin\" in CFG.backbone:\n",
    "            dense_input = base_model.num_features\n",
    "        elif hasattr(base_model, \"fc\"):\n",
    "            dense_input = base_model.fc.in_features\n",
    "        else:\n",
    "            dense_input = base_model.feature_info[-1][\"num_chs\"]\n",
    "\n",
    "        self.train_period = train_period\n",
    "        self.infer_period = infer_period\n",
    "\n",
    "        self.factor = int(self.train_period / self.infer_period)\n",
    "        self.mixup = Mixup(mix_beta=1)\n",
    "        self.global_pool = GeM()\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(p) for p in np.linspace(0.1, 0.5, 5)])\n",
    "        self.head = nn.Linear(dense_input, num_class)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        if self.training:\n",
    "            x = input['wave']\n",
    "            bs, time = x.shape\n",
    "            x = x.reshape(bs * self.factor, time // self.factor)\n",
    "            y = input[\"loss_target\"]\n",
    "            weight = input[\"rating\"]\n",
    "            teacher_preds = input[\"teacher_preds\"]\n",
    "        else:\n",
    "            x = input['wave']\n",
    "            y = input[\"loss_target\"]\n",
    "            weight = input[\"rating\"]\n",
    "            teacher_preds = input[\"teacher_preds\"]\n",
    "\n",
    "        if CFG.use_pcen:\n",
    "            x = self.pcen(x).unsqueeze(1)\n",
    "            self.pcen.reset()\n",
    "        else:\n",
    "            x = self.logmelspec_extractor(x)[:, None]\n",
    "\n",
    "        if self.training:\n",
    "            if np.random.random() <= 0.5:\n",
    "                y2 = torch.repeat_interleave(y, self.factor, dim=0)\n",
    "                weight2 = torch.repeat_interleave(weight, self.factor, dim=0)\n",
    "                teacher_preds2 = torch.repeat_interleave(\n",
    "                    teacher_preds, self.factor, dim=0\n",
    "                    )\n",
    "\n",
    "                for i in range(0, x.shape[0], self.factor):\n",
    "                    x[i: i + self.factor], _, _, _ = self.mixup(\n",
    "                        x[i: i + self.factor],\n",
    "                        y2[i: i + self.factor],\n",
    "                        weight2[i: i + self.factor],\n",
    "                        teacher_preds2[i: i + self.factor],\n",
    "                    )\n",
    "\n",
    "            # # aug \n",
    "            # print(f\"1---{x.shape=}\")\n",
    "            # result = tr_transforms(image=x)  \n",
    "            # x= result[\"image\"]\n",
    "\n",
    "\n",
    "            b, c, f, t = x.shape\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            # print(f\"2---{x.shape=}\")\n",
    "            x = x.reshape(b // self.factor, self.factor * t, c, f)\n",
    "\n",
    "            if np.random.random() <= CFG.mixup_p:\n",
    "                x, y, weight, teacher_preds = self.mixup(x, y, weight, teacher_preds)\n",
    "\n",
    "            x = x.reshape(b, t, c, f)\n",
    "            x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        if self.training:\n",
    "            b, c, f, t = x.shape\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            x = x.reshape(b // self.factor, self.factor * t, c, f)\n",
    "            x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x[:, :, 0, 0]\n",
    "        logit = sum([self.head(dropout(x)) for dropout in self.dropouts]) / 5\n",
    "\n",
    "        return {\"logit\": logit, \"target\": y, \"rating\": weight, \"teacher_preds\": teacher_preds}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_focal_loss(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    alpha: float = 0.25,\n",
    "    gamma: float = 2,\n",
    "    reduction: str = \"none\",\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
    "\n",
    "    Args:\n",
    "        inputs (Tensor): A float tensor of arbitrary shape.\n",
    "                The predictions for each example.\n",
    "        targets (Tensor): A float tensor with the same shape as inputs. Stores the binary\n",
    "                classification label for each element in inputs\n",
    "                (0 for the negative class and 1 for the positive class).\n",
    "        alpha (float): Weighting factor in range (0,1) to balance\n",
    "                positive vs negative examples or -1 for ignore. Default: ``0.25``.\n",
    "        gamma (float): Exponent of the modulating factor (1 - p_t) to\n",
    "                balance easy vs hard examples. Default: ``2``.\n",
    "        reduction (string): ``'none'`` | ``'mean'`` | ``'sum'``\n",
    "                ``'none'``: No reduction will be applied to the output.\n",
    "                ``'mean'``: The output will be averaged.\n",
    "                ``'sum'``: The output will be summed. Default: ``'none'``.\n",
    "    Returns:\n",
    "        Loss tensor with the reduction option applied.\n",
    "    \"\"\"\n",
    "    # Original implementation from https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/focal_loss.py\n",
    "\n",
    "\n",
    "    p = torch.sigmoid(inputs)\n",
    "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "    p_t = p * targets + (1 - p) * (1 - targets)\n",
    "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
    "\n",
    "    if alpha >= 0:\n",
    "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        loss = alpha_t * loss\n",
    "\n",
    "    # Check reduction option and return loss accordingly\n",
    "    if reduction == \"none\":\n",
    "        pass\n",
    "    elif reduction == \"mean\":\n",
    "        loss = loss.mean()\n",
    "    elif reduction == \"sum\":\n",
    "        loss = loss.sum()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid Value for arg 'reduction': '{reduction} \\n Supported reduction modes: 'none', 'mean', 'sum'\"\n",
    "        )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BCEKDLoss(nn.Module):\n",
    "    def __init__(self, weights=[0.1, 0.9], class_weights=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weights = weights\n",
    "        self.T = 20\n",
    "\n",
    "    def forward(self, output):\n",
    "        input_ = output[\"logit\"]\n",
    "        target = output[\"target\"].float()\n",
    "        rating = output[\"rating\"]\n",
    "        teacher_preds = output[\"teacher_preds\"]\n",
    "\n",
    "        rating = rating.unsqueeze(1).repeat(1, CFG.num_classes)\n",
    "        loss = nn.BCEWithLogitsLoss(\n",
    "            weight=rating,\n",
    "            reduction='mean',\n",
    "        )(input_, target)\n",
    "\n",
    "        KD_loss = nn.KLDivLoss()(\n",
    "            F.log_softmax(input_ / self.T, dim=1),\n",
    "            F.softmax(teacher_preds / self.T, dim=1)\n",
    "            ) * (self.weights[1] * self.T * self.T)\n",
    "\n",
    "        return self.weights[0] * loss + KD_loss\n",
    "\n",
    "\n",
    "class FocalLossBCE(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            alpha: float = 0.25,\n",
    "            gamma: float = 2,\n",
    "            reduction: str = \"mean\",\n",
    "            bce_weight: float = 1.0,\n",
    "            focal_weight: float = 1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.bce = torch.nn.BCEWithLogitsLoss(reduction=reduction)\n",
    "        self.bce_weight = bce_weight\n",
    "        self.focal_weight = focal_weight\n",
    "\n",
    "    # def forward(self, logits, targets):\n",
    "    def forward(self,output):\n",
    "        logits = output[\"logit\"]\n",
    "        targets = output[\"target\"].float()\n",
    "        rating = output[\"rating\"]\n",
    "        teacher_preds = output[\"teacher_preds\"]\n",
    "\n",
    "        focall_loss = sigmoid_focal_loss(\n",
    "            inputs=logits,\n",
    "            targets=targets,\n",
    "            alpha=self.alpha,\n",
    "            gamma=self.gamma,\n",
    "            reduction=self.reduction,\n",
    "        )\n",
    "        bce_loss = self.bce(logits, targets.float())\n",
    "        return self.bce_weight * bce_loss + self.focal_weight * focall_loss\n",
    "\n",
    "\n",
    "\n",
    "def padded_cmap(solution, submission, padding_factor=5):\n",
    "    solution = solution  # .drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission  # .drop(['row_id'], axis=1, errors='ignore')\n",
    "    new_rows = []\n",
    "    for i in range(padding_factor):\n",
    "        new_rows.append([1 for i in range(len(solution.columns))])\n",
    "    new_rows = pd.DataFrame(new_rows)\n",
    "    new_rows.columns = solution.columns\n",
    "    padded_solution = pd.concat(\n",
    "        [solution, new_rows]).reset_index(drop=True).copy()\n",
    "    padded_submission = pd.concat(\n",
    "        [submission, new_rows]).reset_index(drop=True).copy()\n",
    "    score = metrics.average_precision_score(\n",
    "        padded_solution.values,\n",
    "        padded_submission.values,\n",
    "        average='macro',\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def map_score(solution, submission):\n",
    "    solution = solution  # .drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission  # .drop(['row_id'], axis=1, errors='ignore')\n",
    "    score = metrics.average_precision_score(\n",
    "        solution.values,\n",
    "        submission.values,\n",
    "        average='micro',  # 'macro'\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def batch_to_device(batch, device):\n",
    "    batch_dict = {key: batch[key].to(device) for key in batch}\n",
    "    return batch_dict\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    '''\n",
    "    Version of macro-averaged ROC-AUC score that ignores all classes that have no true positive labels.\n",
    "    '''\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "\n",
    "    solution_sums = solution.sum(axis=0)\n",
    "    scored_columns = list(solution_sums[solution_sums > 0].index.values)\n",
    "#     assert len(scored_columns) > 0\n",
    "\n",
    "    return sklearn.metrics.roc_auc_score(solution[scored_columns].values, submission[scored_columns].values, average='macro')\n",
    "\n",
    "def calculate_competition_metrics(gt, preds, target_columns, one_hot=True):\n",
    "    if not one_hot:\n",
    "        ground_truth = np.argmax(gt, axis=1)\n",
    "        gt = np.zeros((ground_truth.size, len(target_columns)))\n",
    "        gt[np.arange(ground_truth.size), ground_truth] = 1\n",
    "    val_df = pd.DataFrame(gt, columns=target_columns)\n",
    "    pred_df = pd.DataFrame(preds, columns=target_columns)\n",
    "    # cmAP_1 = padded_cmap(val_df, pred_df, padding_factor=1)\n",
    "    # cmAP_5 = padded_cmap(val_df, pred_df, padding_factor=5)\n",
    "    val_df['id'] = [f'id_{i}' for i in range(len(val_df))]\n",
    "    pred_df['id'] = [f'id_{i}' for i in range(len(pred_df))]\n",
    "    train_score = score(val_df, pred_df, row_id_column_name='id')\n",
    "    return {\n",
    "    #   \"cmAP_1\": cmAP_1,\n",
    "    #   \"cmAP_5\": cmAP_5,\n",
    "      \"ROC\": train_score,\n",
    "    }\n",
    "\n",
    "def train_fn(data_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    scaler = GradScaler(enabled=CFG.apex)\n",
    "    iters = len(data_loader)\n",
    "    gt = []\n",
    "    preds = []\n",
    "\n",
    "    with tqdm(enumerate(data_loader), total=len(data_loader)) as t:\n",
    "\n",
    "        for i, (data) in t:\n",
    "            inputs = batch_to_device(data, device)\n",
    "            targets = data['primary_targets'].to(device)\n",
    "\n",
    "            inputs['wave'] = taa_augmentation(inputs['wave'].unsqueeze(1))\n",
    "            inputs['wave'] = inputs['wave'].squeeze(1)\n",
    "\n",
    "            with autocast(enabled=CFG.apex):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs)\n",
    "\n",
    "            losses.update(loss.item(), inputs['wave'].size(0))\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), max_norm=CFG.max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scheduler.step(epoch + i / iters)\n",
    "            t.set_postfix(\n",
    "                loss=losses.avg,\n",
    "                grad=grad_norm.item(),\n",
    "                lr=optimizer.param_groups[0][\"lr\"]\n",
    "                )\n",
    "\n",
    "            gt.append(targets.cpu().detach().numpy())\n",
    "            preds.append(outputs[\"logit\"].sigmoid().cpu().detach().numpy())\n",
    "\n",
    "    val_df = pd.DataFrame(\n",
    "        np.concatenate(gt), columns=CFG.target_columns[:182])\n",
    "    pred_df = pd.DataFrame(\n",
    "        np.concatenate(preds), columns=CFG.target_columns[:182])\n",
    "    cmAP_1 = padded_cmap(val_df, pred_df, padding_factor=1)\n",
    "    cmAP_5 = padded_cmap(val_df, pred_df, padding_factor=5)\n",
    "    mAP = map_score(val_df, pred_df)\n",
    "\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "    # print(gt, preds.shape, target_columns)\n",
    "    gt = np.array(gt, dtype=np.int32)\n",
    "    scores = calculate_competition_metrics(gt, preds, target_columns)\n",
    "\n",
    "\n",
    "    return losses.avg, cmAP_1, cmAP_5, mAP, scores\n",
    "\n",
    "\n",
    "import sklearn\n",
    "\n",
    "\n",
    "def valid_fn(data_loader, model, criterion, epoch,col_index):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    gt = []\n",
    "    preds = []\n",
    "\n",
    "    with tqdm(enumerate(data_loader), total=len(data_loader)) as t:\n",
    "        for i, (data) in t:\n",
    "            inputs = batch_to_device(data, device)\n",
    "            targets = data['primary_targets'].to(device)\n",
    "\n",
    "            with autocast(enabled=CFG.apex):\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs)\n",
    "\n",
    "            losses.update(loss.item(), inputs['wave'].size(0))\n",
    "            t.set_postfix(loss=losses.avg)\n",
    "\n",
    "            gt.append(targets.cpu().detach().numpy())\n",
    "            preds.append(outputs[\"logit\"].sigmoid().cpu().detach().numpy())\n",
    "\n",
    "    val_df = pd.DataFrame(np.concatenate(gt), columns=CFG.target_columns[:182])\n",
    "    pred_df = pd.DataFrame(np.concatenate(preds), columns=CFG.target_columns[:182])\n",
    "    cmAP_1 = padded_cmap(val_df, pred_df, padding_factor=1)\n",
    "    cmAP_5 = padded_cmap(val_df, pred_df, padding_factor=5)\n",
    "    mAP = map_score(val_df, pred_df)\n",
    "\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    # print(gt, preds.shape, target_columns)\n",
    "    gt = np.array(gt, dtype=np.int32)\n",
    "    scores = calculate_competition_metrics(gt, preds, target_columns)\n",
    "\n",
    "    target_columns =  [id2bird[i] for i in col_index]\n",
    "    scores_cv = calculate_competition_metrics(gt[:,col_index], preds[:,col_index], target_columns)\n",
    "    \n",
    "\n",
    "    return losses.avg, cmAP_1, cmAP_5, mAP,scores,scores_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    criterion,\n",
    "    epochs=10,\n",
    "    fold=None,\n",
    "):\n",
    "\n",
    "    best_score = 0.0\n",
    "    patience = CFG.early_stopping\n",
    "    n_patience = 0\n",
    "\n",
    "    for epoch in range(epochs): \n",
    "        # train for one epoch\n",
    "        train_loss, train_cmAP1, train_cmAP5, train_mAP,train_scores = train_fn(\n",
    "            train_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_loss, val_cmAP1, val_cmAP5, val_mAP,scores = valid_fn(\n",
    "            val_loader, model, criterion, epoch,col_index)\n",
    "        \n",
    "        train_score = train_scores[\"ROC\"]\n",
    "        val_score = scores[\"ROC\"]\n",
    "        logger.info(f\"Epoch {epoch} - Train loss: {train_loss:.4f}, Train cmAP1: {train_cmAP1:.4f}, Train cmAP5: {train_cmAP5:.4f}, Train mAP: {train_mAP:.4f}, \\n Valid loss: {val_loss:.4f}, Valid cmAP1: {val_cmAP1:.4f}, Valid cmAP5: {val_cmAP5:.4f}, Valid mAP: {val_mAP:.4f}\")\n",
    "        logger.info(f\"\\n Epoch {epoch} - train metric {train_score} val metirc {val_score}\")\n",
    "\n",
    "\n",
    "        is_better = val_score > best_score\n",
    "        best_score = max(val_score, best_score)\n",
    "\n",
    "        # Save the best model\n",
    "        if is_better:\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"best_loss\": best_score,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                # \"macro-roc-auc\":scores[\"ROC\"]\n",
    "            }\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch} - Save Best Score: {best_score:.4f} Model\\n\")\n",
    "            torch.save(\n",
    "                state,\n",
    "                os.path.join(CFG.model_output_path, f\"fold_{fold}_model.bin\")\n",
    "                )\n",
    "            \n",
    "            # # 将模型转换为TorchScript\n",
    "            # scripted_model = torch.jit.script(model)\n",
    "            # # 保存序列化的模型\n",
    "            # torch.jit.save(scripted_model, f'jit_model/fold_{fold}_model.pt')\n",
    "\n",
    "            n_patience = 0\n",
    "        else:\n",
    "            n_patience += 1\n",
    "            logger.info(\n",
    "                f\"Valid loss didn't improve last {n_patience} epochs.\\n\")\n",
    "\n",
    "        if n_patience >= patience:\n",
    "            logger.info(\n",
    "                \"Early stop, Training End.\\n\")\n",
    "            break\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "logger = init_logger(log_file=f\"../log/train_{CFG.exp_name}.log\")\n",
    "device = get_device()\n",
    "set_seed(CFG.seed)\n",
    "os.makedirs(os.path.join(CFG.model_output_path), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.read_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main-20240518T060118Z-001/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main/train_folds_0518.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # a[\"filename\"] = a[\"filename\"].apply(lambda x: x.replace(\"../dataset\",\"\"))\n",
    "# a[\"filename\"] = a[\"filename\"].apply(lambda x: \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input\"+x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.to_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main-20240518T060118Z-001/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main/train_folds_0518.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttModel(\n",
    "        backbone=CFG.backbone,\n",
    "        num_class=CFG.num_classes,\n",
    "        train_period=CFG.period,\n",
    "        infer_period=5,\n",
    "    )\n",
    "# modelpath = \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main-20240518T060118Z-001/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main/models/exp071_tf_efficientnet_b0_ns/fold_0_model.bin\"\n",
    "# len(torch.load(modelpath)[\"state_dict\"].keys())\n",
    "\n",
    "#363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>filename</th>\n",
       "      <th>teacher_preds</th>\n",
       "      <th>teacher_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>64486.ogg</td>\n",
       "      <td>[ -6.8236113  -5.626453   -7.5165544  -9.73582...</td>\n",
       "      <td>grehor1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>2525.ogg</td>\n",
       "      <td>[ -7.176402   -9.332384   -8.316804  -10.27886...</td>\n",
       "      <td>zitcis1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>44981.ogg</td>\n",
       "      <td>[-4.0132084 -5.802989  -6.256181  -6.773272  -...</td>\n",
       "      <td>categr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>101323.ogg</td>\n",
       "      <td>[-6.338834  -5.7509503 -7.5665483 -9.063977  -...</td>\n",
       "      <td>comgre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>165746.ogg</td>\n",
       "      <td>[ -7.743705   -7.3720293  -9.064224  -10.81405...</td>\n",
       "      <td>eurcoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>5750</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>95027.ogg</td>\n",
       "      <td>[ -6.1317134  -7.55363    -6.77861    -8.95025...</td>\n",
       "      <td>purher1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>5751</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>80708.ogg</td>\n",
       "      <td>[ -6.922803    -7.7936735   -7.4676466  -10.89...</td>\n",
       "      <td>rocpig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5752</th>\n",
       "      <td>5752</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>168059.ogg</td>\n",
       "      <td>[ -6.418939   -8.418465   -7.230104   -9.64820...</td>\n",
       "      <td>commoo3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5753</th>\n",
       "      <td>5753</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>164922.ogg</td>\n",
       "      <td>[ -5.4923444  -6.9318366  -7.868212   -9.33819...</td>\n",
       "      <td>graher1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5754</th>\n",
       "      <td>5754</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>40565.ogg</td>\n",
       "      <td>[-4.572484  -5.977849  -7.350516  -7.777331  -...</td>\n",
       "      <td>rocpig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5755 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 primary_label secondary_labels    filename  \\\n",
       "0              0        nocall               []   64486.ogg   \n",
       "1              1        nocall               []    2525.ogg   \n",
       "2              2        nocall               []   44981.ogg   \n",
       "3              3        nocall               []  101323.ogg   \n",
       "4              4        nocall               []  165746.ogg   \n",
       "...          ...           ...              ...         ...   \n",
       "5750        5750        nocall               []   95027.ogg   \n",
       "5751        5751        nocall               []   80708.ogg   \n",
       "5752        5752        nocall               []  168059.ogg   \n",
       "5753        5753        nocall               []  164922.ogg   \n",
       "5754        5754        nocall               []   40565.ogg   \n",
       "\n",
       "                                          teacher_preds teacher_label  \n",
       "0     [ -6.8236113  -5.626453   -7.5165544  -9.73582...       grehor1  \n",
       "1     [ -7.176402   -9.332384   -8.316804  -10.27886...       zitcis1  \n",
       "2     [-4.0132084 -5.802989  -6.256181  -6.773272  -...        categr  \n",
       "3     [-6.338834  -5.7509503 -7.5665483 -9.063977  -...        comgre  \n",
       "4     [ -7.743705   -7.3720293  -9.064224  -10.81405...        eurcoo  \n",
       "...                                                 ...           ...  \n",
       "5750  [ -6.1317134  -7.55363    -6.77861    -8.95025...       purher1  \n",
       "5751  [ -6.922803    -7.7936735   -7.4676466  -10.89...        rocpig  \n",
       "5752  [ -6.418939   -8.418465   -7.230104   -9.64820...       commoo3  \n",
       "5753  [ -5.4923444  -6.9318366  -7.868212   -9.33819...       graher1  \n",
       "5754  [-4.572484  -5.977849  -7.350516  -7.777331  -...        rocpig  \n",
       "\n",
       "[5755 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external = pd.read_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/Train mnasnet/nocall_pseudo.csv\")\n",
    "external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "external = pd.read_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/Train mnasnet/nocall_pseudo.csv\")\n",
    "external[\"filename\"] = external[\"filename\"].apply(lambda x: \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/nocall_archive/ff1010bird_nocall/nocall\"+x)\n",
    "# external[\"type\"] = '[]'\n",
    "external[\"kfold\"] = -1\n",
    "external[\"rating\"] = 1\n",
    "select_cols = ['filename', 'primary_label','secondary_labels','kfold', 'rating',\"teacher_preds\"]\n",
    "# external[\"filename\"] = '../input/birdclef-2023/train_audio/' + 'nocall/' + external['filename']\n",
    "# del external['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_array2np(s):\n",
    "    # 去除字符串两端的方括号和换行符，并按空格分割  \n",
    "    numbers_str = s.strip('[]\\n').split()  \n",
    "    # 将字符串列表转换为浮点数列表  \n",
    "    numbers_float = [float(n) for n in numbers_str]  \n",
    "    # 将浮点数列表转换为NumPy数组  \n",
    "    numbers_array = np.array(numbers_float)  \n",
    "\n",
    "    return numbers_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(54310, 6)\n",
      "==========================================================================================\n",
      "Fold 0 Training\n",
      "==========================================================================================\n",
      "(44599, 6)\n",
      "primary_label\n",
      "nocall     5755\n",
      "houspa     2078\n",
      "eaywag1    1977\n",
      "commoo3    1766\n",
      "eurcoo     1701\n",
      "           ... \n",
      "blaeag1       9\n",
      "integr        8\n",
      "wbbfly1       7\n",
      "niwpig1       6\n",
      "asiope1       5\n",
      "Name: count, Length: 183, dtype: int64\n",
      "(9711, 6)\n",
      "primary_label\n",
      "houspa     520\n",
      "eaywag1    494\n",
      "commoo3    441\n",
      "eurcoo     426\n",
      "barswa     345\n",
      "          ... \n",
      "niwpig1      2\n",
      "asiope1      2\n",
      "blaeag1      2\n",
      "wbbfly1      2\n",
      "malwoo1      2\n",
      "Name: count, Length: 182, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5755, 7)\n",
      "the length of parameters is 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 696/696 [01:30<00:00,  7.73it/s, grad=0.0182, loss=0.0856, lr=0.000999]\n",
      "100%|██████████| 152/152 [00:54<00:00,  2.78it/s, loss=0.0124]\n",
      "Epoch 0 - Train loss: 0.0856, Train cmAP1: 0.0702, Train cmAP5: 0.0910, Train mAP: 0.0577, \n",
      " Valid loss: 0.0124, Valid cmAP1: 0.7426, Valid cmAP5: 0.8176, Valid mAP: 0.8228\n",
      "\n",
      " Epoch 0 - train metric 0.7213252864457123 val metirc 0.969718827117269\n",
      "Epoch 0 - Save Best Score: 0.9697 Model\n",
      "\n",
      "100%|██████████| 696/696 [01:25<00:00,  8.15it/s, grad=0.0157, loss=0.0168, lr=0.000905]\n",
      "100%|██████████| 152/152 [00:54<00:00,  2.81it/s, loss=0.012] \n",
      "Epoch 1 - Train loss: 0.0168, Train cmAP1: 0.3286, Train cmAP5: 0.3514, Train mAP: 0.3154, \n",
      " Valid loss: 0.0120, Valid cmAP1: 0.7418, Valid cmAP5: 0.8184, Valid mAP: 0.8243\n",
      "\n",
      " Epoch 1 - train metric 0.8447800862522313 val metirc 0.9732892060784089\n",
      "Epoch 1 - Save Best Score: 0.9733 Model\n",
      "\n",
      "100%|██████████| 696/696 [01:44<00:00,  6.65it/s, grad=0.0192, loss=0.0162, lr=0.000794]\n",
      "100%|██████████| 152/152 [00:50<00:00,  3.03it/s, loss=0.012] \n",
      "Epoch 2 - Train loss: 0.0162, Train cmAP1: 0.3303, Train cmAP5: 0.3533, Train mAP: 0.3173, \n",
      " Valid loss: 0.0120, Valid cmAP1: 0.7383, Valid cmAP5: 0.8185, Valid mAP: 0.8243\n",
      "\n",
      " Epoch 2 - train metric 0.851772001878473 val metirc 0.9744766292291234\n",
      "Epoch 2 - Save Best Score: 0.9745 Model\n",
      "\n",
      "100%|██████████| 696/696 [01:49<00:00,  6.34it/s, grad=0.0147, loss=0.0158, lr=0.000655] \n",
      "100%|██████████| 152/152 [00:55<00:00,  2.76it/s, loss=0.0117]\n",
      "Epoch 3 - Train loss: 0.0158, Train cmAP1: 0.3450, Train cmAP5: 0.3676, Train mAP: 0.3317, \n",
      " Valid loss: 0.0117, Valid cmAP1: 0.7453, Valid cmAP5: 0.8220, Valid mAP: 0.8348\n",
      "\n",
      " Epoch 3 - train metric 0.8608755002758773 val metirc 0.9735650385217126\n",
      "Valid loss didn't improve last 1 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [02:02<00:00,  5.70it/s, grad=0.0132, loss=0.0154, lr=0.0005]   \n",
      "100%|██████████| 152/152 [00:58<00:00,  2.59it/s, loss=0.0113]\n",
      "Epoch 4 - Train loss: 0.0154, Train cmAP1: 0.3497, Train cmAP5: 0.3723, Train mAP: 0.3371, \n",
      " Valid loss: 0.0113, Valid cmAP1: 0.7468, Valid cmAP5: 0.8248, Valid mAP: 0.8442\n",
      "\n",
      " Epoch 4 - train metric 0.8653380457363723 val metirc 0.9731785909580324\n",
      "Valid loss didn't improve last 2 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:42<00:00,  6.78it/s, grad=0.0119, loss=0.0151, lr=0.000346] \n",
      "100%|██████████| 152/152 [00:52<00:00,  2.88it/s, loss=0.0111]\n",
      "Epoch 5 - Train loss: 0.0151, Train cmAP1: 0.3541, Train cmAP5: 0.3767, Train mAP: 0.3412, \n",
      " Valid loss: 0.0111, Valid cmAP1: 0.7560, Valid cmAP5: 0.8304, Valid mAP: 0.8459\n",
      "\n",
      " Epoch 5 - train metric 0.8688619161159506 val metirc 0.9736905564021092\n",
      "Valid loss didn't improve last 3 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:45<00:00,  6.59it/s, grad=0.0143, loss=0.0148, lr=0.000206] \n",
      "100%|██████████| 152/152 [00:52<00:00,  2.88it/s, loss=0.0109]\n",
      "Epoch 6 - Train loss: 0.0148, Train cmAP1: 0.3602, Train cmAP5: 0.3827, Train mAP: 0.3466, \n",
      " Valid loss: 0.0109, Valid cmAP1: 0.7586, Valid cmAP5: 0.8342, Valid mAP: 0.8566\n",
      "\n",
      " Epoch 6 - train metric 0.8759541491790439 val metirc 0.9743466639660346\n",
      "Valid loss didn't improve last 4 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:26<00:00,  8.06it/s, grad=0.0101, loss=0.0144, lr=9.57e-5]  \n",
      "100%|██████████| 152/152 [00:51<00:00,  2.98it/s, loss=0.0106]\n",
      "Epoch 7 - Train loss: 0.0144, Train cmAP1: 0.3658, Train cmAP5: 0.3881, Train mAP: 0.3533, \n",
      " Valid loss: 0.0106, Valid cmAP1: 0.7666, Valid cmAP5: 0.8393, Valid mAP: 0.8630\n",
      "\n",
      " Epoch 7 - train metric 0.8789195197650885 val metirc 0.974922281762951\n",
      "Epoch 7 - Save Best Score: 0.9749 Model\n",
      "\n",
      "100%|██████████| 696/696 [01:35<00:00,  7.32it/s, grad=0.0106, loss=0.0144, lr=2.46e-5] \n",
      "100%|██████████| 152/152 [00:51<00:00,  2.94it/s, loss=0.0106]\n",
      "Epoch 8 - Train loss: 0.0144, Train cmAP1: 0.3697, Train cmAP5: 0.3922, Train mAP: 0.3574, \n",
      " Valid loss: 0.0106, Valid cmAP1: 0.7665, Valid cmAP5: 0.8395, Valid mAP: 0.8633\n",
      "\n",
      " Epoch 8 - train metric 0.8807045588995098 val metirc 0.9753730832676352\n",
      "Epoch 8 - Save Best Score: 0.9754 Model\n",
      "\n",
      "100%|██████████| 696/696 [01:35<00:00,  7.28it/s, grad=0.0101, loss=0.0142, lr=1e-7]    \n",
      "100%|██████████| 152/152 [00:52<00:00,  2.90it/s, loss=0.0106]\n",
      "Epoch 9 - Train loss: 0.0142, Train cmAP1: 0.3717, Train cmAP5: 0.3943, Train mAP: 0.3585, \n",
      " Valid loss: 0.0106, Valid cmAP1: 0.7674, Valid cmAP5: 0.8402, Valid mAP: 0.8635\n",
      "\n",
      " Epoch 9 - train metric 0.881691598411633 val metirc 0.9756121561618811\n",
      "Epoch 9 - Save Best Score: 0.9756 Model\n",
      "\n",
      "100%|██████████| 696/696 [01:34<00:00,  7.38it/s, grad=0.0121, loss=0.0165, lr=0.000976] \n",
      "100%|██████████| 152/152 [00:51<00:00,  2.98it/s, loss=0.0125]\n",
      "Epoch 10 - Train loss: 0.0165, Train cmAP1: 0.3354, Train cmAP5: 0.3584, Train mAP: 0.3222, \n",
      " Valid loss: 0.0125, Valid cmAP1: 0.7249, Valid cmAP5: 0.8073, Valid mAP: 0.8143\n",
      "\n",
      " Epoch 10 - train metric 0.8602332840966684 val metirc 0.9709633478315003\n",
      "Valid loss didn't improve last 1 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:35<00:00,  7.28it/s, grad=0.012, loss=0.016, lr=0.000905]   \n",
      "100%|██████████| 152/152 [00:54<00:00,  2.77it/s, loss=0.0122]\n",
      "Epoch 11 - Train loss: 0.0160, Train cmAP1: 0.3407, Train cmAP5: 0.3636, Train mAP: 0.3275, \n",
      " Valid loss: 0.0122, Valid cmAP1: 0.7268, Valid cmAP5: 0.8094, Valid mAP: 0.8189\n",
      "\n",
      " Epoch 11 - train metric 0.8612458751109846 val metirc 0.9648992019719946\n",
      "Valid loss didn't improve last 2 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:36<00:00,  7.24it/s, grad=0.00835, loss=0.0156, lr=0.000794]\n",
      "100%|██████████| 152/152 [00:53<00:00,  2.82it/s, loss=0.0117]\n",
      "Epoch 12 - Train loss: 0.0156, Train cmAP1: 0.3506, Train cmAP5: 0.3732, Train mAP: 0.3374, \n",
      " Valid loss: 0.0117, Valid cmAP1: 0.7391, Valid cmAP5: 0.8188, Valid mAP: 0.8338\n",
      "\n",
      " Epoch 12 - train metric 0.8671574523115314 val metirc 0.9724050060487187\n",
      "Valid loss didn't improve last 3 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [02:34<00:00,  4.52it/s, grad=0.00949, loss=0.0151, lr=0.000655]\n",
      "100%|██████████| 152/152 [00:42<00:00,  3.55it/s, loss=0.0114]\n",
      "Epoch 13 - Train loss: 0.0151, Train cmAP1: 0.3523, Train cmAP5: 0.3750, Train mAP: 0.3391, \n",
      " Valid loss: 0.0114, Valid cmAP1: 0.7467, Valid cmAP5: 0.8238, Valid mAP: 0.8421\n",
      "\n",
      " Epoch 13 - train metric 0.8700156449030115 val metirc 0.9718258794476712\n",
      "Valid loss didn't improve last 4 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [02:35<00:00,  4.47it/s, grad=0.00738, loss=0.0148, lr=0.0005]  \n",
      "100%|██████████| 152/152 [01:50<00:00,  1.37it/s, loss=0.0111]\n",
      "Epoch 14 - Train loss: 0.0148, Train cmAP1: 0.3646, Train cmAP5: 0.3873, Train mAP: 0.3519, \n",
      " Valid loss: 0.0111, Valid cmAP1: 0.7609, Valid cmAP5: 0.8338, Valid mAP: 0.8518\n",
      "\n",
      " Epoch 14 - train metric 0.8786202342968703 val metirc 0.9712407906063767\n",
      "Valid loss didn't improve last 5 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [02:09<00:00,  5.36it/s, grad=0.0077, loss=0.0145, lr=0.000346] \n",
      "100%|██████████| 152/152 [01:14<00:00,  2.03it/s, loss=0.011] \n",
      "Epoch 15 - Train loss: 0.0145, Train cmAP1: 0.3690, Train cmAP5: 0.3915, Train mAP: 0.3558, \n",
      " Valid loss: 0.0110, Valid cmAP1: 0.7555, Valid cmAP5: 0.8307, Valid mAP: 0.8484\n",
      "\n",
      " Epoch 15 - train metric 0.8826858414592214 val metirc 0.9685171326166727\n",
      "Valid loss didn't improve last 6 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:58<00:00,  5.90it/s, grad=0.0086, loss=0.0142, lr=0.000206] \n",
      "100%|██████████| 152/152 [01:27<00:00,  1.74it/s, loss=0.0108]\n",
      "Epoch 16 - Train loss: 0.0142, Train cmAP1: 0.3701, Train cmAP5: 0.3927, Train mAP: 0.3576, \n",
      " Valid loss: 0.0108, Valid cmAP1: 0.7605, Valid cmAP5: 0.8342, Valid mAP: 0.8576\n",
      "\n",
      " Epoch 16 - train metric 0.8873763646377806 val metirc 0.9727338132991717\n",
      "Valid loss didn't improve last 7 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [02:49<00:00,  4.10it/s, grad=0.00893, loss=0.014, lr=9.57e-5]  \n",
      "100%|██████████| 152/152 [01:47<00:00,  1.41it/s, loss=0.0106]\n",
      "Epoch 17 - Train loss: 0.0140, Train cmAP1: 0.3808, Train cmAP5: 0.4032, Train mAP: 0.3683, \n",
      " Valid loss: 0.0106, Valid cmAP1: 0.7646, Valid cmAP5: 0.8374, Valid mAP: 0.8608\n",
      "\n",
      " Epoch 17 - train metric 0.8915019017158791 val metirc 0.9727950547602991\n",
      "Valid loss didn't improve last 8 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [03:45<00:00,  3.09it/s, grad=0.00717, loss=0.0138, lr=2.46e-5]\n",
      "100%|██████████| 152/152 [01:18<00:00,  1.94it/s, loss=0.0106]\n",
      "Epoch 18 - Train loss: 0.0138, Train cmAP1: 0.3768, Train cmAP5: 0.3995, Train mAP: 0.3649, \n",
      " Valid loss: 0.0106, Valid cmAP1: 0.7664, Valid cmAP5: 0.8390, Valid mAP: 0.8629\n",
      "\n",
      " Epoch 18 - train metric 0.8909468603482535 val metirc 0.9732107286427109\n",
      "Valid loss didn't improve last 9 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:46<00:00,  6.56it/s, grad=0.0104, loss=0.0138, lr=1e-7]    \n",
      "100%|██████████| 152/152 [01:19<00:00,  1.91it/s, loss=0.0105]\n",
      "Epoch 19 - Train loss: 0.0138, Train cmAP1: 0.3863, Train cmAP5: 0.4084, Train mAP: 0.3736, \n",
      " Valid loss: 0.0105, Valid cmAP1: 0.7677, Valid cmAP5: 0.8400, Valid mAP: 0.8642\n",
      "\n",
      " Epoch 19 - train metric 0.8938166526549642 val metirc 0.9742132901410189\n",
      "Valid loss didn't improve last 10 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:56<00:00,  5.98it/s, grad=0.0097, loss=0.0155, lr=0.000976] \n",
      "100%|██████████| 152/152 [01:21<00:00,  1.87it/s, loss=0.0124]\n",
      "Epoch 20 - Train loss: 0.0155, Train cmAP1: 0.3513, Train cmAP5: 0.3742, Train mAP: 0.3395, \n",
      " Valid loss: 0.0124, Valid cmAP1: 0.7282, Valid cmAP5: 0.8099, Valid mAP: 0.8141\n",
      "\n",
      " Epoch 20 - train metric 0.8751131667976759 val metirc 0.9675669276654258\n",
      "Valid loss didn't improve last 11 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:41<00:00,  6.83it/s, grad=0.00857, loss=0.0154, lr=0.000905]\n",
      "100%|██████████| 152/152 [00:59<00:00,  2.56it/s, loss=0.012] \n",
      "Epoch 21 - Train loss: 0.0154, Train cmAP1: 0.3542, Train cmAP5: 0.3770, Train mAP: 0.3419, \n",
      " Valid loss: 0.0120, Valid cmAP1: 0.7318, Valid cmAP5: 0.8119, Valid mAP: 0.8294\n",
      "\n",
      " Epoch 21 - train metric 0.8739741413007743 val metirc 0.9673435751845001\n",
      "Valid loss didn't improve last 12 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:43<00:00,  6.72it/s, grad=0.00798, loss=0.0151, lr=0.000794]\n",
      "100%|██████████| 152/152 [00:52<00:00,  2.87it/s, loss=0.0116]\n",
      "Epoch 22 - Train loss: 0.0151, Train cmAP1: 0.3564, Train cmAP5: 0.3792, Train mAP: 0.3431, \n",
      " Valid loss: 0.0116, Valid cmAP1: 0.7401, Valid cmAP5: 0.8198, Valid mAP: 0.8372\n",
      "\n",
      " Epoch 22 - train metric 0.8769728032260024 val metirc 0.9684753099982224\n",
      "Valid loss didn't improve last 13 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:43<00:00,  6.69it/s, grad=0.00758, loss=0.0147, lr=0.000655]\n",
      "100%|██████████| 152/152 [00:57<00:00,  2.64it/s, loss=0.0114]\n",
      "Epoch 23 - Train loss: 0.0147, Train cmAP1: 0.3644, Train cmAP5: 0.3870, Train mAP: 0.3518, \n",
      " Valid loss: 0.0114, Valid cmAP1: 0.7553, Valid cmAP5: 0.8293, Valid mAP: 0.8442\n",
      "\n",
      " Epoch 23 - train metric 0.8818296287195391 val metirc 0.9700282463151436\n",
      "Valid loss didn't improve last 14 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:43<00:00,  6.75it/s, grad=0.00685, loss=0.0144, lr=0.0005]  \n",
      "100%|██████████| 152/152 [01:00<00:00,  2.53it/s, loss=0.0111]\n",
      "Epoch 24 - Train loss: 0.0144, Train cmAP1: 0.3682, Train cmAP5: 0.3910, Train mAP: 0.3551, \n",
      " Valid loss: 0.0111, Valid cmAP1: 0.7522, Valid cmAP5: 0.8287, Valid mAP: 0.8515\n",
      "\n",
      " Epoch 24 - train metric 0.8852335435382792 val metirc 0.9715092650215009\n",
      "Valid loss didn't improve last 15 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:45<00:00,  6.57it/s, grad=0.00708, loss=0.014, lr=0.000346] \n",
      "100%|██████████| 152/152 [00:53<00:00,  2.83it/s, loss=0.0109]\n",
      "Epoch 25 - Train loss: 0.0140, Train cmAP1: 0.3731, Train cmAP5: 0.3957, Train mAP: 0.3595, \n",
      " Valid loss: 0.0109, Valid cmAP1: 0.7567, Valid cmAP5: 0.8324, Valid mAP: 0.8548\n",
      "\n",
      " Epoch 25 - train metric 0.8890792502935283 val metirc 0.973438663068156\n",
      "Valid loss didn't improve last 16 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:38<00:00,  7.05it/s, grad=0.00815, loss=0.0138, lr=0.000206]\n",
      "100%|██████████| 152/152 [00:56<00:00,  2.71it/s, loss=0.0107]\n",
      "Epoch 26 - Train loss: 0.0138, Train cmAP1: 0.3742, Train cmAP5: 0.3969, Train mAP: 0.3614, \n",
      " Valid loss: 0.0107, Valid cmAP1: 0.7566, Valid cmAP5: 0.8330, Valid mAP: 0.8580\n",
      "\n",
      " Epoch 26 - train metric 0.8927436866598013 val metirc 0.970171277882656\n",
      "Valid loss didn't improve last 17 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [02:04<00:00,  5.58it/s, grad=0.00624, loss=0.0136, lr=9.57e-5] \n",
      "100%|██████████| 152/152 [00:55<00:00,  2.72it/s, loss=0.0105]\n",
      "Epoch 27 - Train loss: 0.0136, Train cmAP1: 0.3874, Train cmAP5: 0.4098, Train mAP: 0.3747, \n",
      " Valid loss: 0.0105, Valid cmAP1: 0.7603, Valid cmAP5: 0.8360, Valid mAP: 0.8633\n",
      "\n",
      " Epoch 27 - train metric 0.8982731391947041 val metirc 0.9706751381565896\n",
      "Valid loss didn't improve last 18 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:39<00:00,  7.03it/s, grad=0.00601, loss=0.0135, lr=2.46e-5]\n",
      "100%|██████████| 152/152 [00:54<00:00,  2.79it/s, loss=0.0105]\n",
      "Epoch 28 - Train loss: 0.0135, Train cmAP1: 0.3856, Train cmAP5: 0.4079, Train mAP: 0.3735, \n",
      " Valid loss: 0.0105, Valid cmAP1: 0.7638, Valid cmAP5: 0.8380, Valid mAP: 0.8656\n",
      "\n",
      " Epoch 28 - train metric 0.8980897807096462 val metirc 0.970090547788721\n",
      "Valid loss didn't improve last 19 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:38<00:00,  7.05it/s, grad=0.00551, loss=0.0134, lr=1e-7]   \n",
      "100%|██████████| 152/152 [01:04<00:00,  2.34it/s, loss=0.0105]\n",
      "Epoch 29 - Train loss: 0.0134, Train cmAP1: 0.3864, Train cmAP5: 0.4087, Train mAP: 0.3731, \n",
      " Valid loss: 0.0105, Valid cmAP1: 0.7634, Valid cmAP5: 0.8378, Valid mAP: 0.8665\n",
      "\n",
      " Epoch 29 - train metric 0.8996141988708735 val metirc 0.9705651902545872\n",
      "Valid loss didn't improve last 20 epochs.\n",
      "\n",
      "Early stop, Training End.\n",
      "\n",
      "training done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# with open(TRAIN_DATA_PATH + 'train_meta_pseudo.pickle', 'rb') as f:\n",
    "#     train = pickle.load(f)\n",
    "# train['filename'] = '../input/birdclef-2023/train_audio/' + train['filename']\n",
    "## 无teacher 训练\n",
    "# train = pd.read_csv(\"../train_folds_0518.csv\")\n",
    "train = pd.read_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/Train mnasnet/trainfold_0518_pseudo.csv\")\n",
    "train['rating'] = 1\n",
    "train[\"teacher_preds\"] = train[train[\"kfold\"]!=-1][\"teacher_preds\"].apply(lambda x :str_array2np(x))\n",
    "# with open('../input/xeno-canto_audio_meta_pseudo.pickle', 'rb') as f:\n",
    "#     xeno_canto_sa = pickle.load(f)\n",
    "# xeno_canto_sa[\"fold\"] = -1\n",
    "# train = pd.concat([train, xeno_canto_sa]).reset_index(drop=True)\n",
    "\n",
    "# with open('../input/xeno-canto_nd_audio_meta_pseudo.pickle', 'rb') as f:\n",
    "#     xeno_canto_nd = pickle.load(f)\n",
    "# train = pd.concat([train, xeno_canto_nd]).reset_index(drop=True)\n",
    "\n",
    "if CFG.external:\n",
    "    # with open('/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/ff1010bird_metadata_v1_pseudo.pickle', 'rb') as f:\n",
    "    #     external = pickle.load(f)\n",
    "    external = pd.read_pickle(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/ff1010bird_metadata_v1_pseudo.pickle\")\n",
    "    # external = pd.read_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/Train mnasnet/nocall_pseudo.csv\")\n",
    "    external[\"filename\"] = external[\"filename\"].apply(lambda x: \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/nocall_archive/ff1010bird_nocall/nocall\"+x)\n",
    "    # external[\"type\"] = '[]'\n",
    "    external[\"kfold\"] = -1\n",
    "    external[\"rating\"] = 1\n",
    "    select_cols = ['filename', 'primary_label','secondary_labels','kfold', 'rating',\"teacher_preds\"]\n",
    "    # del external['length']\n",
    "    \n",
    "    print(external.shape)\n",
    "    external.head()\n",
    "    train[\"filename\"] = train[\"path\"]\n",
    "    train = pd.concat([train[select_cols], external[select_cols]]).reset_index(drop=True)\n",
    "\n",
    "# train[\"rating\"] = np.clip(train[\"rating\"] / train[\"rating\"].max(), 0.1, 1.0)\n",
    "\n",
    "logger.info(train.shape)\n",
    "train.head()\n",
    "\n",
    "# main loop\n",
    "for fold in range(5):\n",
    "\n",
    "    if fold not in CFG.folds:\n",
    "        continue\n",
    "    logger.info(\"=\" * 90)\n",
    "    logger.info(f\"Fold {fold} Training\")\n",
    "    logger.info(\"=\" * 90)\n",
    "\n",
    "    trn_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    val_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    sampler = None\n",
    "    if CFG.use_sampler:\n",
    "        one_hot_target = np.zeros(\n",
    "            (trn_df.shape[0], len(CFG.target_columns)), dtype=np.float32\n",
    "            )\n",
    "\n",
    "        for i, label in enumerate(trn_df.primary_label):\n",
    "            if label != \"nocall\":\n",
    "                primary_label = CFG.bird2id[label]\n",
    "                one_hot_target[i, primary_label] = 1.0\n",
    "\n",
    "        sampler = MultilabelBalancedRandomSampler(\n",
    "            one_hot_target,\n",
    "            trn_df.index,\n",
    "            class_choice=\"least_sampled\"\n",
    "            )\n",
    "\n",
    "    logger.info(trn_df.shape)\n",
    "    logger.info(trn_df['primary_label'].value_counts())\n",
    "    logger.info(val_df.shape)\n",
    "    logger.info(val_df['primary_label'].value_counts())\n",
    "\n",
    "    loaders = {}\n",
    "    trn_dataset = BirdClef2023Dataset(\n",
    "            data_path=CFG.train_datadir,\n",
    "            period=CFG.period,\n",
    "            secondary_coef=CFG.secondary_coef,\n",
    "            train=True,\n",
    "            df=trn_df,\n",
    "    )\n",
    "    loaders['train'] = torchdata.DataLoader(\n",
    "        trn_dataset,\n",
    "        sampler=sampler,\n",
    "        **CFG.loader_params['train']\n",
    "    )\n",
    "    val_dataset = BirdClef2023Dataset(\n",
    "            data_path=CFG.train_datadir,\n",
    "            period=5,\n",
    "            secondary_coef=CFG.secondary_coef,\n",
    "            train=False,\n",
    "            df=val_df,\n",
    "    )\n",
    "    loaders['valid'] = torchdata.DataLoader(\n",
    "        val_dataset,\n",
    "        **CFG.loader_params['valid']\n",
    "    )\n",
    "\n",
    "    model = AttModel(\n",
    "        backbone=CFG.backbone,\n",
    "        num_class=CFG.num_classes,\n",
    "        train_period=CFG.period,\n",
    "        infer_period=5,\n",
    "    )\n",
    "\n",
    "    if CFG.pretrained_weights:\n",
    "        model_path = CFG.pretrained_path\n",
    "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "        del checkpoint['state_dict']['head.weight']\n",
    "        del checkpoint['state_dict']['head.bias']\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
    "\n",
    "        params = list(model.parameters())\n",
    "        print('the length of parameters is', len(params))\n",
    "        for i in range(len(params)):\n",
    "            params[i].data = torch.round(params[i].data*10**17) / 10**17\n",
    "        del checkpoint\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # del xeno_canto_sa, xeno_canto_nd, external\n",
    "    gc.collect()\n",
    "\n",
    "    # criterion = BCEKDLoss()\n",
    "    criterion = FocalLossBCE()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CFG.lr_max,\n",
    "        betas=(0.9, 0.999),\n",
    "        eps=1e-08,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "        amsgrad=False,\n",
    "        )\n",
    "    scheduler = CosineLRScheduler(\n",
    "        optimizer,\n",
    "        t_initial=10,\n",
    "        warmup_t=1,\n",
    "        cycle_limit=40,\n",
    "        cycle_decay=1.0,\n",
    "        lr_min=CFG.lr_min,\n",
    "        t_in_epochs=True,\n",
    "    )\n",
    "\n",
    "    # start training\n",
    "    train_loop(\n",
    "        loaders['train'],\n",
    "        loaders['valid'],\n",
    "        model,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        criterion,\n",
    "        epochs=CFG.epochs,\n",
    "        fold=fold,\n",
    "        )\n",
    "\n",
    "logger.info('training done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.3632386, -6.221536 , -5.1751814, -6.8329625, -5.520384 ,\n",
       "       -8.106002 , -6.291426 , -6.7113867, -5.6586127, -4.2065187,\n",
       "       -5.577632 , -7.779959 , -6.7608037, -6.14487  , -6.1412306,\n",
       "       -5.894186 , -8.003578 , -4.298207 , -4.67443  , -5.2208414,\n",
       "       -3.7749233, -6.8253655, -6.660148 , -6.213027 , -5.4677286,\n",
       "       -7.8196154, -7.110083 , -5.468467 , -5.6851654, -6.8851123,\n",
       "       -6.9113493, -6.502802 , -5.0228243, -7.3172398, -7.6176114,\n",
       "       -6.912636 , -6.88361  , -5.577966 , -5.2653103, -2.5930033,\n",
       "       -4.478192 , -3.698809 , -6.9878225, -4.5013027, -4.5943346,\n",
       "       -5.836675 , -5.708394 , -4.4435215, -4.9604793, -7.8057895,\n",
       "       -5.3005514, -6.7376738, -7.9047747, -3.5978856, -6.7750597,\n",
       "       -4.302254 , -6.631811 , -4.206804 , -4.163726 , -7.1966066,\n",
       "       -7.090315 , -6.7487826, -4.3251696, -4.581149 , -5.4554977,\n",
       "       -6.8678255, -7.224822 , -8.301522 , -6.623717 , -7.6582403,\n",
       "       -2.338531 , -4.30272  , -4.5604377, -4.845799 , -7.1887016,\n",
       "       -8.862705 , -3.2524076, -4.041116 , -4.1466227, -6.881083 ,\n",
       "       -2.906984 , -4.463889 , -2.9861557, -3.4451406, -6.4615607,\n",
       "       -5.2216625, -6.2954574, -5.785323 , -5.0655665, -8.013876 ,\n",
       "       -5.375334 , -7.488642 , -8.099727 , -6.5925136, -5.031426 ,\n",
       "       -6.346943 , -6.4165683, -7.5434866, -6.946772 , -7.591982 ,\n",
       "       -4.940704 , -6.5564427, -4.4598913, -6.770929 , -6.5046434,\n",
       "       -4.734524 , -5.6174545, -4.5677595, -7.6147428, -3.989874 ,\n",
       "       -5.168256 , -7.974462 , -6.5574493, -7.0457754, -7.5637765,\n",
       "       -7.3211975, -5.9944053, -5.721045 , -6.930991 , -7.824651 ,\n",
       "       -5.1253424, -6.9098463, -5.659452 , -4.3569465, -7.7196302,\n",
       "       -6.027027 , -5.1439447, -8.133122 , -5.844718 , -4.9844503,\n",
       "       -5.8025937, -8.332817 , -5.6594095, -3.9955692, -4.011402 ,\n",
       "       -7.6951575, -5.9040904, -7.3785076, -4.6164856, -5.1031904,\n",
       "       -5.0984435, -6.4627957, -4.8602033, -3.4157014, -5.88211  ,\n",
       "       -6.1481953, -5.121453 , -6.4138646, -6.745225 , -6.9761295,\n",
       "       -6.559571 , -5.468393 , -4.7219377, -6.0845623, -4.2191296,\n",
       "       -5.4755087, -6.3228836, -5.6386237, -6.829583 , -6.844731 ,\n",
       "       -6.366638 , -3.740824 , -7.3801165, -5.034655 , -4.1622577,\n",
       "       -6.660316 , -4.39408  , -6.4285636, -6.304561 , -7.3765664,\n",
       "       -5.0863943, -6.494514 , -5.7940497, -6.2611957, -4.608425 ,\n",
       "       -5.0870757, -5.222311 , -5.892075 , -7.0648546, -5.0167236,\n",
       "       -7.377232 , -3.5710976])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"kfold\"]==0][\"teacher_preds\"].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12.8047085,  -9.238798 ,  -9.28768  , -12.805975 , -13.4300995,\n",
       "       -12.065721 , -11.905288 , -15.5233555, -11.37521  , -10.584167 ,\n",
       "        -7.880215 , -11.568201 ,  -8.751513 , -10.0683975, -10.57903  ,\n",
       "       -15.038082 ,  -9.928907 , -10.742993 , -13.881045 , -13.013288 ,\n",
       "        -7.819019 ,  -8.921952 , -15.999883 ,  -8.188779 , -14.371161 ,\n",
       "        -9.523504 , -13.702866 , -13.303877 , -11.960668 ,  -8.356654 ,\n",
       "        -9.913391 ,  -9.508785 , -12.31569  , -11.566313 , -12.6911125,\n",
       "       -14.268026 , -12.118282 , -12.02198  , -10.839478 , -13.68715  ,\n",
       "       -13.477827 , -14.657263 , -12.701844 , -13.337585 , -16.851261 ,\n",
       "       -12.766783 , -13.6003   , -11.453594 , -13.125055 , -13.31653  ,\n",
       "       -12.183271 , -13.693626 , -13.461819 , -12.994865 , -12.466036 ,\n",
       "       -10.318794 , -10.683501 , -11.121885 , -12.346202 , -14.208176 ,\n",
       "        -9.299595 , -10.820049 ,  -9.307911 , -14.914533 , -16.925846 ,\n",
       "       -13.67597  , -10.911665 , -13.121988 , -12.529295 , -11.190372 ,\n",
       "        -7.5698004, -10.62282  ,  -9.298837 ,  -8.133299 ,  -6.4128532,\n",
       "       -13.53796  , -13.160877 , -11.502119 , -14.206073 , -12.314963 ,\n",
       "       -11.391237 , -12.764768 , -11.593595 , -14.674626 ,  -7.981865 ,\n",
       "       -16.91507  ,  -9.052089 , -14.52379  ,  -8.817419 ,  -7.7415934,\n",
       "       -11.184189 , -14.378695 , -12.088062 , -13.806974 , -12.650047 ,\n",
       "       -10.766706 , -10.1239395,  -9.235853 , -13.836265 ,  -9.945637 ,\n",
       "       -14.785673 , -14.283558 , -14.241165 , -10.514246 , -11.699988 ,\n",
       "        -9.130289 ,  -7.611085 , -10.68689  , -14.018327 , -13.215179 ,\n",
       "       -12.600748 , -12.436119 , -12.355576 , -10.305991 , -10.617514 ,\n",
       "       -10.871487 , -10.477991 , -12.354311 , -11.284642 ,  -9.71211  ,\n",
       "       -13.105058 , -11.10367  , -17.451464 ,  -5.7403913, -12.619661 ,\n",
       "       -12.14086  , -12.299892 , -12.917433 , -11.289308 , -12.266068 ,\n",
       "        -7.5740123, -12.397028 , -12.81863  , -10.716975 , -10.222342 ,\n",
       "        -7.297015 , -12.071555 , -10.860855 , -13.43898  , -13.586248 ,\n",
       "       -13.683441 , -12.879845 , -12.999074 , -13.806944 , -13.847975 ,\n",
       "       -12.346544 , -11.4508295, -14.788992 , -14.017729 , -11.301432 ,\n",
       "       -13.291463 , -12.904567 , -12.877579 , -12.889097 , -12.459148 ,\n",
       "       -12.311299 , -11.19447  , -12.277795 , -14.129635 , -12.933514 ,\n",
       "       -15.342884 , -10.131882 , -11.768271 , -12.251961 , -11.951565 ,\n",
       "       -13.813395 , -13.806974 , -10.083685 , -13.147861 , -10.360656 ,\n",
       "        -9.074453 , -11.198397 , -11.753225 , -10.527061 ,  -9.410559 ,\n",
       "        -9.289347 , -11.493616 , -11.611998 , -10.585175 , -11.544372 ,\n",
       "       -13.967627 , -14.255605 , -12.649664 ,  -8.253759 , -10.244661 ,\n",
       "        -9.39806  , -11.296884 , -15.369344 , -13.195168 , -15.252637 ,\n",
       "       -13.806974 , -10.67252  , -11.011396 , -11.46362  , -15.088361 ,\n",
       "        -6.756726 , -10.311008 , -11.396124 ,  -9.766146 , -11.83192  ,\n",
       "       -12.975671 , -10.721055 , -14.385933 , -12.320433 , -11.58423  ,\n",
       "       -10.047966 , -11.22101  , -11.008937 , -12.700499 , -12.651306 ,\n",
       "       -12.741022 , -11.416155 , -11.790989 , -10.85933  , -13.711594 ,\n",
       "       -14.251402 , -11.785492 , -11.109196 , -15.413212 , -10.116264 ,\n",
       "        -6.261492 ,  -8.05111  ,  -7.7234693,  -8.921828 , -11.241508 ,\n",
       "       -10.564898 , -10.480265 , -11.656308 , -13.202808 ,  -9.482935 ,\n",
       "        -8.873869 , -11.4376335, -14.15415  ,  -7.395031 , -14.198796 ,\n",
       "       -12.823993 , -13.327169 , -11.246152 , -12.570263 , -14.9230585,\n",
       "       -13.087162 , -14.514673 ,  -9.9943   , -12.79933  , -13.439948 ,\n",
       "        -6.406377 ,  -9.068036 ,  -7.2050195, -12.291939 , -10.921959 ,\n",
       "       -13.03038  , -10.739643 ,  -9.230352 , -11.001765 , -12.523571 ,\n",
       "       -11.111658 ,  -9.988306 , -11.91748  , -13.785696 ,  -7.1047916,\n",
       "        -9.08392  , -11.601837 , -11.363367 , -11.688226 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"kfold\"]==-1][\"teacher_preds\"].iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
