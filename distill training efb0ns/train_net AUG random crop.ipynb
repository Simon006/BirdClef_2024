{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import importlib\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "import audiomentations as AA\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torchdata\n",
    "import torch_audiomentations as TAA\n",
    "import albumentations\n",
    "\n",
    "from sklearn import metrics\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.distributions import Beta\n",
    "from torchaudio.transforms import AmplitudeToDB, MelSpectrogram\n",
    "from tqdm import tqdm\n",
    "from utils import AverageMeter\n",
    "\n",
    "sys.path.append('../configs')\n",
    "sys.path.append('./samplers')\n",
    "sys.path.append('./pcen')\n",
    "from pcen import StreamingPCENTransform\n",
    "# from sampler import MultilabelBalancedRandomSampler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "TRAIN_DATA_PATH = '../dataset/birdclef-2024/'\n",
    "\n",
    "torch.set_flush_denormal(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'asbfly': 0, 'ashdro1': 1, 'ashpri1': 2, 'ashwoo2': 3, 'asikoe2': 4, 'asiope1': 5, 'aspfly1': 6, 'aspswi1': 7, 'barfly1': 8, 'barswa': 9, 'bcnher': 10, 'bkcbul1': 11, 'bkrfla1': 12, 'bkskit1': 13, 'bkwsti': 14, 'bladro1': 15, 'blaeag1': 16, 'blakit1': 17, 'blhori1': 18, 'blnmon1': 19, 'blrwar1': 20, 'bncwoo3': 21, 'brakit1': 22, 'brasta1': 23, 'brcful1': 24, 'brfowl1': 25, 'brnhao1': 26, 'brnshr': 27, 'brodro1': 28, 'brwjac1': 29, 'brwowl1': 30, 'btbeat1': 31, 'bwfshr1': 32, 'categr': 33, 'chbeat1': 34, 'cohcuc1': 35, 'comfla1': 36, 'comgre': 37, 'comior1': 38, 'comkin1': 39, 'commoo3': 40, 'commyn': 41, 'compea': 42, 'comros': 43, 'comsan': 44, 'comtai1': 45, 'copbar1': 46, 'crbsun2': 47, 'cregos1': 48, 'crfbar1': 49, 'crseag1': 50, 'dafbab1': 51, 'darter2': 52, 'eaywag1': 53, 'emedov2': 54, 'eucdov': 55, 'eurbla2': 56, 'eurcoo': 57, 'forwag1': 58, 'gargan': 59, 'gloibi': 60, 'goflea1': 61, 'graher1': 62, 'grbeat1': 63, 'grecou1': 64, 'greegr': 65, 'grefla1': 66, 'grehor1': 67, 'grejun2': 68, 'grenig1': 69, 'grewar3': 70, 'grnsan': 71, 'grnwar1': 72, 'grtdro1': 73, 'gryfra': 74, 'grynig2': 75, 'grywag': 76, 'gybpri1': 77, 'gyhcaf1': 78, 'heswoo1': 79, 'hoopoe': 80, 'houcro1': 81, 'houspa': 82, 'inbrob1': 83, 'indpit1': 84, 'indrob1': 85, 'indrol2': 86, 'indtit1': 87, 'ingori1': 88, 'inpher1': 89, 'insbab1': 90, 'insowl1': 91, 'integr': 92, 'isbduc1': 93, 'jerbus2': 94, 'junbab2': 95, 'junmyn1': 96, 'junowl1': 97, 'kenplo1': 98, 'kerlau2': 99, 'labcro1': 100, 'laudov1': 101, 'lblwar1': 102, 'lesyel1': 103, 'lewduc1': 104, 'lirplo': 105, 'litegr': 106, 'litgre1': 107, 'litspi1': 108, 'litswi1': 109, 'lobsun2': 110, 'maghor2': 111, 'malpar1': 112, 'maltro1': 113, 'malwoo1': 114, 'marsan': 115, 'mawthr1': 116, 'moipig1': 117, 'nilfly2': 118, 'niwpig1': 119, 'nutman': 120, 'orihob2': 121, 'oripip1': 122, 'pabflo1': 123, 'paisto1': 124, 'piebus1': 125, 'piekin1': 126, 'placuc3': 127, 'plaflo1': 128, 'plapri1': 129, 'plhpar1': 130, 'pomgrp2': 131, 'purher1': 132, 'pursun3': 133, 'pursun4': 134, 'purswa3': 135, 'putbab1': 136, 'redspu1': 137, 'rerswa1': 138, 'revbul': 139, 'rewbul': 140, 'rewlap1': 141, 'rocpig': 142, 'rorpar': 143, 'rossta2': 144, 'rufbab3': 145, 'ruftre2': 146, 'rufwoo2': 147, 'rutfly6': 148, 'sbeowl1': 149, 'scamin3': 150, 'shikra1': 151, 'smamin1': 152, 'sohmyn1': 153, 'spepic1': 154, 'spodov': 155, 'spoowl1': 156, 'sqtbul1': 157, 'stbkin1': 158, 'sttwoo1': 159, 'thbwar1': 160, 'tibfly3': 161, 'tilwar1': 162, 'vefnut1': 163, 'vehpar1': 164, 'wbbfly1': 165, 'wemhar1': 166, 'whbbul2': 167, 'whbsho3': 168, 'whbtre1': 169, 'whbwag1': 170, 'whbwat1': 171, 'whbwoo2': 172, 'whcbar1': 173, 'whiter2': 174, 'whrmun': 175, 'whtkin2': 176, 'woosan': 177, 'wynlau1': 178, 'yebbab1': 179, 'yebbul3': 180, 'zitcis1': 181}\n"
     ]
    }
   ],
   "source": [
    "ROOT = \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input\"\n",
    "sub = pd.read_csv(f\"{ROOT}/birdclef-2024/sample_submission.csv\")\n",
    "target_columns = sub.columns.tolist()[1:]\n",
    "num_classes = len(target_columns)\n",
    "bird2id = {b: i for i, b in enumerate(target_columns)}\n",
    "print(bird2id)\n",
    "id2bird ={i:b for i, b in enumerate(target_columns)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_index = [0, 6, 10, 11, 15, 18, 19, 20,\n",
    " 24, 25, 26, 28, 30, 37, 38, 39, 40, 41, 44,\n",
    " 45, 46, 47, 48, 49, 50, 53, 54, 57, 61, 62,\n",
    " 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76,\n",
    " 77, 78, 80, 82, 84, 87, 90, 91, 97, 100, 102,\n",
    " 105, 107, 108, 109, 110, 111, 112, 113, 114,\n",
    " 116, 117, 118, 119, 121, 123, 128, 129, 133,\n",
    " 136, 137, 140, 141, 143, 146, 149, 153, 155,\n",
    " 157, 161, 164, 165, 169, 173, 176, 177, 178, 180,\n",
    " 181]\n",
    "select_cv_cols = [id2bird[i] for i in  col_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/issamemari/pytorch-multilabel-balanced-sampler/blob/master/sampler.py\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "\n",
    "class MultilabelBalancedRandomSampler(Sampler):\n",
    "    \"\"\"\n",
    "    MultilabelBalancedRandomSampler: Given a multilabel dataset of length n_samples and\n",
    "    number of classes n_classes, samples from the data with equal probability per class\n",
    "    effectively oversampling minority classes and undersampling majority classes at the\n",
    "    same time. Note that using this sampler does not guarantee that the distribution of\n",
    "    classes in the output samples will be uniform, since the dataset is multilabel and\n",
    "    sampling is based on a single class. This does however guarantee that all classes\n",
    "    will have at least batch_size / n_classes samples as batch_size approaches infinity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, indices=None, class_choice=\"least_sampled\"):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            labels: a multi-hot encoding numpy array of shape (n_samples, n_classes)\n",
    "            indices: an arbitrary-length 1-dimensional numpy array representing a list\n",
    "            of indices to sample only from\n",
    "            class_choice: a string indicating how class will be selected for every\n",
    "            sample:\n",
    "                \"least_sampled\": class with the least number of sampled labels so far\n",
    "                \"random\": class is chosen uniformly at random\n",
    "                \"cycle\": the sampler cycles through the classes sequentially\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "        if self.indices is None:\n",
    "            self.indices = range(len(labels))\n",
    "\n",
    "        self.num_classes = self.labels.shape[1]\n",
    "\n",
    "        # List of lists of example indices per class\n",
    "        self.class_indices = []\n",
    "        for class_ in range(self.num_classes):\n",
    "            lst = np.where(self.labels[:, class_] == 1)[0]\n",
    "            lst = lst[np.isin(lst, self.indices)]\n",
    "            self.class_indices.append(lst)\n",
    "\n",
    "        self.counts = [0] * self.num_classes\n",
    "\n",
    "        assert class_choice in [\"least_sampled\", \"random\", \"cycle\"]\n",
    "        self.class_choice = class_choice\n",
    "        self.current_class = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.count >= len(self.indices):\n",
    "            raise StopIteration\n",
    "        self.count += 1\n",
    "        return self.sample()\n",
    "\n",
    "    def sample(self):\n",
    "        class_ = self.get_class()\n",
    "        class_indices = self.class_indices[class_]\n",
    "        chosen_index = np.random.choice(class_indices)\n",
    "        if self.class_choice == \"least_sampled\":\n",
    "            for class_, indicator in enumerate(self.labels[chosen_index]):\n",
    "                if indicator == 1:\n",
    "                    self.counts[class_] += 1\n",
    "        return chosen_index\n",
    "\n",
    "    def get_class(self):\n",
    "        if self.class_choice == \"random\":\n",
    "            class_ = random.randint(0, self.labels.shape[1] - 1)\n",
    "        elif self.class_choice == \"cycle\":\n",
    "            class_ = self.current_class\n",
    "            self.current_class = (self.current_class + 1) % self.labels.shape[1]\n",
    "        elif self.class_choice == \"least_sampled\":\n",
    "            min_count = self.counts[0]\n",
    "            min_classes = [0]\n",
    "            for class_ in range(1, self.num_classes):\n",
    "                if self.counts[class_] < min_count:\n",
    "                    min_count = self.counts[class_]\n",
    "                    min_classes = [class_]\n",
    "                if self.counts[class_] == min_count:\n",
    "                    min_classes.append(class_)\n",
    "            class_ = np.random.choice(min_classes)\n",
    "        return class_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy  \n",
    "import importlib.util  \n",
    "import os  \n",
    "  \n",
    "# 假设你的配置文件是一个 Python 模块，并且它位于某个固定的路径下  \n",
    "# 例如，配置文件名为 'config.py'，它位于与当前脚本相同的目录下  \n",
    "CONFIG_FILE_NAME = 'exp071.py'  # 配置文件名  \n",
    "CONFIG_MODULE_NAME = CONFIG_FILE_NAME.replace('.py', '')  # 转换为模块名  \n",
    "  \n",
    "# 获取当前脚本的目录（如果是从脚本运行的话）  \n",
    "# 注意：如果是从模块导入的，这个可能不是你想要的目录  \n",
    "CURRENT_DIR = \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main-20240518T060118Z-001/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main/configs\"\n",
    "CONFIG_FILE_PATH = os.path.join(CURRENT_DIR, CONFIG_FILE_NAME)  \n",
    "  \n",
    "# 检查配置文件是否存在  \n",
    "if not os.path.exists(CONFIG_FILE_PATH):  \n",
    "    raise FileNotFoundError(f\"Configuration file {CONFIG_FILE_PATH} not found.\")  \n",
    "  \n",
    "# 使用importlib导入配置文件模块  \n",
    "spec = importlib.util.spec_from_file_location(CONFIG_MODULE_NAME, CONFIG_FILE_PATH)  \n",
    "config_module = importlib.util.module_from_spec(spec)  \n",
    "spec.loader.exec_module(config_module)  \n",
    "  \n",
    "# 假设你的配置文件模块中有一个名为 'cfg' 的变量或属性  \n",
    "CFG = copy.deepcopy(getattr(config_module, 'cfg', None))  \n",
    "if CFG is None:  \n",
    "    raise AttributeError(f\"Module {CONFIG_MODULE_NAME} does not have an attribute 'cfg'.\")  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description=\"\")\n",
    "# parser.add_argument(\"-C\", \"--config\", help=\"config filename\")\n",
    "# parser_args, _ = parser.parse_known_args(sys.argv)\n",
    "# CFG = copy(importlib.import_module(parser_args.config).cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def init_logger(log_file='train.log'):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def load_wave_and_crop(filename, period, start=None):\n",
    "\n",
    "    waveform_orig, sample_rate = librosa.load(filename, sr=32000, mono=False)\n",
    "\n",
    "    wave_len = len(waveform_orig)\n",
    "    waveform = np.concatenate([waveform_orig, waveform_orig, waveform_orig])\n",
    "\n",
    "    effective_length = sample_rate * period\n",
    "    while len(waveform) < (period * sample_rate * 3):\n",
    "        waveform = np.concatenate([waveform, waveform_orig])\n",
    "    if start is not None:\n",
    "        start = start - (period - 5) / 2 * sample_rate\n",
    "        while start < 0:\n",
    "            start += wave_len\n",
    "        start = int(start)\n",
    "    else:\n",
    "        if wave_len < effective_length:\n",
    "            start = np.random.randint(effective_length - wave_len)\n",
    "        elif wave_len > effective_length:\n",
    "            start = np.random.randint(wave_len - effective_length)\n",
    "        elif wave_len == effective_length:\n",
    "            start = 0\n",
    "\n",
    "    waveform_seg = waveform[start: start + int(effective_length)]\n",
    "\n",
    "    return waveform_orig, waveform_seg, sample_rate, start\n",
    "\n",
    "\n",
    "def load_wave_and_random_crop(filename, period, min_overlap=0):  \n",
    "    # 加载音频文件  \n",
    "    waveform_orig, sample_rate = librosa.load(filename, sr=32000, mono=False)  # 注意：这里假设你不需要立体声，如果需要立体声则删除mono=False  \n",
    "  \n",
    "    # 计算裁剪的有效长度  \n",
    "    wave_len = len(waveform_orig)\n",
    "    effective_length = int(sample_rate * period)  \n",
    "    waveform = np.concatenate([waveform_orig, waveform_orig, waveform_orig])\n",
    "    \n",
    "    # 确保裁剪长度不会超过原始音频长度（考虑重叠min_overlap）  \n",
    "    max_start = len(waveform) - effective_length  \n",
    "    while len(waveform) < (period * sample_rate * 3):\n",
    "        waveform = np.concatenate([waveform, waveform_orig])\n",
    "    while max_start < 0:  \n",
    "        max_start += wave_len \n",
    "  \n",
    "    # 随机选择起始位置  \n",
    "    start = np.random.randint(0, max_start + 1)  # +1 确保可以取到最大值  \n",
    "  \n",
    "    # 裁剪音频  \n",
    "    waveform_seg = waveform[start: start + effective_length]  \n",
    "   \n",
    "    return waveform_orig, waveform_seg, sample_rate, start  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.transforms import v2 as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for wave trasnform 1d  (160000,)\n",
    "# tr_transforms = albumentations.Compose(\n",
    "#     [\n",
    "#     #    albumentations.OneOf([\n",
    "#     #         AA.Gain(min_gain_in_db=-15, max_gain_in_db=15, p=1.0),\n",
    "#     #         AA.GainTransition(\n",
    "#     #             min_gain_in_db=-24.0,\n",
    "#     #             max_gain_in_db=6.0,\n",
    "#     #             min_duration=0.2,\n",
    "#     #             max_duration=6.0,\n",
    "#     #             p=1.0\n",
    "#     #         )\n",
    "#     #     ], p=0.5,),\n",
    "#         albumentations.HorizontalFlip(p=0.5),\n",
    "#         albumentations.CoarseDropout(max_height=int(128 * 0.375), max_width=int(128 * 0.375), max_holes=1, p=0.7),\n",
    "#         # albumentations.XYMasking(\n",
    "#         #         p=0.3,\n",
    "#         #         num_masks_x=(1, 3),\n",
    "#         #         num_masks_y=(1, 3),\n",
    "#         #         mask_x_length=(1, 10),\n",
    "#         #         mask_y_length=(1, 20),\n",
    "#         #     ) ,\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "tr_transforms = AA.Compose(\n",
    "    [\n",
    "        AA.OneOf([\n",
    "            AA.Gain(min_gain_in_db=-15, max_gain_in_db=15, p=1.0),\n",
    "            AA.GainTransition(\n",
    "                min_gain_in_db=-24.0,\n",
    "                max_gain_in_db=6.0,\n",
    "                min_duration=0.2,\n",
    "                max_duration=6.0,\n",
    "                p=1.0\n",
    "            )\n",
    "        ], p=0.5,),\n",
    "        # AA.OneOf([\n",
    "        #     AA.AddGaussianNoise(p=1.0),\n",
    "        #     AA.AddGaussianSNR(p=1.0),\n",
    "        # ], p=0.3,),\n",
    "        # AA.OneOf([\n",
    "        #     AA.AddShortNoises(\n",
    "        #         sounds_path=\"../input/esc50/use_label\",\n",
    "        #         min_snr_in_db=0,\n",
    "        #         max_snr_in_db=3,\n",
    "        #         p=1.0,\n",
    "        #         lru_cache_size=10,\n",
    "        #         min_time_between_sounds=4.0,\n",
    "        #         max_time_between_sounds=16.0,\n",
    "        #     ),\n",
    "        # ], p=0.5,),\n",
    "        # AA.OneOf([\n",
    "        #     AA.AddBackgroundNoise(\n",
    "        #         sounds_path=\"../input/zenodo_nocall_30sec\",\n",
    "        #         min_snr_in_db=0,\n",
    "        #         max_snr_in_db=3,\n",
    "        #         p=1.0,\n",
    "        #         lru_cache_size=1400,),\n",
    "        # ], p=0.5,),\n",
    "        # AA.LowPassFilter(p=0.3),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# alb_transform = [\n",
    "#         ### num_masks_x=1, num_masks_y=1 will change\n",
    "#         albumentations.XYMasking(num_masks_x=2, num_masks_y=1, \n",
    "#                                  mask_x_length=20, mask_y_length=4,\n",
    "#                                  fill_value=0, mask_fill_value=0, p=CFG.aug_spec_xymasking),\n",
    "#         albumentations.CoarseDropout(fill_value=0, min_holes=20, max_holes=50, p=CFG.aug_spec_coarsedrop),\n",
    "#         albumentations.HorizontalFlip(p=CFG.aug_spec_hflip),\n",
    "#         # albumentations.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ]\n",
    "# tr_transforms = albumentations.Compose(alb_transform)\n",
    "\n",
    "# va_transform = AA.Compose(\n",
    "#     # albumentations.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),1\n",
    "# )\n",
    "\n",
    "alb_transform = [\n",
    "        ### num_masks_x=1, num_masks_y=1 will change\n",
    "        albumentations.XYMasking(num_masks_x=2, num_masks_y=1, \n",
    "                                 mask_x_length=20, mask_y_length=4,\n",
    "                                 fill_value=0, mask_fill_value=0, p=0.),\n",
    "        albumentations.CoarseDropout(fill_value=0, min_holes=20, max_holes=50, p=0.),\n",
    "        albumentations.HorizontalFlip(p=0.5)    \n",
    "    ]\n",
    "albumentations_augment = albumentations.Compose(alb_transform)\n",
    "\n",
    "\n",
    "taa_augmentation = TAA.Compose(\n",
    "    transforms=[\n",
    "        TAA.PitchShift(\n",
    "            sample_rate=CFG.sample_rate,\n",
    "            mode=\"per_example\",\n",
    "            p=0.2,\n",
    "            ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BirdClef2023Dataset(torchdata.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str = 'DATA_PATH',\n",
    "        period: float = 5.0,\n",
    "        secondary_coef: float = 1.0,\n",
    "        smooth_label: float = 0.05,\n",
    "        df: pd.DataFrame = 'DATAFRAME',\n",
    "        train: bool = True,\n",
    "    ):\n",
    "\n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.filenames = df[\"filename\"]\n",
    "\n",
    "        self.primary_label = df[\"primary_label\"]\n",
    "        self.secondary_labels = (\n",
    "            df[\"secondary_labels\"]\n",
    "            .map(\n",
    "                lambda s: s.replace(\"[\", \"\")\n",
    "                .replace(\"]\", \"\")\n",
    "                .replace(\",\", \"\")\n",
    "                .replace(\"'\", \"\")\n",
    "                .split(\" \")\n",
    "            ).values\n",
    "        )\n",
    "\n",
    "        self.secondary_coef = secondary_coef\n",
    "        # self.type = df[\"type\"]\n",
    "        self.teacher_preds = df[\"teacher_preds\"]\n",
    "        self.rating = df[\"rating\"]\n",
    "        self.period = period\n",
    "        self.smooth_label = smooth_label + 1e-6\n",
    "        self.wave_transforms = tr_transforms\n",
    "        # self.wave_transforms_val = va_transforms\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "   \n",
    "    def normalize(self, x):\n",
    "        valid_values = x[x != float('-inf')]\n",
    "        mean_value = np.mean(valid_values)\n",
    "        x[x == float('-inf')] = mean_value\n",
    "        # x[x == float('-inf')] = 0\n",
    "\n",
    "        x = x - x.min()\n",
    "        x = x / x.max()\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        filename = os.path.join(self.data_path, self.filenames[idx])\n",
    "\n",
    "        if self.train:\n",
    "            # waveform, waveform_seg, sample_rate, start = load_wave_and_crop(\n",
    "            #     filename, self.period ,16000                                     # 训练也是前5s\n",
    "            # )\n",
    "            waveform, waveform_seg, sample_rate, start = load_wave_and_random_crop(\n",
    "                filename, self.period ,16000                                     # 训练也是前5s\n",
    "            )\n",
    "\n",
    "\n",
    "            # print(f\"1----{waveform_seg.shape=}\")\n",
    "            # for i in range(len(waveform_seg )):\n",
    "            #     waveform_seg[i] = self.normalize(waveform_seg[i])\n",
    "            # print(type(waveform_seg))\n",
    "            # waveform_seg = self.wave_transforms(\n",
    "            #     # image = waveform_seg\n",
    "            #     samples=waveform_seg, sample_rate=sample_rate\n",
    "            #     )\n",
    "            # waveform_seg = waveform_seg[np.newaxis,:]\n",
    "            # print(waveform_seg.shape)\n",
    "\n",
    "            res = self.wave_transforms(\n",
    "                # image = waveform_seg\n",
    "                samples=waveform_seg, sample_rate=sample_rate\n",
    "                )\n",
    "            # waveform_seg = res['image'].astype(np.float32)\n",
    "            # # print(\"2\",type(waveform_seg))\n",
    "            # waveform_seg = waveform_seg.flatten()\n",
    "            # print(\"2\",waveform_seg.shape)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        else:\n",
    "            waveform, waveform_seg, sample_rate, start = load_wave_and_crop(\n",
    "                filename, self.period, 0    #0                                 #16000   # 0.5秒后开始infer\n",
    "            )\n",
    "            # for i in range(len(waveform_seg)):\n",
    "            #     waveform_seg[i] = self.normalize(waveform_seg[i])\n",
    "            # waveform_seg = self.wave_transforms_val(\n",
    "            #     samples=waveform_seg, sample_rate=sample_rate\n",
    "            #     )\n",
    "\n",
    "        waveform_seg = torch.from_numpy(np.nan_to_num(waveform_seg)).float()\n",
    "\n",
    "\n",
    "        rating = self.rating[idx]\n",
    "\n",
    "        teacher_preds = torch.from_numpy(np.nan_to_num(self.teacher_preds[idx])).float()\n",
    "\n",
    "        target = np.zeros(CFG.num_classes, dtype=np.float32)\n",
    "        if self.primary_label[idx] != 'nocall':\n",
    "            primary_label = CFG.bird2id[self.primary_label[idx]]\n",
    "            target[primary_label] = 1.0\n",
    "\n",
    "            if self.train:\n",
    "                for s in self.secondary_labels[idx]:\n",
    "                    if s != \"\" and s in CFG.bird2id.keys():\n",
    "                        target[CFG.bird2id[s]] = self.secondary_coef\n",
    "\n",
    "        target = torch.from_numpy(target).float()\n",
    "        # teacher_preds = target\n",
    "\n",
    "        return {\n",
    "            \"wave\": waveform_seg,\n",
    "            \"rating\": rating,\n",
    "            \"primary_targets\": (target > 0.5).float(),\n",
    "            \"loss_target\": target * (1-self.smooth_label) + self.smooth_label / target.size(-1),\n",
    "            \"teacher_preds\": teacher_preds,\n",
    "        }\n",
    "\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = torch.nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "\n",
    "def gem_freq(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), 1)).pow(1.0 / p)\n",
    "\n",
    "\n",
    "class GeMFreq(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.p = torch.nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem_freq(x, p=self.p, eps=self.eps)\n",
    "\n",
    "\n",
    "class NormalizeMelSpec(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, X):\n",
    "        mean = X.mean((1, 2), keepdim=True)\n",
    "        std = X.std((1, 2), keepdim=True)\n",
    "        Xstd = (X - mean) / (std + self.eps)\n",
    "        norm_min, norm_max = \\\n",
    "            Xstd.min(-1)[0].min(-1)[0], Xstd.max(-1)[0].max(-1)[0]\n",
    "        fix_ind = (norm_max - norm_min) > self.eps * torch.ones_like(\n",
    "            (norm_max - norm_min)\n",
    "        )\n",
    "        V = torch.zeros_like(Xstd)\n",
    "        if fix_ind.sum():\n",
    "            V_fix = Xstd[fix_ind]\n",
    "            norm_max_fix = norm_max[fix_ind, None, None]\n",
    "            norm_min_fix = norm_min[fix_ind, None, None]\n",
    "            V_fix = torch.max(\n",
    "                torch.min(V_fix, norm_max_fix),\n",
    "                norm_min_fix,\n",
    "            )\n",
    "            V_fix = (V_fix - norm_min_fix) / (norm_max_fix - norm_min_fix)\n",
    "            V[fix_ind] = V_fix\n",
    "        return V\n",
    "\n",
    "\n",
    "class Mixup(nn.Module):\n",
    "    def __init__(self, mix_beta):\n",
    "\n",
    "        super(Mixup, self).__init__()\n",
    "        self.beta_distribution = Beta(mix_beta, mix_beta)\n",
    "\n",
    "    def forward(self, X, Y, weight=None, teacher_preds=None):\n",
    "\n",
    "        bs = X.shape[0]\n",
    "        n_dims = len(X.shape)\n",
    "        perm = torch.randperm(bs)\n",
    "        coeffs = self.beta_distribution.rsample(torch.Size((bs,))).to(X.device)\n",
    "\n",
    "        if n_dims == 2:\n",
    "            X = coeffs.view(-1, 1) * X + (1 - coeffs.view(-1, 1)) * X[perm]\n",
    "        elif n_dims == 3:\n",
    "            X = coeffs.view(-1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1)) * X[perm]\n",
    "        else:\n",
    "            X = coeffs.view(-1, 1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1, 1)) * X[perm]\n",
    "\n",
    "        Y = coeffs.view(-1, 1) * Y + (1 - coeffs.view(-1, 1)) * Y[perm]\n",
    "\n",
    "        if weight is None:\n",
    "            return X, Y\n",
    "        else:\n",
    "            weight = coeffs.view(-1) * weight + (1 - coeffs.view(-1)) * weight[perm]\n",
    "            teacher_preds = coeffs.view(-1, 1) * teacher_preds + (1 - coeffs.view(-1, 1)) * teacher_preds[perm]\n",
    "            return X, Y, weight, teacher_preds\n",
    "\n",
    "\n",
    "class AttModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone=\"resnet34\",\n",
    "        num_class=397,\n",
    "        train_period=15.0,\n",
    "        infer_period=5.0,\n",
    "        in_chans=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if CFG.use_pcen:\n",
    "            self.pcen = StreamingPCENTransform(\n",
    "                n_mels=CFG.n_mels,\n",
    "                n_fft=CFG.n_fft,\n",
    "                hop_length=CFG.hop_length,\n",
    "                trainable=True,\n",
    "                use_cuda_kernel=False\n",
    "                )\n",
    "            self.pcen.last_state = torch.zeros([55, 1, 128])\n",
    "        else:\n",
    "            self.logmelspec_extractor = nn.Sequential(\n",
    "                MelSpectrogram(\n",
    "                    sample_rate=CFG.sample_rate,\n",
    "                    n_mels=CFG.n_mels,\n",
    "                    f_min=CFG.fmin,\n",
    "                    f_max=CFG.fmax,\n",
    "                    n_fft=CFG.n_fft,\n",
    "                    hop_length=CFG.hop_length,\n",
    "                    normalized=True,\n",
    "                ),\n",
    "                AmplitudeToDB(top_db=80.0),\n",
    "                NormalizeMelSpec(),\n",
    "            )\n",
    "\n",
    "        base_model = timm.create_model(\n",
    "            backbone,\n",
    "            features_only=False,\n",
    "            pretrained=CFG.use_imagenet_weights,\n",
    "            in_chans=CFG.in_channels,\n",
    "        )\n",
    "\n",
    "        layers = list(base_model.children())[:-2]\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "        if \"efficientnet\" in CFG.backbone:\n",
    "            dense_input = base_model.num_features\n",
    "        elif \"swin\" in CFG.backbone:\n",
    "            dense_input = base_model.num_features\n",
    "        elif hasattr(base_model, \"fc\"):\n",
    "            dense_input = base_model.fc.in_features\n",
    "        else:\n",
    "            dense_input = base_model.feature_info[-1][\"num_chs\"]\n",
    "\n",
    "        self.train_period = train_period\n",
    "        self.infer_period = infer_period\n",
    "\n",
    "        self.factor = int(self.train_period / self.infer_period)\n",
    "        self.mixup = Mixup(mix_beta=1)\n",
    "        self.global_pool = GeM()\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(p) for p in np.linspace(0.1, 0.5, 5)])\n",
    "        self.head = nn.Linear(dense_input, num_class)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        if self.training:\n",
    "            x = input['wave']\n",
    "            bs, time = x.shape\n",
    "            x = x.reshape(bs * self.factor, time // self.factor)\n",
    "            y = input[\"loss_target\"]\n",
    "            weight = input[\"rating\"]\n",
    "            teacher_preds = input[\"teacher_preds\"]\n",
    "        else:\n",
    "            x = input['wave']\n",
    "            y = input[\"loss_target\"]\n",
    "            weight = input[\"rating\"]\n",
    "            teacher_preds = input[\"teacher_preds\"]\n",
    "\n",
    "        if CFG.use_pcen:\n",
    "            x = self.pcen(x).unsqueeze(1)\n",
    "            self.pcen.reset()\n",
    "        else:\n",
    "            x = self.logmelspec_extractor(x)[:, None]\n",
    "\n",
    "        if self.training:\n",
    "            if np.random.random() <= 0.5:\n",
    "                y2 = torch.repeat_interleave(y, self.factor, dim=0)\n",
    "                weight2 = torch.repeat_interleave(weight, self.factor, dim=0)\n",
    "                teacher_preds2 = torch.repeat_interleave(\n",
    "                    teacher_preds, self.factor, dim=0\n",
    "                    )\n",
    "\n",
    "                for i in range(0, x.shape[0], self.factor):\n",
    "                    x[i: i + self.factor], _, _, _ = self.mixup(\n",
    "                        x[i: i + self.factor],\n",
    "                        y2[i: i + self.factor],\n",
    "                        weight2[i: i + self.factor],\n",
    "                        teacher_preds2[i: i + self.factor],\n",
    "                    )\n",
    "\n",
    "            # # aug \n",
    "            # print(f\"1---{x.shape=}\")\n",
    "            # result = tr_transforms(image=x)  \n",
    "            # x= result[\"image\"]\n",
    "            # 1---x.shape=torch.Size([64, 1, 128, 313])\n",
    "            # 2---x.shape=torch.Size([64, 313, 1, 128])\n",
    "            x_squeezed = x.squeeze(dim=1)  # 现在形状是 [64, 313, 128]  \n",
    "            # print(f\"{x_squeezed.shape=}\")\n",
    "            # 使用permute重新排列维度  \n",
    "            x_permuted = x_squeezed.permute(1, 2, 0)  # [313, 128，64] \n",
    "            mel_spec = np.array(x_permuted.cpu())   \n",
    "            mel_spec = albumentations_augment(image=mel_spec)[\"image\"]\n",
    "            mel_spec = np.transpose(mel_spec, (2, 0, 1))   #  [64, 313, 128]  \n",
    "            mel_spec = mel_spec[:, np.newaxis,:, :] #[64,1 , 313, 128]\n",
    "            x = torch.tensor(mel_spec).to(device)\n",
    "\n",
    "\n",
    "            b, c, f, t = x.shape            # [64,1,313,128]\n",
    "            x = x.permute(0, 3, 1, 2)   \n",
    "            # print(f\"2---{x.shape=}\")  # [64, 313, 1, 128]\n",
    "            x = x.reshape(b // self.factor, self.factor * t, c, f)\n",
    "\n",
    "            if np.random.random() <= CFG.mixup_p:\n",
    "                x, y, weight, teacher_preds = self.mixup(x, y, weight, teacher_preds)\n",
    "\n",
    "            x = x.reshape(b, t, c, f)\n",
    "            x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        if self.training:\n",
    "            b, c, f, t = x.shape\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            x = x.reshape(b // self.factor, self.factor * t, c, f)\n",
    "            x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x[:, :, 0, 0]\n",
    "        logit = sum([self.head(dropout(x)) for dropout in self.dropouts]) / 5\n",
    "\n",
    "        return {\"logit\": logit, \"target\": y, \"rating\": weight, \"teacher_preds\": teacher_preds}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_focal_loss(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    alpha: float = 0.25,\n",
    "    gamma: float = 2,\n",
    "    reduction: str = \"none\",\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
    "\n",
    "    Args:\n",
    "        inputs (Tensor): A float tensor of arbitrary shape.\n",
    "                The predictions for each example.\n",
    "        targets (Tensor): A float tensor with the same shape as inputs. Stores the binary\n",
    "                classification label for each element in inputs\n",
    "                (0 for the negative class and 1 for the positive class).\n",
    "        alpha (float): Weighting factor in range (0,1) to balance\n",
    "                positive vs negative examples or -1 for ignore. Default: ``0.25``.\n",
    "        gamma (float): Exponent of the modulating factor (1 - p_t) to\n",
    "                balance easy vs hard examples. Default: ``2``.\n",
    "        reduction (string): ``'none'`` | ``'mean'`` | ``'sum'``\n",
    "                ``'none'``: No reduction will be applied to the output.\n",
    "                ``'mean'``: The output will be averaged.\n",
    "                ``'sum'``: The output will be summed. Default: ``'none'``.\n",
    "    Returns:\n",
    "        Loss tensor with the reduction option applied.\n",
    "    \"\"\"\n",
    "    # Original implementation from https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/focal_loss.py\n",
    "\n",
    "\n",
    "    p = torch.sigmoid(inputs)\n",
    "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "    p_t = p * targets + (1 - p) * (1 - targets)\n",
    "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
    "\n",
    "    if alpha >= 0:\n",
    "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        loss = alpha_t * loss\n",
    "\n",
    "    # Check reduction option and return loss accordingly\n",
    "    if reduction == \"none\":\n",
    "        pass\n",
    "    elif reduction == \"mean\":\n",
    "        loss = loss.mean()\n",
    "    elif reduction == \"sum\":\n",
    "        loss = loss.sum()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid Value for arg 'reduction': '{reduction} \\n Supported reduction modes: 'none', 'mean', 'sum'\"\n",
    "        )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BCEKDLoss(nn.Module):\n",
    "    def __init__(self, weights=[0.1, 0.9], class_weights=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weights = weights\n",
    "        self.T = 20\n",
    "\n",
    "    def forward(self, output):\n",
    "        input_ = output[\"logit\"]\n",
    "        target = output[\"target\"].float()\n",
    "        rating = output[\"rating\"]\n",
    "        teacher_preds = output[\"teacher_preds\"]\n",
    "\n",
    "        rating = rating.unsqueeze(1).repeat(1, CFG.num_classes)\n",
    "        loss = nn.BCEWithLogitsLoss(\n",
    "            weight=rating,\n",
    "            reduction='mean',\n",
    "        )(input_, target)\n",
    "\n",
    "        KD_loss = nn.KLDivLoss()(\n",
    "            F.log_softmax(input_ / self.T, dim=1),\n",
    "            F.softmax(teacher_preds / self.T, dim=1)\n",
    "            ) * (self.weights[1] * self.T * self.T)\n",
    "\n",
    "        return self.weights[0] * loss + KD_loss\n",
    "\n",
    "\n",
    "class FocalLossBCE(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            alpha: float = 0.25,\n",
    "            gamma: float = 2,\n",
    "            reduction: str = \"mean\",\n",
    "            bce_weight: float = 1.0,\n",
    "            focal_weight: float = 1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.bce = torch.nn.BCEWithLogitsLoss(reduction=reduction)\n",
    "        self.bce_weight = bce_weight\n",
    "        self.focal_weight = focal_weight\n",
    "\n",
    "    # def forward(self, logits, targets):\n",
    "    def forward(self,output):\n",
    "        logits = output[\"logit\"]\n",
    "        targets = output[\"target\"].float()\n",
    "        rating = output[\"rating\"]\n",
    "        teacher_preds = output[\"teacher_preds\"]\n",
    "\n",
    "        focall_loss = sigmoid_focal_loss(\n",
    "            inputs=logits,\n",
    "            targets=targets,\n",
    "            alpha=self.alpha,\n",
    "            gamma=self.gamma,\n",
    "            reduction=self.reduction,\n",
    "        )\n",
    "        bce_loss = self.bce(logits, targets.float())\n",
    "        return self.bce_weight * bce_loss + self.focal_weight * focall_loss\n",
    "\n",
    "\n",
    "\n",
    "def padded_cmap(solution, submission, padding_factor=5):\n",
    "    solution = solution  # .drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission  # .drop(['row_id'], axis=1, errors='ignore')\n",
    "    new_rows = []\n",
    "    for i in range(padding_factor):\n",
    "        new_rows.append([1 for i in range(len(solution.columns))])\n",
    "    new_rows = pd.DataFrame(new_rows)\n",
    "    new_rows.columns = solution.columns\n",
    "    padded_solution = pd.concat(\n",
    "        [solution, new_rows]).reset_index(drop=True).copy()\n",
    "    padded_submission = pd.concat(\n",
    "        [submission, new_rows]).reset_index(drop=True).copy()\n",
    "    score = metrics.average_precision_score(\n",
    "        padded_solution.values,\n",
    "        padded_submission.values,\n",
    "        average='macro',\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def map_score(solution, submission):\n",
    "    solution = solution  # .drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission  # .drop(['row_id'], axis=1, errors='ignore')\n",
    "    score = metrics.average_precision_score(\n",
    "        solution.values,\n",
    "        submission.values,\n",
    "        average='micro',  # 'macro'\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def batch_to_device(batch, device):\n",
    "    batch_dict = {key: batch[key].to(device) for key in batch}\n",
    "    return batch_dict\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    '''\n",
    "    Version of macro-averaged ROC-AUC score that ignores all classes that have no true positive labels.\n",
    "    '''\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "\n",
    "    solution_sums = solution.sum(axis=0)\n",
    "    scored_columns = list(solution_sums[solution_sums > 0].index.values)\n",
    "#     assert len(scored_columns) > 0\n",
    "\n",
    "    return sklearn.metrics.roc_auc_score(solution[scored_columns].values, submission[scored_columns].values, average='macro')\n",
    "\n",
    "def calculate_competition_metrics(gt, preds, target_columns, one_hot=True):\n",
    "    if not one_hot:\n",
    "        ground_truth = np.argmax(gt, axis=1)\n",
    "        gt = np.zeros((ground_truth.size, len(target_columns)))\n",
    "        gt[np.arange(ground_truth.size), ground_truth] = 1\n",
    "    val_df = pd.DataFrame(gt, columns=target_columns)\n",
    "    pred_df = pd.DataFrame(preds, columns=target_columns)\n",
    "    # cmAP_1 = padded_cmap(val_df, pred_df, padding_factor=1)\n",
    "    # cmAP_5 = padded_cmap(val_df, pred_df, padding_factor=5)\n",
    "    val_df['id'] = [f'id_{i}' for i in range(len(val_df))]\n",
    "    pred_df['id'] = [f'id_{i}' for i in range(len(pred_df))]\n",
    "    train_score = score(val_df, pred_df, row_id_column_name='id')\n",
    "    return {\n",
    "    #   \"cmAP_1\": cmAP_1,\n",
    "    #   \"cmAP_5\": cmAP_5,\n",
    "      \"ROC\": train_score,\n",
    "    }\n",
    "\n",
    "def train_fn(data_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    scaler = GradScaler(enabled=CFG.apex)\n",
    "    iters = len(data_loader)\n",
    "    gt = []\n",
    "    preds = []\n",
    "\n",
    "    with tqdm(enumerate(data_loader), total=len(data_loader)) as t:\n",
    "\n",
    "        for i, (data) in t:\n",
    "            inputs = batch_to_device(data, device)\n",
    "            targets = data['primary_targets'].to(device)\n",
    "\n",
    "            inputs['wave'] = taa_augmentation(inputs['wave'].unsqueeze(1))\n",
    "            inputs['wave'] = inputs['wave'].squeeze(1)\n",
    "\n",
    "            with autocast(enabled=CFG.apex):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs)\n",
    "\n",
    "            losses.update(loss.item(), inputs['wave'].size(0))\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), max_norm=CFG.max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scheduler.step(epoch + i / iters)\n",
    "            t.set_postfix(\n",
    "                loss=losses.avg,\n",
    "                grad=grad_norm.item(),\n",
    "                lr=optimizer.param_groups[0][\"lr\"]\n",
    "                )\n",
    "\n",
    "            gt.append(targets.cpu().detach().numpy())\n",
    "            preds.append(outputs[\"logit\"].sigmoid().cpu().detach().numpy())\n",
    "\n",
    "    val_df = pd.DataFrame(\n",
    "        np.concatenate(gt), columns=CFG.target_columns[:182])\n",
    "    pred_df = pd.DataFrame(\n",
    "        np.concatenate(preds), columns=CFG.target_columns[:182])\n",
    "    cmAP_1 = padded_cmap(val_df, pred_df, padding_factor=1)\n",
    "    cmAP_5 = padded_cmap(val_df, pred_df, padding_factor=5)\n",
    "    mAP = map_score(val_df, pred_df)\n",
    "\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "    # print(gt, preds.shape, target_columns)\n",
    "    gt = np.array(gt, dtype=np.int32)\n",
    "    scores = calculate_competition_metrics(gt, preds, target_columns)\n",
    "\n",
    "\n",
    "    return losses.avg, cmAP_1, cmAP_5, mAP, scores\n",
    "\n",
    "\n",
    "import sklearn\n",
    "\n",
    "\n",
    "def valid_fn(data_loader, model, criterion, epoch,col_index):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    gt = []\n",
    "    preds = []\n",
    "\n",
    "    with tqdm(enumerate(data_loader), total=len(data_loader)) as t:\n",
    "        for i, (data) in t:\n",
    "            inputs = batch_to_device(data, device)\n",
    "            targets = data['primary_targets'].to(device)\n",
    "\n",
    "            with autocast(enabled=CFG.apex):\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs)\n",
    "\n",
    "            losses.update(loss.item(), inputs['wave'].size(0))\n",
    "            t.set_postfix(loss=losses.avg)\n",
    "\n",
    "            gt.append(targets.cpu().detach().numpy())\n",
    "            preds.append(outputs[\"logit\"].sigmoid().cpu().detach().numpy())\n",
    "\n",
    "    val_df = pd.DataFrame(np.concatenate(gt), columns=CFG.target_columns[:182])\n",
    "    pred_df = pd.DataFrame(np.concatenate(preds), columns=CFG.target_columns[:182])\n",
    "    cmAP_1 = padded_cmap(val_df, pred_df, padding_factor=1)\n",
    "    cmAP_5 = padded_cmap(val_df, pred_df, padding_factor=5)\n",
    "    mAP = map_score(val_df, pred_df)\n",
    "\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    # print(gt, preds.shape, target_columns)\n",
    "    gt = np.array(gt, dtype=np.int32)\n",
    "    target_columns = CFG.target_columns[:182]\n",
    "    scores = calculate_competition_metrics(gt, preds, target_columns)\n",
    "\n",
    "    target_columns =  [id2bird[i] for i in col_index]\n",
    "    scores_cv = calculate_competition_metrics(gt[:,col_index], preds[:,col_index], target_columns)\n",
    "    \n",
    "    target_columns =  [id2bird[i] for i in col_index[:50]]\n",
    "    scores_cv_50 = calculate_competition_metrics(gt[:,col_index[:50]], preds[:,col_index[:50]], target_columns)\n",
    "\n",
    "    return losses.avg, cmAP_1, cmAP_5, mAP,scores,scores_cv,scores_cv_50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    criterion,\n",
    "    epochs=10,\n",
    "    fold=None,\n",
    "):\n",
    "\n",
    "    best_score = 0.0\n",
    "    patience = CFG.early_stopping\n",
    "    n_patience = 0\n",
    "\n",
    "    for epoch in range(epochs): \n",
    "        # train for one epoch\n",
    "        train_loss, train_cmAP1, train_cmAP5, train_mAP,train_scores = train_fn(\n",
    "            train_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_loss, val_cmAP1, val_cmAP5, val_mAP,scores,scores_cv,score_cv_50 = valid_fn(\n",
    "            val_loader, model, criterion, epoch,col_index)\n",
    "        \n",
    "        train_score = train_scores[\"ROC\"]\n",
    "        val_score = scores[\"ROC\"]\n",
    "        cv_score = scores_cv[\"ROC\"]\n",
    "        cv_score_50 = score_cv_50[\"ROC\"]\n",
    "        logger.info(f\"Epoch {epoch} - Train loss: {train_loss:.4f}, Train cmAP1: {train_cmAP1:.4f}, Train cmAP5: {train_cmAP5:.4f}, Train mAP: {train_mAP:.4f}, \\n Valid loss: {val_loss:.4f}, Valid cmAP1: {val_cmAP1:.4f}, Valid cmAP5: {val_cmAP5:.4f}, Valid mAP: {val_mAP:.4f}\")\n",
    "        logger.info(f\"\\n Epoch {epoch} - train metric {train_score} val metirc {val_score} cv score:{cv_score} cv 50_score {cv_score_50}\")\n",
    "\n",
    "\n",
    "        is_better = val_score > best_score\n",
    "        best_score = max(val_score, best_score)\n",
    "\n",
    "        # \n",
    "        state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"best_loss\": best_score,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                # \"macro-roc-auc\":scores[\"ROC\"]\n",
    "            }\n",
    "        logger.info(\n",
    "            f\"Epoch {epoch} - Save Best Score: {best_score:.4f} Model\\n\")\n",
    "        torch.save(\n",
    "            state,\n",
    "            os.path.join(CFG.model_output_path, f\"final_fold_{fold}_model.bin\")\n",
    "            )\n",
    "\n",
    "\n",
    "        # Save the best model\n",
    "        if is_better:\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"best_loss\": best_score,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                # \"macro-roc-auc\":scores[\"ROC\"]\n",
    "            }\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch} - Save Best Score: {best_score:.4f} Model\\n\")\n",
    "            torch.save(\n",
    "                state,\n",
    "                os.path.join(CFG.model_output_path, f\"fold_{fold}_model.bin\")\n",
    "                )\n",
    "            \n",
    "            # # 将模型转换为TorchScript\n",
    "            # scripted_model = torch.jit.script(model)\n",
    "            # # 保存序列化的模型\n",
    "            # torch.jit.save(scripted_model, f'jit_model/fold_{fold}_model.pt')\n",
    "\n",
    "            n_patience = 0\n",
    "        else:\n",
    "            n_patience += 1\n",
    "            logger.info(\n",
    "                f\"Valid loss didn't improve last {n_patience} epochs.\\n\")\n",
    "\n",
    "        if n_patience >= patience:\n",
    "            logger.info(\n",
    "                \"Early stop, Training End.\\n\")\n",
    "            break\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "logger = init_logger(log_file=f\"../log/train_{CFG.exp_name}.log\")\n",
    "device = get_device()\n",
    "set_seed(CFG.seed)\n",
    "os.makedirs(os.path.join(CFG.model_output_path), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.read_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main-20240518T060118Z-001/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main/train_folds_0518.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # a[\"filename\"] = a[\"filename\"].apply(lambda x: x.replace(\"../dataset\",\"\"))\n",
    "# a[\"filename\"] = a[\"filename\"].apply(lambda x: \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input\"+x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.to_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main-20240518T060118Z-001/BirdCLEF-2023-Identify-bird-calls-in-soundscapes-main/train_folds_0518.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttModel(\n",
    "        backbone=CFG.backbone,\n",
    "        num_class=CFG.num_classes,\n",
    "        train_period=CFG.period,\n",
    "        infer_period=5,\n",
    "    )\n",
    "\n",
    "\n",
    "#363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>filename</th>\n",
       "      <th>teacher_preds</th>\n",
       "      <th>teacher_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>64486.ogg</td>\n",
       "      <td>[ -6.8236113  -5.626453   -7.5165544  -9.73582...</td>\n",
       "      <td>grehor1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>2525.ogg</td>\n",
       "      <td>[ -7.176402   -9.332384   -8.316804  -10.27886...</td>\n",
       "      <td>zitcis1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>44981.ogg</td>\n",
       "      <td>[-4.0132084 -5.802989  -6.256181  -6.773272  -...</td>\n",
       "      <td>categr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>101323.ogg</td>\n",
       "      <td>[-6.338834  -5.7509503 -7.5665483 -9.063977  -...</td>\n",
       "      <td>comgre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>165746.ogg</td>\n",
       "      <td>[ -7.743705   -7.3720293  -9.064224  -10.81405...</td>\n",
       "      <td>eurcoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>5750</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>95027.ogg</td>\n",
       "      <td>[ -6.1317134  -7.55363    -6.77861    -8.95025...</td>\n",
       "      <td>purher1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>5751</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>80708.ogg</td>\n",
       "      <td>[ -6.922803    -7.7936735   -7.4676466  -10.89...</td>\n",
       "      <td>rocpig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5752</th>\n",
       "      <td>5752</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>168059.ogg</td>\n",
       "      <td>[ -6.418939   -8.418465   -7.230104   -9.64820...</td>\n",
       "      <td>commoo3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5753</th>\n",
       "      <td>5753</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>164922.ogg</td>\n",
       "      <td>[ -5.4923444  -6.9318366  -7.868212   -9.33819...</td>\n",
       "      <td>graher1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5754</th>\n",
       "      <td>5754</td>\n",
       "      <td>nocall</td>\n",
       "      <td>[]</td>\n",
       "      <td>40565.ogg</td>\n",
       "      <td>[-4.572484  -5.977849  -7.350516  -7.777331  -...</td>\n",
       "      <td>rocpig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5755 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 primary_label secondary_labels    filename  \\\n",
       "0              0        nocall               []   64486.ogg   \n",
       "1              1        nocall               []    2525.ogg   \n",
       "2              2        nocall               []   44981.ogg   \n",
       "3              3        nocall               []  101323.ogg   \n",
       "4              4        nocall               []  165746.ogg   \n",
       "...          ...           ...              ...         ...   \n",
       "5750        5750        nocall               []   95027.ogg   \n",
       "5751        5751        nocall               []   80708.ogg   \n",
       "5752        5752        nocall               []  168059.ogg   \n",
       "5753        5753        nocall               []  164922.ogg   \n",
       "5754        5754        nocall               []   40565.ogg   \n",
       "\n",
       "                                          teacher_preds teacher_label  \n",
       "0     [ -6.8236113  -5.626453   -7.5165544  -9.73582...       grehor1  \n",
       "1     [ -7.176402   -9.332384   -8.316804  -10.27886...       zitcis1  \n",
       "2     [-4.0132084 -5.802989  -6.256181  -6.773272  -...        categr  \n",
       "3     [-6.338834  -5.7509503 -7.5665483 -9.063977  -...        comgre  \n",
       "4     [ -7.743705   -7.3720293  -9.064224  -10.81405...        eurcoo  \n",
       "...                                                 ...           ...  \n",
       "5750  [ -6.1317134  -7.55363    -6.77861    -8.95025...       purher1  \n",
       "5751  [ -6.922803    -7.7936735   -7.4676466  -10.89...        rocpig  \n",
       "5752  [ -6.418939   -8.418465   -7.230104   -9.64820...       commoo3  \n",
       "5753  [ -5.4923444  -6.9318366  -7.868212   -9.33819...       graher1  \n",
       "5754  [-4.572484  -5.977849  -7.350516  -7.777331  -...        rocpig  \n",
       "\n",
       "[5755 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external = pd.read_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/Train mnasnet/nocall_pseudo.csv\")\n",
    "external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "external = pd.read_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/Train mnasnet/nocall_pseudo.csv\")\n",
    "external[\"filename\"] = external[\"filename\"].apply(lambda x: \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/nocall_archive/ff1010bird_nocall/nocall\"+x)\n",
    "# external[\"type\"] = '[]'\n",
    "external[\"kfold\"] = -1\n",
    "external[\"rating\"] = 1\n",
    "select_cols = ['filename', 'primary_label','secondary_labels','kfold', 'rating',\"teacher_preds\"]\n",
    "# external[\"filename\"] = '../input/birdclef-2023/train_audio/' + 'nocall/' + external['filename']\n",
    "# del external['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_array2np(s):\n",
    "    # 去除字符串两端的方括号和换行符，并按空格分割  \n",
    "    numbers_str = s.strip('[]\\n').split()  \n",
    "    # 将字符串列表转换为浮点数列表  \n",
    "    numbers_float = [float(n) for n in numbers_str]  \n",
    "    # 将浮点数列表转换为NumPy数组  \n",
    "    numbers_array = np.array(numbers_float)  \n",
    "\n",
    "    return numbers_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(54310, 6)\n",
      "==========================================================================================\n",
      "Fold 0 Training\n",
      "==========================================================================================\n",
      "(44599, 6)\n",
      "primary_label\n",
      "nocall     5755\n",
      "houspa     2078\n",
      "eaywag1    1977\n",
      "commoo3    1766\n",
      "eurcoo     1701\n",
      "           ... \n",
      "blaeag1       9\n",
      "integr        8\n",
      "wbbfly1       7\n",
      "niwpig1       6\n",
      "asiope1       5\n",
      "Name: count, Length: 183, dtype: int64\n",
      "(9711, 6)\n",
      "primary_label\n",
      "houspa     520\n",
      "eaywag1    494\n",
      "commoo3    441\n",
      "eurcoo     426\n",
      "barswa     345\n",
      "          ... \n",
      "niwpig1      2\n",
      "asiope1      2\n",
      "blaeag1      2\n",
      "wbbfly1      2\n",
      "malwoo1      2\n",
      "Name: count, Length: 182, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5755, 7)\n",
      "the length of parameters is 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 696/696 [01:32<00:00,  7.49it/s, grad=0.00169, loss=0.0124, lr=0.000999]\n",
      "100%|██████████| 152/152 [00:50<00:00,  3.00it/s, loss=0.00372]\n",
      "Epoch 0 - Train loss: 0.0124, Train cmAP1: 0.0922, Train cmAP5: 0.1137, Train mAP: 0.0794, \n",
      " Valid loss: 0.0037, Valid cmAP1: 0.7682, Valid cmAP5: 0.8387, Valid mAP: 0.8647\n",
      "\n",
      " Epoch 0 - train metric 0.7454483942498266 val metirc 0.990187406994165 cv score:0.9904530536797359 cv 50_score 0.9907288147297906\n",
      "Epoch 0 - Save Best Score: 0.9902 Model\n",
      "\n",
      "Epoch 0 - Save Best Score: 0.9902 Model\n",
      "\n",
      "100%|██████████| 696/696 [01:22<00:00,  8.47it/s, grad=0.00149, loss=0.0034, lr=0.000905] \n",
      "100%|██████████| 152/152 [00:51<00:00,  2.96it/s, loss=0.00365]\n",
      "Epoch 1 - Train loss: 0.0034, Train cmAP1: 0.3124, Train cmAP5: 0.3352, Train mAP: 0.2876, \n",
      " Valid loss: 0.0037, Valid cmAP1: 0.7727, Valid cmAP5: 0.8432, Valid mAP: 0.8662\n",
      "\n",
      " Epoch 1 - train metric 0.8306797302631096 val metirc 0.9911336011644614 cv score:0.990988022780096 cv 50_score 0.9910635068195569\n",
      "Epoch 1 - Save Best Score: 0.9911 Model\n",
      "\n",
      "Epoch 1 - Save Best Score: 0.9911 Model\n",
      "\n",
      "100%|██████████| 696/696 [01:44<00:00,  6.68it/s, grad=0.00156, loss=0.00329, lr=0.000794]\n",
      "100%|██████████| 152/152 [00:59<00:00,  2.57it/s, loss=0.00364]\n",
      "Epoch 2 - Train loss: 0.0033, Train cmAP1: 0.3084, Train cmAP5: 0.3315, Train mAP: 0.2856, \n",
      " Valid loss: 0.0036, Valid cmAP1: 0.7775, Valid cmAP5: 0.8455, Valid mAP: 0.8681\n",
      "\n",
      " Epoch 2 - train metric 0.8301977783937841 val metirc 0.9911330316036483 cv score:0.9918465546222796 cv 50_score 0.9918421599563652\n",
      "Epoch 2 - Save Best Score: 0.9911 Model\n",
      "\n",
      "Valid loss didn't improve last 1 epochs.\n",
      "\n",
      "100%|██████████| 696/696 [01:34<00:00,  7.34it/s, grad=0.00147, loss=0.00322, lr=0.000655]\n",
      " 15%|█▌        | 23/152 [00:09<00:39,  3.30it/s, loss=0.00385]"
     ]
    }
   ],
   "source": [
    "\n",
    "# with open(TRAIN_DATA_PATH + 'train_meta_pseudo.pickle', 'rb') as f:\n",
    "#     train = pickle.load(f)\n",
    "# train['filename'] = '../input/birdclef-2023/train_audio/' + train['filename']\n",
    "## 无teacher 训练\n",
    "# train = pd.read_csv(\"../train_folds_0518.csv\")\n",
    "train = pd.read_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/Train mnasnet/trainfold_0518_pseudo.csv\")\n",
    "train['rating'] = 1\n",
    "train[\"teacher_preds\"] = train[train[\"kfold\"]!=-1][\"teacher_preds\"].apply(lambda x :str_array2np(x))\n",
    "# with open('../input/xeno-canto_audio_meta_pseudo.pickle', 'rb') as f:\n",
    "#     xeno_canto_sa = pickle.load(f)\n",
    "# xeno_canto_sa[\"fold\"] = -1\n",
    "# train = pd.concat([train, xeno_canto_sa]).reset_index(drop=True)\n",
    "\n",
    "# with open('../input/xeno-canto_nd_audio_meta_pseudo.pickle', 'rb') as f:\n",
    "#     xeno_canto_nd = pickle.load(f)\n",
    "# train = pd.concat([train, xeno_canto_nd]).reset_index(drop=True)\n",
    "\n",
    "if CFG.external:\n",
    "    # with open('/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/ff1010bird_metadata_v1_pseudo.pickle', 'rb') as f:\n",
    "    #     external = pickle.load(f)\n",
    "    external = pd.read_pickle(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/ff1010bird_metadata_v1_pseudo.pickle\")\n",
    "    # external = pd.read_csv(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/Train mnasnet/nocall_pseudo.csv\")\n",
    "    external[\"filename\"] = external[\"filename\"].apply(lambda x: \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/nocall_archive/ff1010bird_nocall/nocall\"+x)\n",
    "    # external[\"type\"] = '[]'\n",
    "    external[\"kfold\"] = -1\n",
    "    external[\"rating\"] = 1\n",
    "    select_cols = ['filename', 'primary_label','secondary_labels','kfold', 'rating',\"teacher_preds\"]\n",
    "    # del external['length']\n",
    "    \n",
    "    print(external.shape)\n",
    "    external.head()\n",
    "    train[\"filename\"] = train[\"path\"]\n",
    "    train = pd.concat([train[select_cols], external[select_cols]]).reset_index(drop=True)\n",
    "\n",
    "# train[\"rating\"] = np.clip(train[\"rating\"] / train[\"rating\"].max(), 0.1, 1.0)\n",
    "\n",
    "logger.info(train.shape)\n",
    "train.head()\n",
    "\n",
    "# main loop\n",
    "for fold in range(5):\n",
    "\n",
    "    if fold not in CFG.folds:\n",
    "        continue\n",
    "    logger.info(\"=\" * 90)\n",
    "    logger.info(f\"Fold {fold} Training\")\n",
    "    logger.info(\"=\" * 90)\n",
    "\n",
    "    trn_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    val_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    sampler = None\n",
    "    if CFG.use_sampler:\n",
    "        one_hot_target = np.zeros(\n",
    "            (trn_df.shape[0], len(CFG.target_columns)), dtype=np.float32\n",
    "            )\n",
    "\n",
    "        for i, label in enumerate(trn_df.primary_label):\n",
    "            if label != \"nocall\":\n",
    "                primary_label = CFG.bird2id[label]\n",
    "                one_hot_target[i, primary_label] = 1.0\n",
    "\n",
    "        sampler = MultilabelBalancedRandomSampler(\n",
    "            one_hot_target,\n",
    "            trn_df.index,\n",
    "            class_choice=\"least_sampled\"\n",
    "            )\n",
    "\n",
    "    logger.info(trn_df.shape)\n",
    "    logger.info(trn_df['primary_label'].value_counts())\n",
    "    logger.info(val_df.shape)\n",
    "    logger.info(val_df['primary_label'].value_counts())\n",
    "\n",
    "    loaders = {}\n",
    "    trn_dataset = BirdClef2023Dataset(\n",
    "            data_path=CFG.train_datadir,\n",
    "            period=CFG.period,\n",
    "            secondary_coef=CFG.secondary_coef,\n",
    "            train=True,\n",
    "            df=trn_df,\n",
    "    )\n",
    "    loaders['train'] = torchdata.DataLoader(\n",
    "        trn_dataset,\n",
    "        sampler=sampler,\n",
    "        **CFG.loader_params['train']\n",
    "    )\n",
    "    val_dataset = BirdClef2023Dataset(\n",
    "            data_path=CFG.train_datadir,\n",
    "            period=5,\n",
    "            secondary_coef=CFG.secondary_coef,\n",
    "            train=False,\n",
    "            df=val_df,\n",
    "    )\n",
    "    loaders['valid'] = torchdata.DataLoader(\n",
    "        val_dataset,\n",
    "        **CFG.loader_params['valid']\n",
    "    )\n",
    "\n",
    "    model = AttModel(\n",
    "        backbone=CFG.backbone,\n",
    "        num_class=CFG.num_classes,\n",
    "        train_period=CFG.period,\n",
    "        infer_period=5,\n",
    "    )\n",
    "\n",
    "    if CFG.pretrained_weights:\n",
    "        model_path = CFG.pretrained_path\n",
    "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "        del checkpoint['state_dict']['head.weight']\n",
    "        del checkpoint['state_dict']['head.bias']\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
    "\n",
    "        params = list(model.parameters())\n",
    "        print('the length of parameters is', len(params))\n",
    "        for i in range(len(params)):\n",
    "            params[i].data = torch.round(params[i].data*10**17) / 10**17\n",
    "        del checkpoint\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # del xeno_canto_sa, xeno_canto_nd, external\n",
    "    gc.collect()\n",
    "\n",
    "    criterion = BCEKDLoss()\n",
    "    # criterion = FocalLossBCE(alpha=1.0)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CFG.lr_max,\n",
    "        betas=(0.9, 0.999),\n",
    "        eps=1e-08,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "        amsgrad=False,\n",
    "        )\n",
    "    scheduler = CosineLRScheduler(\n",
    "        optimizer,\n",
    "        t_initial=10,\n",
    "        warmup_t=1,\n",
    "        cycle_limit=20,\n",
    "        cycle_decay=0.8,\n",
    "        lr_min=CFG.lr_min,\n",
    "        t_in_epochs=True,\n",
    "    )\n",
    "\n",
    "    # start training\n",
    "    train_loop(\n",
    "        loaders['train'],\n",
    "        loaders['valid'],\n",
    "        model,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        criterion,\n",
    "        epochs=CFG.epochs,\n",
    "        fold=fold,\n",
    "        )\n",
    "\n",
    "logger.info('training done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(CFG.use_imagenet_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上分待办\n",
    "    - 删除前1秒数据\n",
    "    - 尝试random crop\n",
    "    - 更换teacher\n",
    "    - no weighted\n",
    "    - 不使用additional?\n",
    "    - nfnet尝试\n",
    "    - XYMASKING\n",
    "    - 20-25s midal train/infer \n",
    "    - adjust lr schduler\n",
    "    - use sampler weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9671 - 0.61\n",
    "# 0.9766 - 0.62\n",
    "# 0.9913 - 0.63\n",
    "# 0.9918 - 0.63  train loss 0.0034 valid loss0.0035 # bk loss\n",
    "# v4 : p=0.3 filter , 删除oneof aug , 修改max grad 10 # .cv 0.9915\n",
    "# 0.9921 - 0.64 v5 add oneof fmax,lrmax, secomdary coef   # .9919  cv 9921\n",
    "# V6 cfg.use_imagenet_weights = False   9910  \n",
    "# V7 imageweighted drop  9919 - cv 9923\n",
    "# V8 cfg.use_sampler = True #False  待办\n",
    "# V9 imageweighted drop+ 0.5s infer\n",
    "# adjust lr schduler\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
