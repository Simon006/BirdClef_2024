{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe653c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:00:31.007333Z",
     "iopub.status.busy": "2024-05-12T08:00:31.006957Z",
     "iopub.status.idle": "2024-05-12T08:01:11.905151Z",
     "shell.execute_reply": "2024-05-12T08:01:11.904046Z"
    },
    "papermill": {
     "duration": 40.912614,
     "end_time": "2024-05-12T08:01:11.907617",
     "exception": false,
     "start_time": "2024-05-12T08:00:30.995003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install warmup_scheduler\n",
    "# !pip install torchlibrosa\n",
    "# !pip install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9403b041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:11.936638Z",
     "iopub.status.busy": "2024-05-12T08:01:11.936282Z",
     "iopub.status.idle": "2024-05-12T08:01:12.912223Z",
     "shell.execute_reply": "2024-05-12T08:01:12.911426Z"
    },
    "papermill": {
     "duration": 0.993152,
     "end_time": "2024-05-12T08:01:12.914460",
     "exception": false,
     "start_time": "2024-05-12T08:01:11.921308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from audiomentations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416fd425",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.545387Z",
     "start_time": "2024-05-02T08:55:32.908334Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:12.941690Z",
     "iopub.status.busy": "2024-05-12T08:01:12.940911Z",
     "iopub.status.idle": "2024-05-12T08:01:22.276389Z",
     "shell.execute_reply": "2024-05-12T08:01:22.275561Z"
    },
    "papermill": {
     "duration": 9.351354,
     "end_time": "2024-05-12T08:01:22.278668",
     "exception": false,
     "start_time": "2024-05-12T08:01:12.927314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from metrics import calculate_competition_metrics, metrics_to_string, calculate_competition_metrics_no_map\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from torch.optim import AdamW\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "try:\n",
    "    from itertools import  ifilterfalse\n",
    "except ImportError: # py3k\n",
    "    from itertools import  filterfalse as ifilterfalse\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2357b253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.306450Z",
     "iopub.status.busy": "2024-05-12T08:01:22.305944Z",
     "iopub.status.idle": "2024-05-12T08:01:22.322380Z",
     "shell.execute_reply": "2024-05-12T08:01:22.321424Z"
    },
    "papermill": {
     "duration": 0.031879,
     "end_time": "2024-05-12T08:01:22.324247",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.292368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def padded_cmap(solution, submission, padding_factor=5):\n",
    "    solution = solution#.drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission#.drop(['row_id'], axis=1, errors='ignore')\n",
    "    \n",
    "    new_rows = []\n",
    "    for i in range(padding_factor):\n",
    "        new_rows.append([1 for i in range(len(solution.columns))])\n",
    "    new_rows = pd.DataFrame(new_rows)\n",
    "    new_rows.columns = solution.columns\n",
    "    padded_solution = pd.concat([solution, new_rows]).reset_index(drop=True).copy()\n",
    "    padded_submission = pd.concat([submission, new_rows]).reset_index(drop=True).copy()\n",
    "    score = sklearn.metrics.average_precision_score(\n",
    "        padded_solution.values,\n",
    "        padded_submission.values,\n",
    "        average='macro',\n",
    "    )\n",
    "    return score\n",
    "\n",
    "def padded_auc(solution, submission, padding_factor=5):\n",
    "    solution = solution #.drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission #.drop(['row_id'], axis=1, errors='ignore')\n",
    "\n",
    "\n",
    "    solution_sums = solution.sum(axis=0)\n",
    "    scored_columns = list(solution_sums[solution_sums > 0].index.values)\n",
    "#     assert len(scored_columns) > 0\n",
    "\n",
    "    return sklearn.metrics.roc_auc_score(solution[scored_columns].values, submission[scored_columns].values, average='macro')\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    '''\n",
    "    Version of macro-averaged ROC-AUC score that ignores all classes that have no true positive labels.\n",
    "    '''\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "\n",
    "    solution_sums = solution.sum(axis=0)\n",
    "    scored_columns = list(solution_sums[solution_sums > 0].index.values)\n",
    "#     assert len(scored_columns) > 0\n",
    "\n",
    "    return sklearn.metrics.roc_auc_score(solution[scored_columns].values, submission[scored_columns].values, average='macro')\n",
    "\n",
    "def calculate_competition_metrics(gt, preds, target_columns, one_hot=True):\n",
    "    if not one_hot:\n",
    "        ground_truth = np.argmax(gt, axis=1)\n",
    "        gt = np.zeros((ground_truth.size, len(target_columns)))\n",
    "        gt[np.arange(ground_truth.size), ground_truth] = 1\n",
    "    val_df = pd.DataFrame(gt, columns=target_columns)\n",
    "    pred_df = pd.DataFrame(preds, columns=target_columns)\n",
    "    cmAP_1 = padded_cmap(val_df, pred_df, padding_factor=1)\n",
    "    cmAP_5 = padded_cmap(val_df, pred_df, padding_factor=5)\n",
    "    val_df['id'] = [f'id_{i}' for i in range(len(val_df))]\n",
    "    pred_df['id'] = [f'id_{i}' for i in range(len(pred_df))]\n",
    "    train_score = score(val_df, pred_df, row_id_column_name='id')\n",
    "    return {\n",
    "      \"cmAP_1\": cmAP_1,\n",
    "      \"cmAP_5\": cmAP_5,\n",
    "      \"ROC\": train_score,\n",
    "    }\n",
    "def metrics_to_string(scores, key_word):\n",
    "    log_info = \"\"\n",
    "    for key in scores.keys():\n",
    "        log_info = log_info + f\"{key_word} {key} : {scores[key]:.4f}, \"\n",
    "    return log_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7715e97",
   "metadata": {
    "papermill": {
     "duration": 0.012634,
     "end_time": "2024-05-12T08:01:22.349719",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.337085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169871b",
   "metadata": {
    "papermill": {
     "duration": 0.012227,
     "end_time": "2024-05-12T08:01:22.374472",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.362245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Epoch 1 - Train loss: 0.8522, Train cmAP_1 : 0.5357, Train cmAP_5 : 0.7442, \n",
    "Epoch 1 - Valid loss: 0.8485, Valid cmAP_1 : 0.1220, Valid cmAP_5 : 0.3257, Valid mAP : 0.0082, Valid ROC : 0.5372, \n",
    "Epoch 1 - Save Best Score: 0.5372 Model\n",
    "\n",
    "Epoch 2 - Train loss: 0.7673, Train cmAP_1 : 0.5354, Train cmAP_5 : 0.7419, \n",
    "Epoch 2 - Valid loss: 0.6464, Valid cmAP_1 : 0.1235, Valid cmAP_5 : 0.3270, Valid mAP : 0.0129, Valid ROC : 0.5611, \n",
    "Epoch 2 - Save Best Score: 0.5611 Model\n",
    "\n",
    "Epoch 3 - Train loss: 0.3128, Train cmAP_1 : 0.5624, Train cmAP_5 : 0.7448, \n",
    "Epoch 3 - Valid loss: 0.1051, Valid cmAP_1 : 0.0590, Valid cmAP_5 : 0.2511, Valid mAP : 0.0226, Valid ROC : 0.6110, \n",
    "Epoch 3 - Save Best Score: 0.6110 Model\n",
    "\n",
    "Epoch 4 - Train loss: 0.0411, Train cmAP_1 : 0.5409, Train cmAP_5 : 0.7417, \n",
    "Epoch 4 - Valid loss: 0.0401, Valid cmAP_1 : 0.1435, Valid cmAP_5 : 0.3504, Valid mAP : 0.0463, Valid ROC : 0.7263, \n",
    "Epoch 4 - Save Best Score: 0.7263 Model\n",
    "\n",
    "Epoch 5 - Train loss: 0.0350, Train cmAP_1 : 0.5427, Train cmAP_5 : 0.7459, \n",
    "Epoch 5 - Valid loss: 0.0328, Valid cmAP_1 : 0.2460, Valid cmAP_5 : 0.4553, Valid mAP : 0.2485, Valid ROC : 0.8743, \n",
    "Epoch 5 - Save Best Score: 0.8743 Model\n",
    "\n",
    "Epoch 6 - Train loss: 0.0288, Train cmAP_1 : 0.5864, Train cmAP_5 : 0.7732, \n",
    "Epoch 6 - Valid loss: 0.0261, Valid cmAP_1 : 0.3153, Valid cmAP_5 : 0.5258, Valid mAP : 0.3372, Valid ROC : 0.9202, \n",
    "Epoch 6 - Save Best Score: 0.9202 Model\n",
    "\n",
    "Epoch 7 - Train loss: 0.0256, Train cmAP_1 : 0.5644, Train cmAP_5 : 0.7617, \n",
    "Epoch 7 - Valid loss: 0.0274, Valid cmAP_1 : 0.3493, Valid cmAP_5 : 0.5602, Valid mAP : 0.3776, Valid ROC : 0.9380, \n",
    "Epoch 7 - Save Best Score: 0.9380 Model\n",
    "\n",
    "Epoch 8 - Train loss: 0.0236, Train cmAP_1 : 0.5792, Train cmAP_5 : 0.7725, \n",
    "Epoch 8 - Valid loss: 0.0198, Valid cmAP_1 : 0.4676, Valid cmAP_5 : 0.6471, Valid mAP : 0.5536, Valid ROC : 0.9509, \n",
    "Epoch 8 - Save Best Score: 0.9509 Model\n",
    "\n",
    "Epoch 9 - Train loss: 0.0223, Train cmAP_1 : 0.6052, Train cmAP_5 : 0.7826, \n",
    "Epoch 9 - Valid loss: 0.0202, Valid cmAP_1 : 0.4754, Valid cmAP_5 : 0.6594, Valid mAP : 0.5519, Valid ROC : 0.9569, \n",
    "Epoch 9 - Save Best Score: 0.9569 Model\n",
    "\n",
    "Epoch 10 - Train loss: 0.0217, Train cmAP_1 : 0.5950, Train cmAP_5 : 0.7810, \n",
    "Epoch 10 - Valid loss: 0.0198, Valid cmAP_1 : 0.4619, Valid cmAP_5 : 0.6518, Valid mAP : 0.5328, Valid ROC : 0.9592, \n",
    "Epoch 10 - Save Best Score: 0.9592 Model\n",
    "\n",
    "Epoch 11 - Train loss: 0.0202, Train cmAP_1 : 0.6104, Train cmAP_5 : 0.7915, \n",
    "Epoch 11 - Valid loss: 0.0166, Valid cmAP_1 : 0.5612, Valid cmAP_5 : 0.7150, Valid mAP : 0.6656, Valid ROC : 0.9641, \n",
    "Epoch 11 - Save Best Score: 0.9641 Model\n",
    "\n",
    "Epoch 12 - Train loss: 0.0197, Train cmAP_1 : 0.5942, Train cmAP_5 : 0.7841, \n",
    "Epoch 12 - Valid loss: 0.0162, Valid cmAP_1 : 0.5966, Valid cmAP_5 : 0.7349, Valid mAP : 0.6805, Valid ROC : 0.9634, \n",
    "Valid loss didn't improve last 1 epochs.\n",
    "\n",
    "Epoch 13 - Train loss: 0.0192, Train cmAP_1 : 0.5937, Train cmAP_5 : 0.7795, \n",
    "Epoch 13 - Valid loss: 0.0159, Valid cmAP_1 : 0.6153, Valid cmAP_5 : 0.7457, Valid mAP : 0.6893, Valid ROC : 0.9669, \n",
    "Epoch 13 - Save Best Score: 0.9669 Model\n",
    "\n",
    "Epoch 14 - Train loss: 0.0191, Train cmAP_1 : 0.5991, Train cmAP_5 : 0.7903, \n",
    "Epoch 14 - Valid loss: 0.0193, Valid cmAP_1 : 0.5310, Valid cmAP_5 : 0.7047, Valid mAP : 0.5732, Valid ROC : 0.9660, \n",
    "Valid loss didn't improve last 1 epochs.\n",
    "\n",
    "Epoch 15 - Train loss: 0.0180, Train cmAP_1 : 0.6038, Train cmAP_5 : 0.7822, \n",
    "Epoch 15 - Valid loss: 0.0163, Valid cmAP_1 : 0.5753, Valid cmAP_5 : 0.7283, Valid mAP : 0.6613, Valid ROC : 0.9656, \n",
    "Valid loss didn't improve last 2 epochs.\n",
    "\n",
    "Epoch 16 - Train loss: 0.0181, Train cmAP_1 : 0.6067, Train cmAP_5 : 0.7918, \n",
    "Epoch 16 - Valid loss: 0.0168, Valid cmAP_1 : 0.5555, Valid cmAP_5 : 0.7140, Valid mAP : 0.6448, Valid ROC : 0.9613, \n",
    "Valid loss didn't improve last 3 epochs.\n",
    "\n",
    "Epoch 17 - Train loss: 0.0176, Train cmAP_1 : 0.6181, Train cmAP_5 : 0.7918, \n",
    "Epoch 17 - Valid loss: 0.0160, Valid cmAP_1 : 0.5999, Valid cmAP_5 : 0.7436, Valid mAP : 0.6738, Valid ROC : 0.9670, \n",
    "Epoch 17 - Save Best Score: 0.9670 Model\n",
    "\n",
    "Epoch 18 - Train loss: 0.0169, Train cmAP_1 : 0.6040, Train cmAP_5 : 0.7897, \n",
    "Epoch 18 - Valid loss: 0.0174, Valid cmAP_1 : 0.5920, Valid cmAP_5 : 0.7447, Valid mAP : 0.6454, Valid ROC : 0.9690, \n",
    "Epoch 18 - Save Best Score: 0.9690 Model\n",
    "\n",
    "Epoch 19 - Train loss: 0.0162, Train cmAP_1 : 0.6005, Train cmAP_5 : 0.7870, \n",
    "Epoch 19 - Valid loss: 0.0174, Valid cmAP_1 : 0.5855, Valid cmAP_5 : 0.7397, Valid mAP : 0.6386, Valid ROC : 0.9682, \n",
    "Valid loss didn't improve last 1 epochs.\n",
    "\n",
    "Epoch 20 - Train loss: 0.0161, Train cmAP_1 : 0.6355, Train cmAP_5 : 0.8080, \n",
    "Epoch 20 - Valid loss: 0.0151, Valid cmAP_1 : 0.6357, Valid cmAP_5 : 0.7629, Valid mAP : 0.7092, Valid ROC : 0.9683, \n",
    "Valid loss didn't improve last 2 epochs.\n",
    "\n",
    "Epoch 21 - Train loss: 0.0157, Train cmAP_1 : 0.6019, Train cmAP_5 : 0.7856, \n",
    "Epoch 21 - Valid loss: 0.0162, Valid cmAP_1 : 0.5980, Valid cmAP_5 : 0.7464, Valid mAP : 0.6594, Valid ROC : 0.9675, \n",
    "Valid loss didn't improve last 3 epochs.\n",
    "\n",
    "Epoch 22 - Train loss: 0.0160, Train cmAP_1 : 0.5569, Train cmAP_5 : 0.7717, \n",
    "Epoch 22 - Valid loss: 0.0148, Valid cmAP_1 : 0.6402, Valid cmAP_5 : 0.7668, Valid mAP : 0.7204, Valid ROC : 0.9673, \n",
    "Valid loss didn't improve last 4 epochs.\n",
    "\n",
    "Epoch 23 - Train loss: 0.0158, Train cmAP_1 : 0.6211, Train cmAP_5 : 0.8011, \n",
    "Epoch 23 - Valid loss: 0.0150, Valid cmAP_1 : 0.6254, Valid cmAP_5 : 0.7594, Valid mAP : 0.7124, Valid ROC : 0.9642, \n",
    "Valid loss didn't improve last 5 epochs.\n",
    "\n",
    "Epoch 24 - Train loss: 0.0153, Train cmAP_1 : 0.5914, Train cmAP_5 : 0.7817, \n",
    "Epoch 24 - Valid loss: 0.0154, Valid cmAP_1 : 0.6207, Valid cmAP_5 : 0.7590, Valid mAP : 0.6824, Valid ROC : 0.9650, \n",
    "Valid loss didn't improve last 6 epochs.\n",
    "\n",
    "Epoch 25 - Train loss: 0.0143, Train cmAP_1 : 0.6056, Train cmAP_5 : 0.7859, \n",
    "Epoch 25 - Valid loss: 0.0155, Valid cmAP_1 : 0.6094, Valid cmAP_5 : 0.7542, Valid mAP : 0.6769, Valid ROC : 0.9680, \n",
    "Valid loss didn't improve last 7 epochs.\n",
    "\n",
    "Early stop, Training End.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb135ac3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.550548Z",
     "start_time": "2024-05-02T08:55:35.546391Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.400650Z",
     "iopub.status.busy": "2024-05-12T08:01:22.400295Z",
     "iopub.status.idle": "2024-05-12T08:01:22.458884Z",
     "shell.execute_reply": "2024-05-12T08:01:22.458041Z"
    },
    "papermill": {
     "duration": 0.07395,
     "end_time": "2024-05-12T08:01:22.460750",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.386800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_name = 'exp1'\n",
    "# backbone = 'eca_nfnet_l0'\n",
    "seed = 42\n",
    "batch_size =  64\n",
    "num_workers = 12\n",
    "\n",
    "n_epochs = 100\n",
    "warmup_epo = 5\n",
    "cosine_epo = 100 - warmup_epo\n",
    "\n",
    "image_size = 256 #128 #256\n",
    "\n",
    "lr_max = 1e-5\n",
    "lr_min = 1e-7\n",
    "weight_decay = 1e-6\n",
    "\n",
    "# mel_spec_params = {\n",
    "#     \"sample_rate\": 32000,\n",
    "#     \"n_mels\": 128,\n",
    "#     \"f_min\": 20,\n",
    "#     \"f_max\": 16000,\n",
    "#     \"n_fft\": 1024,\n",
    "#     \"hop_length\": 320,\n",
    "#     \"normalized\": True,\n",
    "#     \"center\" : True,\n",
    "#     \"pad_mode\" : \"constant\",\n",
    "#     \"norm\" : \"slaney\",\n",
    "#     \"onesided\" : True,\n",
    "#     \"mel_scale\" : \"slaney\"\n",
    "# }\n",
    "\n",
    "mel_spec_params = {\n",
    "    \"sample_rate\": 32000,\n",
    "    \"n_mels\": 128,\n",
    "    \"f_min\": 20,\n",
    "    \"f_max\": 16000,\n",
    "    \"n_fft\": 2048,\n",
    "    \"hop_length\": 512,\n",
    "    \"normalized\": True,\n",
    "    \"center\" : True,\n",
    "    \"pad_mode\" : \"constant\",\n",
    "    \"norm\" : \"slaney\",\n",
    "    \"onesided\" : True,\n",
    "    \"mel_scale\" : \"slaney\"\n",
    "}\n",
    "\n",
    "top_db = 80\n",
    "train_period = 5\n",
    "val_period = 5\n",
    "\n",
    "secondary_coef = 1.0\n",
    "\n",
    "train_duration = train_period * mel_spec_params[\"sample_rate\"]\n",
    "val_duration = val_period * mel_spec_params[\"sample_rate\"]\n",
    "\n",
    "N_FOLD = 5\n",
    "fold = 2\n",
    "\n",
    "use_amp = True\n",
    "max_grad_norm = 10\n",
    "early_stopping = 7\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "output_folder = \"outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(os.path.join(output_folder, exp_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5f73f",
   "metadata": {
    "papermill": {
     "duration": 0.012306,
     "end_time": "2024-05-12T08:01:22.485843",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.473537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Seed Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fced25a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.567584Z",
     "start_time": "2024-05-02T08:55:35.550548Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.512437Z",
     "iopub.status.busy": "2024-05-12T08:01:22.512065Z",
     "iopub.status.idle": "2024-05-12T08:01:22.520280Z",
     "shell.execute_reply": "2024-05-12T08:01:22.519593Z"
    },
    "papermill": {
     "duration": 0.02401,
     "end_time": "2024-05-12T08:01:22.522237",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.498227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5616b57d",
   "metadata": {
    "papermill": {
     "duration": 0.012058,
     "end_time": "2024-05-12T08:01:22.546849",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.534791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a855440",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.624574Z",
     "start_time": "2024-05-02T08:55:35.567584Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.572945Z",
     "iopub.status.busy": "2024-05-12T08:01:22.572620Z",
     "iopub.status.idle": "2024-05-12T08:01:22.814323Z",
     "shell.execute_reply": "2024-05-12T08:01:22.813423Z"
    },
    "papermill": {
     "duration": 0.257192,
     "end_time": "2024-05-12T08:01:22.816514",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.559322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'asbfly': 0, 'ashdro1': 1, 'ashpri1': 2, 'ashwoo2': 3, 'asikoe2': 4, 'asiope1': 5, 'aspfly1': 6, 'aspswi1': 7, 'barfly1': 8, 'barswa': 9, 'bcnher': 10, 'bkcbul1': 11, 'bkrfla1': 12, 'bkskit1': 13, 'bkwsti': 14, 'bladro1': 15, 'blaeag1': 16, 'blakit1': 17, 'blhori1': 18, 'blnmon1': 19, 'blrwar1': 20, 'bncwoo3': 21, 'brakit1': 22, 'brasta1': 23, 'brcful1': 24, 'brfowl1': 25, 'brnhao1': 26, 'brnshr': 27, 'brodro1': 28, 'brwjac1': 29, 'brwowl1': 30, 'btbeat1': 31, 'bwfshr1': 32, 'categr': 33, 'chbeat1': 34, 'cohcuc1': 35, 'comfla1': 36, 'comgre': 37, 'comior1': 38, 'comkin1': 39, 'commoo3': 40, 'commyn': 41, 'compea': 42, 'comros': 43, 'comsan': 44, 'comtai1': 45, 'copbar1': 46, 'crbsun2': 47, 'cregos1': 48, 'crfbar1': 49, 'crseag1': 50, 'dafbab1': 51, 'darter2': 52, 'eaywag1': 53, 'emedov2': 54, 'eucdov': 55, 'eurbla2': 56, 'eurcoo': 57, 'forwag1': 58, 'gargan': 59, 'gloibi': 60, 'goflea1': 61, 'graher1': 62, 'grbeat1': 63, 'grecou1': 64, 'greegr': 65, 'grefla1': 66, 'grehor1': 67, 'grejun2': 68, 'grenig1': 69, 'grewar3': 70, 'grnsan': 71, 'grnwar1': 72, 'grtdro1': 73, 'gryfra': 74, 'grynig2': 75, 'grywag': 76, 'gybpri1': 77, 'gyhcaf1': 78, 'heswoo1': 79, 'hoopoe': 80, 'houcro1': 81, 'houspa': 82, 'inbrob1': 83, 'indpit1': 84, 'indrob1': 85, 'indrol2': 86, 'indtit1': 87, 'ingori1': 88, 'inpher1': 89, 'insbab1': 90, 'insowl1': 91, 'integr': 92, 'isbduc1': 93, 'jerbus2': 94, 'junbab2': 95, 'junmyn1': 96, 'junowl1': 97, 'kenplo1': 98, 'kerlau2': 99, 'labcro1': 100, 'laudov1': 101, 'lblwar1': 102, 'lesyel1': 103, 'lewduc1': 104, 'lirplo': 105, 'litegr': 106, 'litgre1': 107, 'litspi1': 108, 'litswi1': 109, 'lobsun2': 110, 'maghor2': 111, 'malpar1': 112, 'maltro1': 113, 'malwoo1': 114, 'marsan': 115, 'mawthr1': 116, 'moipig1': 117, 'nilfly2': 118, 'niwpig1': 119, 'nutman': 120, 'orihob2': 121, 'oripip1': 122, 'pabflo1': 123, 'paisto1': 124, 'piebus1': 125, 'piekin1': 126, 'placuc3': 127, 'plaflo1': 128, 'plapri1': 129, 'plhpar1': 130, 'pomgrp2': 131, 'purher1': 132, 'pursun3': 133, 'pursun4': 134, 'purswa3': 135, 'putbab1': 136, 'redspu1': 137, 'rerswa1': 138, 'revbul': 139, 'rewbul': 140, 'rewlap1': 141, 'rocpig': 142, 'rorpar': 143, 'rossta2': 144, 'rufbab3': 145, 'ruftre2': 146, 'rufwoo2': 147, 'rutfly6': 148, 'sbeowl1': 149, 'scamin3': 150, 'shikra1': 151, 'smamin1': 152, 'sohmyn1': 153, 'spepic1': 154, 'spodov': 155, 'spoowl1': 156, 'sqtbul1': 157, 'stbkin1': 158, 'sttwoo1': 159, 'thbwar1': 160, 'tibfly3': 161, 'tilwar1': 162, 'vefnut1': 163, 'vehpar1': 164, 'wbbfly1': 165, 'wemhar1': 166, 'whbbul2': 167, 'whbsho3': 168, 'whbtre1': 169, 'whbwag1': 170, 'whbwat1': 171, 'whbwoo2': 172, 'whcbar1': 173, 'whiter2': 174, 'whrmun': 175, 'whtkin2': 176, 'woosan': 177, 'wynlau1': 178, 'yebbab1': 179, 'yebbul3': 180, 'zitcis1': 181}\n"
     ]
    }
   ],
   "source": [
    "ROOT = \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/birdclef-2024\"\n",
    "\n",
    "df = pd.read_csv(f'{ROOT}/train_metadata.csv')\n",
    "df[\"path\"] = f\"{ROOT}/train_audio/\" + df[\"filename\"]\n",
    "df[\"rating\"] = np.clip(df[\"rating\"] / df[\"rating\"].max(), 0.1, 1.0)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLD, random_state=seed, shuffle=True)\n",
    "df['fold'] = -1\n",
    "for ifold, (train_idx, val_idx) in enumerate(skf.split(X=df, y=df[\"primary_label\"].values)):\n",
    "    df.loc[val_idx, 'fold'] = ifold\n",
    "\n",
    "sub = pd.read_csv(f\"{ROOT}/sample_submission.csv\")\n",
    "target_columns = sub.columns.tolist()[1:]\n",
    "num_classes = len(target_columns)\n",
    "bird2id = {b: i for i, b in enumerate(target_columns)}\n",
    "print(bird2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e246d",
   "metadata": {
    "papermill": {
     "duration": 0.012283,
     "end_time": "2024-05-12T08:01:22.841622",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.829339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f29a25f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.63072Z",
     "start_time": "2024-05-02T08:55:35.625578Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.868563Z",
     "iopub.status.busy": "2024-05-12T08:01:22.868198Z",
     "iopub.status.idle": "2024-05-12T08:01:22.894735Z",
     "shell.execute_reply": "2024-05-12T08:01:22.893788Z"
    },
    "papermill": {
     "duration": 0.042423,
     "end_time": "2024-05-12T08:01:22.896620",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.854197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_melspec(X, eps=1e-6):\n",
    "    mean = X.mean((1, 2), keepdim=True)\n",
    "    std = X.std((1, 2), keepdim=True)\n",
    "    Xstd = (X - mean) / (std + eps)\n",
    "\n",
    "    norm_min, norm_max = (\n",
    "        Xstd.min(-1)[0].min(-1)[0],\n",
    "        Xstd.max(-1)[0].max(-1)[0],\n",
    "    )\n",
    "    fix_ind = (norm_max - norm_min) > eps * torch.ones_like(\n",
    "        (norm_max - norm_min)\n",
    "    )\n",
    "    V = torch.zeros_like(Xstd)\n",
    "    if fix_ind.sum():\n",
    "        V_fix = Xstd[fix_ind]\n",
    "        norm_max_fix = norm_max[fix_ind, None, None]\n",
    "        norm_min_fix = norm_min[fix_ind, None, None]\n",
    "        V_fix = torch.max(\n",
    "            torch.min(V_fix, norm_max_fix),\n",
    "            norm_min_fix,\n",
    "        )\n",
    "        V_fix = (V_fix - norm_min_fix) / (norm_max_fix - norm_min_fix)\n",
    "        V[fix_ind] = V_fix\n",
    "    return V\n",
    "\n",
    "\n",
    "def read_wav(path):\n",
    "    wav, org_sr = torchaudio.load(path, normalize=True)\n",
    "    wav = torchaudio.functional.resample(wav, orig_freq=org_sr, new_freq=mel_spec_params[\"sample_rate\"])\n",
    "    return wav\n",
    "\n",
    "\n",
    "def crop_start_wav(wav, duration_):\n",
    "    while wav.size(-1) < duration_:\n",
    "        wav = torch.cat([wav, wav], dim=1)\n",
    "    wav = wav[:, :duration_]\n",
    "    return wav\n",
    "\n",
    "def crop_random_wav(wav, duration_):\n",
    "    while wav.size(-1) < duration_:\n",
    "        wav = torch.cat([wav, wav], dim=1)\n",
    "    start = np.random.randint(wav.shape[1]-duration_)\n",
    "    wav = wav[:, start:start+duration_]\n",
    "    return wav\n",
    "\n",
    "def random_power(images, power=1.5, c=0.7):\n",
    "    images = images - images.min()\n",
    "    images = images / (images.max() + 0.0000001)\n",
    "    images = images ** (random.random() * power + c)\n",
    "    return images\n",
    "\n",
    "class BirdDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform=None, add_secondary_labels=True, mode=\"train\"):\n",
    "        self.df = df\n",
    "        self.bird2id = bird2id\n",
    "        self.num_classes = num_classes\n",
    "        self.secondary_coef = secondary_coef\n",
    "        self.add_secondary_labels = add_secondary_labels\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(**mel_spec_params)\n",
    "        self.db_transform = torchaudio.transforms.AmplitudeToDB(stype='power', top_db=top_db)\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            self.wave_transforms = A.Compose(\n",
    "                [\n",
    "#                     OneOf([\n",
    "#                         Gain(min_gain_in_db=-15, max_gain_in_db=15, p=0.8),\n",
    "#                         GainTransition(min_gain_in_db=-15, max_gain_in_db=15, p=0.8),\n",
    "#                     ]),\n",
    "#                     OneOf(\n",
    "#                         [\n",
    "#                             NoiseInjection(p=1, max_noise_level=0.04),\n",
    "#                             GaussianNoise(p=1, min_snr=5, max_snr=20),\n",
    "#                             PinkNoise(p=1, min_snr=5, max_snr=20),\n",
    "#                             AddGaussianNoise(min_amplitude=0.0001, max_amplitude=0.03, p=0.5),\n",
    "#                             AddGaussianSNR(min_snr_in_db=5, max_snr_in_db=15, p=0.5),\n",
    "#                         ],\n",
    "#                         p=0.3,\n",
    "#                     ),\n",
    "                    AddBackgroundNoise(\n",
    "                        sounds_path=\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/backgroud_noise/archive/birdclef2021_nocall\", min_snr_in_db=0, max_snr_in_db=2, p=0.5\n",
    "                    ),\n",
    "                    A.Normalize(p=1),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.wave_transforms = Compose(\n",
    "                [\n",
    "                    Normalize(p=1),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def prepare_target(self, primary_label, secondary_labels):\n",
    "        secondary_labels = eval(secondary_labels)\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if primary_label != 'nocall':\n",
    "            primary_label = self.bird2id[primary_label]\n",
    "            target[primary_label] = 1.0\n",
    "            if self.add_secondary_labels:\n",
    "                for s in secondary_labels:\n",
    "                    if s != \"\" and s in self.bird2id.keys():\n",
    "                        target[self.bird2id[s]] = self.secondary_coef\n",
    "        target = torch.from_numpy(target).float()\n",
    "        return target\n",
    "    \n",
    "    def prepare_spec(self, path):\n",
    "        wav = read_wav(path)\n",
    "        if self.mode=='train':\n",
    "            wav = crop_start_wav(wav, train_duration)\n",
    "        else:\n",
    "            wav = crop_start_wav(wav, train_duration)\n",
    "        if self.wave_transforms:\n",
    "            ttt = self.wave_transforms(wav[0, :].numpy(), sample_rate=32000)\n",
    "            # print(ttt)\n",
    "            wav[0, :] = torch.tensor(ttt).float() #self.wave_transforms(wav[0, :], sample_rate=32000)\n",
    "        tmp = self.mel_transform(wav)\n",
    "        if self.mode==\"train\":\n",
    "            tmp[0, :] = random_power(tmp[0, :], power=3, c=0.5)\n",
    "#         print(tmp.shape)\n",
    "        mel_spectrogram = normalize_melspec(self.db_transform(tmp))\n",
    "        mel_spectrogram = mel_spectrogram * 255\n",
    "        mel_spectrogram = mel_spectrogram.expand(3, -1, -1).permute(1, 2, 0).numpy()\n",
    "        return mel_spectrogram\n",
    "\n",
    "#     def prepare_spec(self, path):\n",
    "#         wav = read_wav(path)\n",
    "#         wav = crop_start_wav(wav, train_duration)\n",
    "#         mel_spectrogram = normalize_melspec(self.db_transform(self.mel_transform(wav)))\n",
    "#         mel_spectrogram = mel_spectrogram * 255\n",
    "#         mel_spectrogram = mel_spectrogram.expand(3, -1, -1).permute(1, 2, 0).numpy()\n",
    "#         return mel_spectrogram\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df[\"path\"].iloc[idx]\n",
    "        primary_label = self.df[\"primary_label\"].iloc[idx]\n",
    "        secondary_labels = self.df[\"secondary_labels\"].iloc[idx]\n",
    "        rating = self.df[\"rating\"].iloc[idx]\n",
    "\n",
    "        spec = self.prepare_spec(path)\n",
    "        target = self.prepare_target(primary_label, secondary_labels)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            res = self.transform(image=spec)\n",
    "            spec = res['image'].astype(np.float32)\n",
    "        else:\n",
    "            spec = spec.astype(np.float32)\n",
    "\n",
    "        spec = spec.transpose(2, 0, 1)\n",
    "\n",
    "        return {\"spec\": spec, \"target\": target, 'rating': rating}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c40a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_melspec(X, eps=1e-6):\n",
    "    mean = X.mean((1, 2), keepdim=True)\n",
    "    std = X.std((1, 2), keepdim=True)\n",
    "    Xstd = (X - mean) / (std + eps)\n",
    "\n",
    "    norm_min, norm_max = (\n",
    "        Xstd.min(-1)[0].min(-1)[0],\n",
    "        Xstd.max(-1)[0].max(-1)[0],\n",
    "    )\n",
    "    fix_ind = (norm_max - norm_min) > eps * torch.ones_like(\n",
    "        (norm_max - norm_min)\n",
    "    )\n",
    "    V = torch.zeros_like(Xstd)\n",
    "    if fix_ind.sum():\n",
    "        V_fix = Xstd[fix_ind]\n",
    "        norm_max_fix = norm_max[fix_ind, None, None]\n",
    "        norm_min_fix = norm_min[fix_ind, None, None]\n",
    "        V_fix = torch.max(\n",
    "            torch.min(V_fix, norm_max_fix),\n",
    "            norm_min_fix,\n",
    "        )\n",
    "        V_fix = (V_fix - norm_min_fix) / (norm_max_fix - norm_min_fix)\n",
    "        V[fix_ind] = V_fix\n",
    "    return V\n",
    "\n",
    "\n",
    "def read_wav(path):\n",
    "    wav, org_sr = torchaudio.load(path, normalize=True)\n",
    "    wav = torchaudio.functional.resample(wav, orig_freq=org_sr, new_freq=mel_spec_params[\"sample_rate\"])\n",
    "    return wav\n",
    "\n",
    "\n",
    "def crop_start_wav(wav, duration_):\n",
    "    while wav.size(-1) < duration_:\n",
    "        wav = torch.cat([wav, wav], dim=1)\n",
    "    wav = wav[:, :duration_]\n",
    "    return wav\n",
    "\n",
    "\n",
    "class BirdDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform=None, add_secondary_labels=True):\n",
    "        self.df = df\n",
    "        self.bird2id = bird2id\n",
    "        self.num_classes = num_classes\n",
    "        self.secondary_coef = secondary_coef\n",
    "        self.add_secondary_labels = add_secondary_labels\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(**mel_spec_params)\n",
    "        self.db_transform = torchaudio.transforms.AmplitudeToDB(stype='power', top_db=top_db)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def prepare_target(self, primary_label, secondary_labels):\n",
    "        secondary_labels = eval(secondary_labels)\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if primary_label != 'nocall':\n",
    "            primary_label = self.bird2id[primary_label]\n",
    "            target[primary_label] = 1.0\n",
    "            if self.add_secondary_labels:\n",
    "                for s in secondary_labels:\n",
    "                    if s != \"\" and s in self.bird2id.keys():\n",
    "                        target[self.bird2id[s]] = self.secondary_coef\n",
    "        target = torch.from_numpy(target).float()\n",
    "        return target\n",
    "\n",
    "    def prepare_spec(self, path):\n",
    "        wav = read_wav(path)\n",
    "        wav = crop_start_wav(wav, train_duration)\n",
    "        mel_spectrogram = normalize_melspec(self.db_transform(self.mel_transform(wav)))\n",
    "        mel_spectrogram = mel_spectrogram * 255\n",
    "        mel_spectrogram = mel_spectrogram.expand(3, -1, -1).permute(1, 2, 0).numpy()\n",
    "        return mel_spectrogram\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df[\"path\"].iloc[idx]\n",
    "        primary_label = self.df[\"primary_label\"].iloc[idx]\n",
    "        secondary_labels = self.df[\"secondary_labels\"].iloc[idx]\n",
    "        rating = self.df[\"rating\"].iloc[idx]\n",
    "\n",
    "        spec = self.prepare_spec(path)\n",
    "        target = self.prepare_target(primary_label, secondary_labels)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            res = self.transform(image=spec)\n",
    "            spec = res['image'].astype(np.float32)\n",
    "        else:\n",
    "            spec = spec.astype(np.float32)\n",
    "\n",
    "        spec = spec.transpose(2, 0, 1)\n",
    "\n",
    "        return {\"spec\": spec, \"target\": target, 'rating': rating}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80681e",
   "metadata": {
    "papermill": {
     "duration": 0.012246,
     "end_time": "2024-05-12T08:01:22.921605",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.909359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df0c52df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.948162Z",
     "iopub.status.busy": "2024-05-12T08:01:22.947478Z",
     "iopub.status.idle": "2024-05-12T08:01:22.951718Z",
     "shell.execute_reply": "2024-05-12T08:01:22.950791Z"
    },
    "papermill": {
     "duration": 0.019548,
     "end_time": "2024-05-12T08:01:22.953599",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.934051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CNN_ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325ad2e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.638517Z",
     "start_time": "2024-05-02T08:55:35.63072Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.979453Z",
     "iopub.status.busy": "2024-05-12T08:01:22.979172Z",
     "iopub.status.idle": "2024-05-12T08:01:22.990401Z",
     "shell.execute_reply": "2024-05-12T08:01:22.989550Z"
    },
    "papermill": {
     "duration": 0.02635,
     "end_time": "2024-05-12T08:01:22.992297",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.965947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeM(torch.nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = torch.nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, ch, h, w = x.shape\n",
    "        x = torch.nn.functional.avg_pool2d(x.clamp(min=self.eps).pow(self.p), (x.size(-2), x.size(-1))).pow(\n",
    "            1.0 / self.p)\n",
    "        x = x.view(bs, ch)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, backbone, pretrained):\n",
    "        super().__init__()\n",
    "\n",
    "        out_indices = (3, 4)\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone,\n",
    "            features_only=True,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=3,\n",
    "            num_classes=num_classes,\n",
    "            out_indices=out_indices,\n",
    "        )\n",
    "        feature_dims = self.backbone.feature_info.channels()\n",
    "        print(f\"feature dims: {feature_dims}\")\n",
    "\n",
    "        self.global_pools = torch.nn.ModuleList([GeM() for _ in out_indices])\n",
    "        self.mid_features = np.sum(feature_dims)\n",
    "        self.neck = torch.nn.BatchNorm1d(self.mid_features)\n",
    "        self.head = torch.nn.Linear(self.mid_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        ms = self.backbone(x)\n",
    "        h = torch.cat([global_pool(m) for m, global_pool in zip(ms, self.global_pools)], dim=1)\n",
    "        x = self.neck(h)\n",
    "        x = self.head(x)\n",
    "#         print(x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b5a23a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.018966Z",
     "iopub.status.busy": "2024-05-12T08:01:23.018683Z",
     "iopub.status.idle": "2024-05-12T08:01:23.056797Z",
     "shell.execute_reply": "2024-05-12T08:01:23.055941Z"
    },
    "papermill": {
     "duration": 0.054001,
     "end_time": "2024-05-12T08:01:23.058736",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.004735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def init_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Conv2d\") != -1:\n",
    "        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        model.weight.data.normal_(1.0, 0.02)\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"GRU\") != -1:\n",
    "        for weight in model.parameters():\n",
    "            if len(weight.size()) > 1:\n",
    "                nn.init.orghogonal_(weight.data)\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        model.weight.data.normal_(0, 0.01)\n",
    "        model.bias.data.zero_()\n",
    "\n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    output = F.interpolate(\n",
    "        framewise_output.unsqueeze(1),\n",
    "        size=(frames_num, framewise_output.size(2)),\n",
    "        align_corners=True,\n",
    "        mode=\"bilinear\").squeeze(1)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class TimmSED(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            base_model_name: str,\n",
    "            config=None,\n",
    "            pretrained=False,\n",
    "            num_classes=24,\n",
    "            in_channels=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        self.spec_augmenter = SpecAugmentation(\n",
    "            time_drop_width=64 // 2,\n",
    "            time_stripes_num=2,\n",
    "            freq_drop_width=8 // 2,\n",
    "            freq_stripes_num=2\n",
    "        )\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(self.config.n_mels)\n",
    "\n",
    "        base_model = timm.create_model(\n",
    "            base_model_name,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=in_channels,\n",
    "        )\n",
    "\n",
    "        layers = list(base_model.children())[:-2]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        if \"eca_nfnet_l0\" == base_model_name:\n",
    "            in_features = base_model.num_features\n",
    "        elif hasattr(base_model, \"fc\"):\n",
    "            in_features = base_model.fc.in_features\n",
    "        else:\n",
    "            in_features = base_model.classifier.in_features\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n",
    "        self.att_block = AttBlockV2(\n",
    "            in_features, num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        # self.init_weight()\n",
    "        if len(self.config.local_pretrain_path) > 0:\n",
    "\n",
    "            print(\"load from local\")\n",
    "            state_dict = self.state_dict()\n",
    "            avg_state_dict = {}\n",
    "\n",
    "            for model_path in self.config.local_pretrain_path:\n",
    "\n",
    "                if model_path[-3:] == \"pth\":\n",
    "                    model_state_dict = torch.load(model_path)[\"model\"]\n",
    "                elif model_path[-3:] == \"bin\":\n",
    "                    model_state_dict = torch.load(model_path, map_location='cuda:0')\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                # model_state_dict = torch.load(model_path)[\"model\"]\n",
    "                backbone_keys = [key for key in model_state_dict.keys()]\n",
    "                print(\"load from local 2\")\n",
    "                for backbone_key in backbone_keys:\n",
    "                    base_model_key = backbone_key\n",
    "\n",
    "                    if base_model_key not in avg_state_dict:\n",
    "                        avg_state_dict[base_model_key] = model_state_dict[backbone_key] / \\\n",
    "                                                            len(self.config.local_pretrain_path)\n",
    "                    else:\n",
    "                        avg_state_dict[base_model_key] += model_state_dict[backbone_key] / \\\n",
    "                                                         len(self.config.local_pretrain_path)\n",
    "\n",
    "            print(len(state_dict.keys()), len(avg_state_dict.keys()))\n",
    "            for key, key_ in zip(state_dict.keys(), avg_state_dict.keys()):\n",
    "#                 print(key, key_)\n",
    "#                 if 'att_block' or 'bn0' in key:\n",
    "                if 'att_block' in key:\n",
    "                    # print(key)\n",
    "                    continue\n",
    "                state_dict[key] = avg_state_dict[key_]\n",
    "\n",
    "            self.load_state_dict(state_dict)\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # x = input_data  # (batch_size, 3, time_steps, mel_bins)\n",
    "        x = input_data[:, [0], :, :]  # (batch_size, 1, time_steps, mel_bins)\n",
    "        x = x.transpose(2, 3)\n",
    "        # print(x.shape, 'in')\n",
    "\n",
    "        frames_num = x.shape[2]\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        if self.training:\n",
    "            if random.random() < 0.25:\n",
    "                x = self.spec_augmenter(x)\n",
    "\n",
    "        x = x.transpose(2, 3)\n",
    "\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # Aggregate in frequency axis\n",
    "        x = torch.mean(x, dim=2)\n",
    "\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        \n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        interpolate_ratio = frames_num // segmentwise_output.size(1)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n",
    "        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"segmentwise_output\": segmentwise_output,\n",
    "            \"clipwise_output\": clipwise_output,\n",
    "            \"logit\": logit,\n",
    "            \"framewise_logit\": framewise_logit.max(dim=1)[0],\n",
    "            \"segmentwise_logit\": segmentwise_logit.max(dim=1)[0],            \n",
    "        }\n",
    "        \n",
    "        # segmentwise_logit = segmentwise_output? logit=clipwise_output? framewise_logit=framewise_output?\n",
    "        return output_dict\n",
    "        \n",
    "        \n",
    "#         torch.sigmoid(preds['logit'])\n",
    "#         segmentwise_output_with_max, _ = segmentwise_output.max(dim=1)\n",
    "#         logit = torch.sigmoid(logit)\n",
    "#         clipwise_output = clipwise_output\n",
    "#         print(segmentwise_output_with_max.shape)\n",
    "#         print(clipwise_output.shape)\n",
    "#         print(logit.shape)\n",
    "#         return logit #segmentwise_output_with_max# (segmentwise_output_with_max+logit+clipwise_output)/3\n",
    "#         print(torch.sigmoid(logit).shape)\n",
    "        \n",
    "        \n",
    "#         return output_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c2a92",
   "metadata": {
    "papermill": {
     "duration": 0.012125,
     "end_time": "2024-05-12T08:01:23.083445",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.071320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89772f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.109961Z",
     "iopub.status.busy": "2024-05-12T08:01:23.109631Z",
     "iopub.status.idle": "2024-05-12T08:01:23.118790Z",
     "shell.execute_reply": "2024-05-12T08:01:23.117919Z"
    },
    "papermill": {
     "duration": 0.024788,
     "end_time": "2024-05-12T08:01:23.120764",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.095976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sigmoid_focal_loss(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    alpha: float = 0.25,\n",
    "    gamma: float = 2,\n",
    "    reduction: str = \"none\",\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
    "\n",
    "    Args:\n",
    "        inputs (Tensor): A float tensor of arbitrary shape.\n",
    "                The predictions for each example.\n",
    "        targets (Tensor): A float tensor with the same shape as inputs. Stores the binary\n",
    "                classification label for each element in inputs\n",
    "                (0 for the negative class and 1 for the positive class).\n",
    "        alpha (float): Weighting factor in range (0,1) to balance\n",
    "                positive vs negative examples or -1 for ignore. Default: ``0.25``.\n",
    "        gamma (float): Exponent of the modulating factor (1 - p_t) to\n",
    "                balance easy vs hard examples. Default: ``2``.\n",
    "        reduction (string): ``'none'`` | ``'mean'`` | ``'sum'``\n",
    "                ``'none'``: No reduction will be applied to the output.\n",
    "                ``'mean'``: The output will be averaged.\n",
    "                ``'sum'``: The output will be summed. Default: ``'none'``.\n",
    "    Returns:\n",
    "        Loss tensor with the reduction option applied.\n",
    "    \"\"\"\n",
    "    # Original implementation from https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/focal_loss.py\n",
    "\n",
    "\n",
    "    p = torch.sigmoid(inputs)\n",
    "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "    p_t = p * targets + (1 - p) * (1 - targets)\n",
    "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
    "\n",
    "    if alpha >= 0:\n",
    "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        loss = alpha_t * loss\n",
    "\n",
    "    # Check reduction option and return loss accordingly\n",
    "    if reduction == \"none\":\n",
    "        pass\n",
    "    elif reduction == \"mean\":\n",
    "        loss = loss.mean()\n",
    "    elif reduction == \"sum\":\n",
    "        loss = loss.sum()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid Value for arg 'reduction': '{reduction} \\n Supported reduction modes: 'none', 'mean', 'sum'\"\n",
    "        )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "732bb63f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.645087Z",
     "start_time": "2024-05-02T08:55:35.638517Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.146894Z",
     "iopub.status.busy": "2024-05-12T08:01:23.146585Z",
     "iopub.status.idle": "2024-05-12T08:01:23.154236Z",
     "shell.execute_reply": "2024-05-12T08:01:23.153367Z"
    },
    "papermill": {
     "duration": 0.023005,
     "end_time": "2024-05-12T08:01:23.156211",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.133206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLossBCE(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            alpha: float = 0.25,\n",
    "            gamma: float = 2,\n",
    "            reduction: str = \"mean\",\n",
    "            bce_weight: float = 1.0,\n",
    "            focal_weight: float = 1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.bce = torch.nn.BCEWithLogitsLoss(reduction=reduction)\n",
    "        self.bce_weight = bce_weight\n",
    "        self.focal_weight = focal_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        focall_loss = sigmoid_focal_loss(\n",
    "            inputs=logits,\n",
    "            targets=targets,\n",
    "            alpha=self.alpha,\n",
    "            gamma=self.gamma,\n",
    "            reduction=self.reduction,\n",
    "        )\n",
    "        bce_loss = self.bce(logits, targets.float())\n",
    "        return self.bce_weight * bce_loss + self.focal_weight * focall_loss\n",
    "\n",
    "\n",
    "criterion = FocalLossBCE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9419a907",
   "metadata": {
    "papermill": {
     "duration": 0.012077,
     "end_time": "2024-05-12T08:01:23.180744",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.168667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Init Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "656a0357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.652735Z",
     "start_time": "2024-05-02T08:55:35.645087Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.207008Z",
     "iopub.status.busy": "2024-05-12T08:01:23.206680Z",
     "iopub.status.idle": "2024-05-12T08:01:23.214947Z",
     "shell.execute_reply": "2024-05-12T08:01:23.213991Z"
    },
    "papermill": {
     "duration": 0.023685,
     "end_time": "2024-05-12T08:01:23.216925",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.193240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_logger(log_file='train.log'):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b20f4",
   "metadata": {
    "papermill": {
     "duration": 0.012363,
     "end_time": "2024-05-12T08:01:23.241926",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.229563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train and Val Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa038469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.660572Z",
     "start_time": "2024-05-02T08:55:35.652735Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.270485Z",
     "iopub.status.busy": "2024-05-12T08:01:23.269405Z",
     "iopub.status.idle": "2024-05-12T08:01:23.300105Z",
     "shell.execute_reply": "2024-05-12T08:01:23.299044Z"
    },
    "papermill": {
     "duration": 0.046671,
     "end_time": "2024-05-12T08:01:23.302224",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.255553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    data2 = data[indices]\n",
    "    targets2 = targets[indices]\n",
    "\n",
    "    lam = torch.FloatTensor([np.random.beta(alpha, alpha)])\n",
    "    data = data * lam + data2 * (1 - lam)\n",
    "    targets = targets * lam + targets2 * (1 - lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix(data, targets, alpha):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
    "    data[:, :, bbx1:bbx2, bby1:bby2] = data[indices, :, bbx1:bbx2, bby1:bby2]\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
    "    targets = targets * lam + shuffled_targets * (1 - lam)\n",
    "#     new_targets = [targets, shuffled_targets, lam]\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler=None):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    gt = []\n",
    "    preds = []\n",
    "    bar = tqdm(loader, total=len(loader))\n",
    "    for batch in bar:\n",
    "        optimizer.zero_grad()\n",
    "        spec = batch['spec']\n",
    "        target = batch['target']\n",
    "        \n",
    "#         print(spec.shape)\n",
    "        \n",
    "        if np.random.rand() < 0.5:\n",
    "            spec, target = mixup(spec, target, 0.4)\n",
    "        else:\n",
    "            spec, target = cutmix(spec, target, 0.4)\n",
    "\n",
    "        spec = spec.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(spec)\n",
    "                if CNN_:\n",
    "                    loss = criterion(logits, target)\n",
    "                else:\n",
    "                    loss_1 = criterion(logits['logit'], target)\n",
    "                    loss_2 = criterion(logits['framewise_logit'], target)\n",
    "                    loss_3 = criterion(logits['segmentwise_logit'], target)\n",
    "    #                 loss_4 = criterion(logits['clipwise_output'], target)\n",
    "                    loss = (loss_1+loss_2+loss_3)/3\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits = model(spec)\n",
    "            if CNN_:\n",
    "                loss = criterion(logits, target)\n",
    "            else:\n",
    "                loss_1 = criterion(logits['logit'], target)\n",
    "                loss_2 = criterion(logits['framewise_logit'], target)\n",
    "                loss_3 = criterion(logits['segmentwise_logit'], target)\n",
    "                loss = (loss_1+loss_2+loss_3)/3\n",
    "            \n",
    "            loss.backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.update(loss.item(), batch[\"spec\"].size(0))\n",
    "        bar.set_postfix(\n",
    "            loss=losses.avg,\n",
    "            grad=grad_norm.item(),\n",
    "            lr=optimizer.param_groups[0][\"lr\"]\n",
    "        )\n",
    "        gt.append(target.cpu().detach().numpy())\n",
    "        if CNN_:\n",
    "            preds.append(logits.sigmoid().cpu().detach().numpy())\n",
    "        else:\n",
    "            preds.append(((logits['logit']+logits['framewise_logit']+logits['segmentwise_logit'])/3).sigmoid().cpu().detach().numpy())\n",
    "        \n",
    "#         break\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "#     print(gt, preds.shape, target_columns)\n",
    "\n",
    "    gt = np.array(gt, dtype=np.int32)\n",
    "    scores = calculate_competition_metrics(gt, preds, target_columns)\n",
    "\n",
    "    return scores, losses.avg\n",
    "\n",
    "\n",
    "def valid_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    bar = tqdm(loader, total=len(loader))\n",
    "    gt = []\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in bar:\n",
    "            spec = batch['spec'].to(device)\n",
    "            target = batch['target'].to(device)\n",
    "\n",
    "            logits = model(spec)\n",
    "            if CNN_:\n",
    "                loss = criterion(logits, target)\n",
    "            else:\n",
    "                loss_1 = criterion(logits['logit'], target)\n",
    "                loss_2 = criterion(logits['framewise_logit'], target)\n",
    "                loss_3 = criterion(logits['segmentwise_logit'], target)\n",
    "                loss = (loss_1+loss_2+loss_3)/3\n",
    "\n",
    "            losses.update(loss.item(), batch[\"spec\"].size(0))\n",
    "\n",
    "            gt.append(target.cpu().detach().numpy())\n",
    "            if CNN_:\n",
    "                preds.append(logits.sigmoid().cpu().detach().numpy())\n",
    "            else:\n",
    "                preds.append(((logits['logit']+logits['framewise_logit']+logits['segmentwise_logit'])/3).sigmoid().cpu().detach().numpy())\n",
    "        \n",
    "            bar.set_postfix(loss=losses.avg)\n",
    "#             break\n",
    "\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "#     print(gt)\n",
    "#     print(gt, preds.shape, target_columns)\n",
    "    gt = np.array(gt, dtype=np.int32)\n",
    "    scores = calculate_competition_metrics(gt, preds, target_columns)\n",
    "    return scores, losses.avg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f9986",
   "metadata": {
    "papermill": {
     "duration": 0.012291,
     "end_time": "2024-05-12T08:01:23.327540",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.315249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "564ee056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.674443Z",
     "start_time": "2024-05-02T08:55:35.66805Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.356017Z",
     "iopub.status.busy": "2024-05-12T08:01:23.355134Z",
     "iopub.status.idle": "2024-05-12T08:01:23.363402Z",
     "shell.execute_reply": "2024-05-12T08:01:23.362464Z"
    },
    "papermill": {
     "duration": 0.024923,
     "end_time": "2024-05-12T08:01:23.365386",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.340463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix Warmup Bug\n",
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfc8314",
   "metadata": {
    "papermill": {
     "duration": 0.012343,
     "end_time": "2024-05-12T08:01:23.390457",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.378114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transformation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aafb3f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.417300Z",
     "iopub.status.busy": "2024-05-12T08:01:23.416930Z",
     "iopub.status.idle": "2024-05-12T08:01:23.422177Z",
     "shell.execute_reply": "2024-05-12T08:01:23.421262Z"
    },
    "papermill": {
     "duration": 0.020951,
     "end_time": "2024-05-12T08:01:23.424271",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.403320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "mean = (0.485, 0.456, 0.406)  # RGB\n",
    "std = (0.229, 0.224, 0.225)  # RGB\n",
    "\n",
    "transforms_train = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "#     A.Resize(128, 256),\n",
    "    A.CoarseDropout(max_height=int(128 * 0.375), max_width=int(128 * 0.375), max_holes=1, p=0.7),\n",
    "    A.Normalize(mean,std)\n",
    "])\n",
    "\n",
    "transforms_val = A.Compose([\n",
    "#     A.Resize(128, 256),\n",
    "    A.Normalize(mean,std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b1cf27",
   "metadata": {
    "papermill": {
     "duration": 0.01261,
     "end_time": "2024-05-12T08:01:23.451021",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.438411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scheduler Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0582e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.load(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/Train mnasnet/outputs/exp1/fold2_rgb_9682.bin\")[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a78383a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(a,\"rgb9682.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f45799d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.478668Z",
     "iopub.status.busy": "2024-05-12T08:01:23.478342Z",
     "iopub.status.idle": "2024-05-12T08:01:23.484427Z",
     "shell.execute_reply": "2024-05-12T08:01:23.483714Z"
    },
    "papermill": {
     "duration": 0.022396,
     "end_time": "2024-05-12T08:01:23.486367",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.463971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    base_model_name = 'mnasnet_100'\n",
    "    pretrained = False\n",
    "    num_classes = 182\n",
    "    in_channels = 1\n",
    "    n_mels = 128\n",
    "    local_pretrain_path = [\n",
    "#         \"/kaggle/input/mnasnet/fold-0_0.8900275134065998.bin\"\n",
    "        #   \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/pretrain_models/mnasnet_2.bin\"\n",
    "          \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/Train mnasnet/rgb9682.bin\"\n",
    "        # \"/kaggle/input/spnasnet-128-320/fold-0_0.8834222108826184.bin\",\n",
    "#         \"/kaggle/input/spnasnet-128-320/fold-1_0.8951362703845499.bin\",\n",
    "#         \"/kaggle/input/spnasnet-128-320/fold-2_0.8902828133741624.bin\",\n",
    "#         \"/kaggle/input/spnasnet-128-320/fold-3_0.886560187250359.bin\",\n",
    "    ]\n",
    "    \n",
    "config = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22a6e147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.869499Z",
     "start_time": "2024-05-02T08:55:35.674443Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.513349Z",
     "iopub.status.busy": "2024-05-12T08:01:23.512534Z",
     "iopub.status.idle": "2024-05-12T08:01:24.667899Z",
     "shell.execute_reply": "2024-05-12T08:01:24.666953Z"
    },
    "papermill": {
     "duration": 1.171127,
     "end_time": "2024-05-12T08:01:24.669992",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.498865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from local\n",
      "load from local 2\n",
      "323 323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x785aed5dcf10>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABm0AAADFCAYAAAC2AraWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABao0lEQVR4nO3deZxU9Z3v/3ftSy/VG91NQwPNIktQMaAtaDSJ/aMVzf1hmBlxnHEduTcXmBD0IqjgOBoRM0mQaCQ6uZG5V67G373hjpghEowmGXsQIcaFRdnX3ru6uqq79vP7oxa66GZpBappXs/Hox7nnO/5nlPf049HTmze/fl+TYZhGAIAAAAAAAAAAEBWmbM9AAAAAAAAAAAAABDaAAAAAAAAAAAA9AuENgAAAAAAAAAAAP0AoQ0AAAAAAAAAAEA/QGgDAAAAAAAAAADQDxDaAAAAAAAAAAAA9AOENgAAAAAAAAAAAP2ANdsDGGji8biOHj2qvLw8mUymbA8HAAAAAAAAAABkkWEY6ujoUEVFhczmU9fSENqcZUePHlVlZWW2hwEAAAAAAAAAAPqRQ4cOaejQoafsQ2hzluXl5UlK/PDz8/OzPBoAAAAAAAAAAJBNPp9PlZWV6fzgVAhtzrLUlGj5+fmENgAAAAAAAAAAQJLOaEmVU0+eBgAAAAAAAAAAgPPiC4U2zz//vEaMGCGn06nq6mq9//77p+z/+uuva9y4cXI6nbr00kv161//OuO8YRhatmyZBg8eLJfLpZqaGn3++ecZfVpbW3XHHXcoPz9fBQUFuu++++T3+9Png8Gg7r77bl166aWyWq2aOXNmr2N555139NWvflUOh0OjR4/Wyy+//KWfDwAAAAAAAAAA4Mvqc2jz2muvaeHChXrssce0bds2XX755aqtrVVjY2Ov/d977z3dfvvtuu+++/SnP/1JM2fO1MyZM/XJJ5+k+zzzzDNatWqVVq9erc2bNysnJ0e1tbUKBoPpPnfccYc+/fRTbdy4UevXr9fvf/97zZkzJ30+FovJ5XLp7//+71VTU9PrWPbt26ebb75Z3/jGN/Thhx9qwYIF+ru/+zv95je/+cLPBwAAAAAAAAAAcDaYDMMw+nJBdXW1rrzySj333HOSpHg8rsrKSs2fP1+LFy/u0f+2225TIBDQ+vXr021XX321Jk2apNWrV8swDFVUVOiBBx7Qgw8+KElqb29XWVmZXn75Zc2ePVs7duzQhAkTtGXLFk2ZMkWStGHDBs2YMUOHDx9WRUVFxnfefffd8nq9WrduXUb7Qw89pDfffDMjMJo9e7a8Xq82bNjwhZ4vFAopFAqlj1MLCrW3t7OmzUVoy/5W/eitzxSJxb/UfUwmyaTk/IYmpfbS7ampD7sfm0wmmU2SOWNrktmcOne83dStn8VsSnxMJlnMZlnMktlskvUkbWZT8pzFLGuyzWYxy2oxJY9T+4mtLblv6dbPbjHLbjXLZjHLZkm02y1mmc2nn9MRAAAAAAAAAC4kPp9PHo/njHIDa19uHA6HtXXrVi1ZsiTdZjabVVNTo7q6ul6vqaur08KFCzPaamtr04HKvn37VF9fn1Ed4/F4VF1drbq6Os2ePVt1dXUqKChIBzaSVFNTI7PZrM2bN+vWW289o/HX1dX1qMKpra3VggULvvDzLV++XI8//vgZfT8GtlA0pgd++WcdbO3M9lAuWIlgJxHiONKhjjmjzW41y2G1JLe9t/XWx2GzyGk1y2mzyJHcJj6Jvk7b8XNnsiAYAAAAAAAAAJxtfQptmpubFYvFVFZWltFeVlamnTt39npNfX19r/3r6+vT51Ntp+pTWlqaOXCrVUVFRek+Z+JkY/H5fOrq6lJbW1ufn2/JkiUZoVSq0gYXn5f/fb8OtnaqNM+hx//TV/RF/93fMCQjY9/IaO9eHJfajRuGDCNzG08fH9+PG0oeJ/ZjcUPxuKGYYSgWP+FzirZo3FAslthG43FFY8e3kbihaCyuWNxQJBZP9Ol2PhxL9kue6y71PcFIXB1f7Md3VqSCHqfNIpfdIlf3rc0iZ3Lfndw6eznvtlnkdljktlvltluSn8Q+wRAAAAAAAACA3vQptEFPDodDDocj28NAljV1hPSTt3dLkhbdOE43XTo4yyO6MMTjhiLxuCIxQ5FoXOFYXOFoXJFYsi2WaOt+LhyNK5TexhTKOM5s774fjKS2cYUisW7HMQWjiZApJXVPXzB6Tp7bbFKvYY7LblGO3aoch1W5DovcDqtyHVbl2C3JNmuyLXGcY0+1WeSwWs7JWAEAAAAAAACcP30KbUpKSmSxWNTQ0JDR3tDQoPLy8l6vKS8vP2X/1LahoUGDBw/O6DNp0qR0n8bGxox7RKNRtba2nvR7+zKW/Px8uVwuWSyWPj8fIEk/2viZ/KGoLh3i0bevGJLt4VwwzGaTHGaLHFZJWc4+I7H48RAnElMwkgp6YuoMx9QVjqkreS6xH1dXOKquSKK9K5zo3xWJqTMcVVc4cV3iE1VnOBESSVLckPyhqPyhsxcK2Swm5TqsynValeuwKS+9b1WeM7Gflwx+cp224+3JfnlOq/KdNjlthD8AAAAAAABAtvQptLHb7Zo8ebI2bdqkmTNnSpLi8bg2bdqkefPm9XrN1KlTtWnTpvS6MZK0ceNGTZ06VZJUVVWl8vJybdq0KR3S+Hw+bd68Wd/5znfS9/B6vdq6dasmT54sSXr77bcVj8dVXV19xuOfOnWqfv3rX2e0dR/LF3k+YPtRn17bclCStPSWCTKbmfbqQpRaPyfXce4KEKOxeDLUyQxzOsMxdYai6TZ/KLWNKhCKKhCKKRBO7PtDMQVC0fT5YCQRBEVihto6I2rrjEjq+sJjtFvMiQDHZVNetzAnsW/LOM532ZTvtMnjsinfZZXHlQiDmPoNAAAAAAAA+GL6/K+TCxcu1F133aUpU6boqquu0sqVKxUIBHTPPfdIku68804NGTJEy5cvlyR997vf1fXXX68f/vCHuvnmm/Xqq6/qgw8+0IsvvihJMplMWrBggZ588kmNGTNGVVVVWrp0qSoqKtLByfjx43XjjTfq/vvv1+rVqxWJRDRv3jzNnj1bFRUV6bFt375d4XBYra2t6ujo0IcffihJ6TDov/yX/6LnnntOixYt0r333qu3335bv/zlL/Xmm2+e8fMB3RmGoSfWb1fckG6+dLCuqirK9pDQj1ktZuVZzMpz2s7aPaOxuDojMfmDiVCnIxSVP5gIdPzB7scR+UNRdXQ/F4yqIxhJ9AlFZRhSOBZXSyCslkD4C43HbFKvYc7x48SnwGVTgdumApddHpdNHneiOojQEwAAAAAAABezPoc2t912m5qamrRs2TLV19dr0qRJ2rBhg8rKyiRJBw8elNlsTvefNm2a1q5dq0cffVQPP/ywxowZo3Xr1mnixInpPosWLVIgENCcOXPk9Xp17bXXasOGDXI6nek+r7zyiubNm6cbbrhBZrNZs2bN0qpVqzLGNmPGDB04cCB9fMUVV0g6vnB7VVWV3nzzTX3ve9/Ts88+q6FDh+qf//mfVVtbe8bPB3S3cXuD6va2yG41a/FN47I9HFyErBaz8i1m5X/JICgeNxQIR+VLBTnBqHxdkXSw4wtG5QumjhPnfMGIfF0RtXcljsOxuOKG5O2MyNsZ6fMYzCbJ47KpwG1PbhNBT4HLJo/bng56Ct329LbQbVeek7AHAAAAAAAAA4PJSCUaOCt8Pp88Ho/a29uVn5+f7eHgHApFY5r+49/rQEun/uvXR2nRjYQ2uLgFI7FkiJP4+ILJ/c5E6NPeFck4396VCHe8XeH0NG9fhNkkFWQEOYng5/g2sV+YY1dR8lPgsslqMZ/+5gAAAAAAAMCX1Jfc4Nwt3gAMcP/y3gEdaOlUSa5D//Ubo7M9HCDrnDaLnDaLSvOdp+98glTg400FOZ1heZOBT3tXIthJVfC0dYbT285wTHFDag2E1RoISwqc8Xd6XDYV5SQCnaIch4pyksGO+3i4U5hjV3Fyn/V6AAAAAAAAcK4R2gBfQIs/pFWbPpckLaode04XrwcuBl808AlFY+kApy2QCHva0sFOYj/dFgirNRn4SEpX++w7w++yW83pAKc416HiVKCTa1dJjiMR9KT2c+3KsVsIeQAAAAAAANAn/Esz8AX8+LefqSMU1Vcq8jVr8tBsDwe4aDmsFpXlW1TWh7AnGourvSuSrs5p6wyrNRBRayCk1kAkeZz56YrEFI7Gdaw9qGPtwTMcm1kluQ6V5NpVkutQcXqbaBvUbb/AbZeFdXkAAAAAAAAueoQ2QB/tqu/Q2s0HJUlLb5nAP7QCFxirxZyolMl1nPE1neGoWvyJAKclEFKLP6yWZKCT2A+l95v9IYWicYWicR3xdumIt+u09zebpKKc4wHPoLxksJOX2B+U61RJXiLoKXTbZea9AwAAAAAAMCAR2gB9YBiGnli/XXFDumliua4eWZztIQE4D9x2q9xFVlUWuU/b1zAMdYZjiQAnGfA0+0Nq7gipJRBWkz+kFn9Izf6wWvwhtXVGFDeU6OMPSeo45f0tZpOKc7oHOg6VJLeD8hwqTbaX5juZuhEAAAAAAOACw7/mAH3w9s5G/XF3s+wWs5bcND7bwwHQD5lMJuU4rMpxWDWs+PQhTyQWV1s6zAmnw5umjuTHH1JzR+J8ayCsWNxQY0dIjR2h097bbbccD3HynMkwJxHwlOY7VZoMeajeAQAAAAAA6B8IbYAzFI7G9f03d0iS7r226oz+MRYATsdmMScClDNYlycSi6eDne6hTno/edzoCyoQjqkzHNP+lk7tb+k85X2tZlMiwEkGOWX5TpXlJ45T+2V5ThW4bTKZCHcAAAAAAADOFUIb4Az9j/84oL3NAZXk2jX3G6OyPRwAFyGbxaxyj1PlntMHPIFQVI3JIKexI6hGXyjjuClZrdMaCCsaN3S0Paij7cFT3tNuMas0v1uok5cIdco9ibby/MTY3Hb+8wIAAAAAAOCL4F9VgDPQGgjr2d9+Jkl6YPpY5TltWR4RAJxajsOqKodVVSU5p+wXicXTAU6DL6hGX1ANvuR+x/FtayCscCyuw21dOtzWdcp75jmsKvMkQpxUqHN8P9FenOuQhSnZAAAAAAAAMhDaAGdg5W8/ky8Y1bjyPP3VlMpsDwcAzhqbxayKApcqClyn7BeKxtTUEVKDL5QMdoJq6AipoT2o+tSxLyR/KKqOUFQdjX7tbvSf9H4Ws0lleQ6Ve5wa7HElt85uW5dK8xyyWcxn+5EBAAAAAAD6LUIb4DQ+a+jQK5sPSpKWfWsCfxkO4KLksFo0tNCtoYWnXs/LH4qqvj0R4tR3C3TSbb7E1GyxjCnZvL3ey2SSBuU6uoU5x8OdwR5Xup1gBwAAAAAADBSENsApGIahJ9ZvVyxuaPqEMk0bVZLtIQFAv5brsGp0aa5Gl+aetE80FlezP6x6X1D17V061p4IddJbX5fq24OKxAw1Jqdu+/Ph9l7vlQ52ClwanO/U4AKnKjwuDS5IBDsVBU6V5jkJ3AEAAAAAwAWB0AY4hXd2NekPnzfLZjHp4Rnjsz0cABgQrBZzYm0bj1OqLOi1TzxuqLUz3C3MSYQ7x9qDOurtUr0vqGPeoMKx+PFg5yTfl5qKLTUNXOKTCHcqClwaUuBSvssqk4lgBwAAAAAAZBehDXASkVhcT7y5XZJ0zzVVGnGaxbwBAGeP2WxSSa5DJbkOTRzi6bWPYRhqCYR1zBvU0fYuHfMmgp2j7cH0fr0vmDkV24G2Xu+VY7dkhDpDCpyqKHBpsCcR6pR7nLJbmYYNAAAAAACcW4Q2wEm88h8HtLcpoOIcu+Z9c3S2hwMAOIHJdDzYuXRo78FOLG6oqSOUDHUSVTpHvF06mgp4vF1qCYQVCMf0eaNfnzf6T/JdUlmeU0MKj1fnDCl0aWhyW1HgUq6D/6wCAAAAAABfDv+6APTC2xnWj3/7uSRp4fRLlO+0ZXlEAIAvwmI2HZ+KbVjvfbrCMR1r79LRZKhztD0R6hztFvKEovHEGjy+oLaepFrH47Klw5whyWBnaKFLQwvdGlroUoHbxhRsAAAAAADglAhtgF6s/O3nau+KaFx5nm6bUpnt4QAAziGX3aKRg3I1clBur+dT07AdaUsEOOltt/32rkj6s/2Yr9f7uO2WdIjTPdAZUpjYL86xE+oAAAAAAHCRI7QBTrC7sUP/4z8OSJKW3jJBVgtrGADAxaz7NGyXVxb02scfiupIW6JC53D3YKetU4fbutTYEVJnOKbPGvz6rKH3KdicNnNGoFNZlKjQqUxW6hQR6gAAAAAAMOAR2gAn+P6bOxSLG6oZX6prRpdkezgAgAtArsOqseV5Glue1+v5YCSmY+1BHU6GOIfbOnWkrSu536WGjqCCkbh2N/q1+yTr6qQqdVIhTiLUOb7vcTGVJwAAAAAAFzpCG6Cbd3Y16ne7mmQ1m/TwjPHZHg4AYIBw2iyqKslRVUlOr+fD0biOtXelA53DbV061JrctnWqwXf6Sp08p1WVhW5VFiWCnWHF7vTx0EK3nDbLuXxEAAAAAABwFhDaAEnRWFxPvrlDknTXtBEnXdsAAICzzW41a3hxjoYX9x7qBCOxxNRryRAnFeocaktMwdbsD6sjGNX2Y76TrqlTmufQsCK3KovcqkxW51QWuTWsyK2yfKcsZqZeAwAAAAAg2whtgKS17x/U7ka/Ct02/f03x2R7OAAApDltFo0clHvSPyjoDCfW1DnU1qlDrV062NqpQ62dOpis1vGHomrsCKmxI6QPDrT1uN5mMWloYSrEcWlYMswZVpSjyiKX8pxMvQYAAAAAwPlAaANIau+M6EcbP5MkLfx/LpHHzT9OAQAuHG67VWPK8jSmrOeaOoZhyNsZSQQ5bZ3JQCcxDdvB1sTaOpGYoX3NAe1rDvR6/6Ice7oq53iok6NhxW6VU6UDAAAAAMBZQ2gDSHp20+fydkY0pjRXt181LNvDAQDgrDGZTCrMsaswx67LKwt6nI/FDR1r79Kh1sSUawdaAzrYrVqnNRBOf/58yNvjepvFlFw7x63hxYlgJzHVW2KftXQAAAAAADhzXyi0ef755/WDH/xA9fX1uvzyy/WTn/xEV1111Un7v/7661q6dKn279+vMWPGaMWKFZoxY0b6vGEYeuyxx/TSSy/J6/Xqmmuu0QsvvKAxY45PUdXa2qr58+frjTfekNls1qxZs/Tss88qN/f4NCEfffSR5s6dqy1btmjQoEGaP3++Fi1alD7/9a9/Xe+++26P8c2YMUNvvvmmJOnuu+/WmjVrMs7X1tZqw4YNff9B4YKwt8mvf6nbL0laessEWS3m7A4IAIDzyGJOTI02tNCtqaOKe5zvCEaSU64FdDA55drBZMBzuK1TkZihvc0B7T1JlU5ZvkPDk1U5w4vcGtYt2Cl022QyUaUDAAAAAEBKn0Ob1157TQsXLtTq1atVXV2tlStXqra2Vrt27VJpaWmP/u+9955uv/12LV++XLfccovWrl2rmTNnatu2bZo4caIk6ZlnntGqVau0Zs0aVVVVaenSpaqtrdX27dvldDolSXfccYeOHTumjRs3KhKJ6J577tGcOXO0du1aSZLP59P06dNVU1Oj1atX6+OPP9a9996rgoICzZkzR5L0f/7P/1E4HE6PraWlRZdffrn+8i//MmPMN954o37xi1+kjx0OR19/TLiAPPXrHYrGDX1zXKmuu2RQtocDAEC/kue0aUKFTRMq8nucS1XpHGzp1IHWTh1o6dTB1kBi29KpjlBUDb6QGnwhvb+/tZd7WzWiOBHojChOVugUuTWiJEeleQ4CHQAAAADARcdkGIbRlwuqq6t15ZVX6rnnnpMkxeNxVVZWav78+Vq8eHGP/rfddpsCgYDWr1+fbrv66qs1adIkrV69WoZhqKKiQg888IAefPBBSVJ7e7vKysr08ssva/bs2dqxY4cmTJigLVu2aMqUKZKkDRs2aMaMGTp8+LAqKir0wgsv6JFHHlF9fb3sdrskafHixVq3bp127tzZ67OsXLlSy5Yt07Fjx5STkyMpUWnj9Xq1bt26M/p5hEIhhUKh9LHP51NlZaXa29uVn9/zHzfQv/zh8yb97c/fl9Vs0oYF12l0ae8LPAMAgL4xDENtnREdaElW6CSDncQ2oAZf6JTXu2yWZEVOIsQZVuTWiOS0axUFLtbRAQAAAABcMHw+nzwezxnlBn2qtAmHw9q6dauWLFmSbjObzaqpqVFdXV2v19TV1WnhwoUZbbW1telQZN++faqvr1dNTU36vMfjUXV1terq6jR79mzV1dWpoKAgHdhIUk1NjcxmszZv3qxbb71VdXV1uu6669KBTep7VqxYoba2NhUWFvYY289//nPNnj07HdikvPPOOyotLVVhYaG++c1v6sknn1Rxcc/pQiRp+fLlevzxx0/yE0N/Fo3F9eT6HZKkv506nMAGAICzyGQyqSjHrqIcu64Y1vO/w7rCMR1s7dSBlkRlzoFkhc7+loCOtHWpKxLTroYO7Wro6HGtzWJSZTLEGVGcoxEliSqdEcVuDSlwMdUpAAAAAOCC1afQprm5WbFYTGVlZRntZWVlJ61mqa+v77V/fX19+nyq7VR9Tpx6zWq1qqioKKNPVVVVj3ukzp0Y2rz//vv65JNP9POf/zyj/cYbb9S3v/1tVVVVac+ePXr44Yd10003qa6uThZLz4V0lyxZkhFKpSpt0P+9uuWQdjV0yOOy6bs3jDn9BQAA4Kxx2S0aW56nseV5Pc6Fo3Ed8XalA539LQEdTG4PtXYpHItrb1NAe5t6rqNjNScCneHFxytzRpQkwp2hhS7ZCHQAAAAAAP1Yn9e0GSh+/vOf69JLL9VVV12V0T579uz0/qWXXqrLLrtMo0aN0jvvvKMbbrihx30cDgdr3lyA2rsi+tHGzyRJ36sZowK3/TRXAACA88VuNauqJEdVJTk9zqXW0UmFOQdaOrWvOZAOeELRuPY1B7SvOSCpKeNai9mkoYUujShO3DsV6FQlAx0qdAAAAAAA2dan0KakpEQWi0UNDQ0Z7Q0NDSovL+/1mvLy8lP2T20bGho0ePDgjD6TJk1K92lsbMy4RzQaVWtra8Z9evue7t+REggE9Oqrr+of//EfT/vMI0eOVElJiXbv3t1raIML03Nvf67WQFijBuXojquHZ3s4AADgDCWCF7eGFrp1zeiSjHPxuKGGjmAyxEmGOs3Hw52uSCwxFVtLp979LDPQSVXojEgFOcnqnKqSHNbQAQAAAACcN30Kbex2uyZPnqxNmzZp5syZkqR4PK5NmzZp3rx5vV4zdepUbdq0SQsWLEi3bdy4UVOnTpUkVVVVqby8XJs2bUqHND6fT5s3b9Z3vvOd9D28Xq+2bt2qyZMnS5LefvttxeNxVVdXp/s88sgjikQistls6e8ZO3Zsj6nRXn/9dYVCIf3N3/zNaZ/58OHDamlpyQiUcGHb1xzQy+/tlyQ9essEpkkBAGCAMJtNGuxxabDHpWmjMs8ZhqEGX0j7WwLa3xzQvuR2fzLUyajQ2ZUZ6NgtZlUWuVRVkquqEreqSnI1osStkSW5Kst3yGQi0AEAAAAAnB0mwzCMvlzw2muv6a677tLPfvYzXXXVVVq5cqV++ctfaufOnSorK9Odd96pIUOGaPny5ZKk9957T9dff72efvpp3XzzzXr11Vf11FNPadu2bZo4caIkacWKFXr66ae1Zs0aVVVVaenSpfroo4+0fft2OZ1OSdJNN92khoYGrV69WpFIRPfcc4+mTJmitWvXSpLa29s1duxYTZ8+XQ899JA++eQT3Xvvvfrxj3+sOXPmZDzD1772NQ0ZMkSvvvpqRrvf79fjjz+uWbNmqby8XHv27NGiRYvU0dGhjz/++IymQfP5fPJ4PGpvb1d+fn5ffrQ4T+7/lw+0cXuDrr9kkNbce9XpLwAAAANaPG6o3hfMCHP2NR9fSycci5/0WrfdouHFORpZkqMRyUAnFewUum0EOgAAAACAPuUGfV7T5rbbblNTU5OWLVum+vp6TZo0SRs2bFBZWZkk6eDBgzKbj1cuTJs2TWvXrtWjjz6qhx9+WGPGjNG6devSgY0kLVq0SIFAQHPmzJHX69W1116rDRs2pAMbSXrllVc0b9483XDDDTKbzZo1a5ZWrVqVPu/xePTWW29p7ty5mjx5skpKSrRs2bIegc2uXbv0xz/+UW+99VaPZ7NYLProo4+0Zs0aeb1eVVRUaPr06XriiSdYt2aAeG93szZub5DFbNKjN4/P9nAAAEA/YDabVFHgUkWBS9NOmHItFjd01NuVrtDZ25wKdQI61NalznBMO475tOOYr8d9851WVQ3K1cjkdGvdPzmOi3ZpSQAAAADAKfS50ganRqVN/xWLG7p51R+0s75Dd00drsf/34mnvwgAAOAkIrG4DrUmKnL2NgW0vyUR5uxv7tQRb9cpry3PdyYCnEE5GaFOZZGbqVsBAAAAYIA5p5U2wIXqlx8c0s76DuU7rVpQc0m2hwMAAC5wNotZIwflauSgXH1zXOa5YCSWUZ2zrymQXjOnJRBWvS+oel9QdXtbMq6zmE0aVuROhzgjByW2owblqjSP9XMAAAAAYKAjtMFFwReM6J9+s0uStKDmEhXm2LM8IgAAMJA5bRaNK8/XuPKef0HV3hnRvpaA9jX7ta8pGeokP53hWHr/RDl2i6oG5aiqJDHl2shBORpZkquqQTnKZbo1AAAAABgQ+O0OF4Xnf7dbLYGwRg7K0d9OHZ7t4QAAgIuYx23TJHeBJlUWZLQbhqEGX0h7m/3a260yZ2+TX4fauhQIx/TJEZ8+OdJz/ZzSPEeyMqdboDMoV5WFLlmZbg0AAAAALhiENhjwDrQE9Is/7pckPTJjPPPEAwCAfslkMqnc41S5x6lpo0oyzoWjcR1s7dTeJn8yyEkGOs1+NfvDauwIqbEjpM37WjOus1kS060lpnFLTLM2KlmhQ+UxAAAAAPQ/hDYY8Jb/eqfCsbi+NqZE3xxXmu3hAAAA9Jndatbo0lyNLs3tca69K5KuyEmFOXuS4U4oGteepoD2NPWcbq3QbetWmZMKdXI0rChHdit/5AIAAAAA2UBogwGtbk+LNnxaL7NJevTmCSzeCwAABhyPy6ZJlT2nW4vHDR3xdmlvt0AnNfXasfag2joj2nqgTVsPtGVcZzEnqnNGJadYO77NVRHVOQAAAABwThHaYMCKxQ09sX67JOmvq4dpbHlelkcEAABw/pjNJlUWuVVZ5Nb1lwzKONcZjiZDnJ6BTmc4ll5PRzsaM64rcNs0KlmdM6r0+HZYkZspaAEAAADgLCC0wYD1/209pO3HfMpzWvW9mkuyPRwAAIB+w223auIQjyYO8WS0G4ahel9Qe5sSU6x13x7xdsl7kuocq9mk4cXudEXOqEGJMGdUSa48btv5fDQAAAAAuKAR2mBA8oei+sFvPpMk/f03x6g415HlEQEAAPR/JpNJgz0uDfa4dM3okoxzneFocu2c40HO3ma/9jQG1BWJpdfO2aiGjOtKcu2ZYU5yf0ihSxYzU9cCAAAAQHeENhiQfvq73Wr2hzSi2K27po3I9nAAAAAueG67VV+p8OgrFZnVOfF4ZnVO6pNaO6fZH1azv1Xv72vNuM5uNSemV+temTMoVyMH5cht59cUAAAAABcnfhvCgHOotVP//Md9kqRHbp4gu5X51QEAAM4Vs9mkigKXKgpcunZMZnWOPxTVvm5hTrpKpzmgcDSunfUd2lnf0eOeQwpcGpmsyhmdDHNGleZoUK5DJhPVOQAAAAAGLkIbDDhP/9tOhaNxXTO6WDXjS7M9HAAAgItWrsOqS4d6dOnQzOqcWNzQ4bbOjOqc3Y1+7WkKqDUQ1hFvl454u/SHz5szrstzWtPTqyXCnByNLs3VsCK3rBb+UAcAAADAhY/QBgPK+/ta9ebHx2Q2SY/ePIG/xAQAAOiHLGaThhfnaHhxjr4xLvOPbFoDYe09IcjZ0+TXodZOdQSj+vCQVx8e8mZcY7Mk7jc6WZEzOj3VWq5yHfzKAwAAAODCwW8wGDDicUP/uP5TSdLsq4Zp/OD8LI8IAAAAfVWUY1dRTpGmjCjKaA9GYjrQ0tktzEls9zYF1BWJaXdj4lifZt5vsMeZUZmT2h+Ux1RrAAAAAPofQhsMGP9722F9csSnPIdVC/+fS7I9HAAAAJxFTptFY8vzNLY8L6M9Hjd0tL0rUZHT6NfuJr/2JEOdZn9Yx9qDOtYe1B9395xqbXRpbrI6J7EdXZqryiK3LGbCHAAAAADZQWiDASEQiuqZ3+ySJM375miV5DqyPCIAAACcD2azSUML3Rpa6Nb1lwzKOOftDKfDnFRlzu5uU6396aBXfzrozbjGbjGrqiQ5xVppZoWO02Y5j08GAAAA4GJEaIMB4YV39qipI6RhRW7dfc2IbA8HAAAA/UCB267Jw+2aPLwwoz0YiWl/SyAxzVpjQLvTU635FYrGtauhQ7saOjKuMZmkoYWudEXO6HSgk6sCt/18PhYAAACAAYzQBhe8w22devEPeyVJD88YL4eVv4AEAADAyTltFo0rz9e48sw1EONxQ0e8XRlr5qSqc7ydER1q7dKh1i79bldTxnUlufb0WjndP+X5TtbNAQAAANAnhDa44D39bzsVjsZ19cgi1X6lLNvDAQAAwAXKbDapssityiK3vjGuNONciz+UDnBSYc6eRr+OtgfV7A+r2d+qzftaM67JsVuOr5dTdnzdnGFFblkt5vP5aAAAAAAuEIQ2uKB9sL9V6z86JpNJWnrLBP6SEQAAAOdEca5DxbkOVY8szmgPhKLa03RCZU6jXwdaOhUIx/TR4XZ9dLg94xq7xawRJe5ERc6g7mvnsG4OAAAAcLEjtMEFKx439I/rt0uSbptSqa9UeLI8IgAAAFxschxWXTa0QJcNLchoD0fjOtgayAhydjcl1tDpisT0WYNfnzX4M6452bo5owflyeO2ncenAgAAAJAthDa4YK378Ig+OtyuXIdVD0wfm+3hAAAAAGl2q1mjS/M0ujQvoz0eN3S0vUufJ6dXO9N1cwblOXqGOaW5Ks1zUG0OAAAADCCENrggdYajWrFhpyRp7jdGa1CeI8sjAgAAAE7PbDZpaKFbQwvd+sbY4+vmGIahlkA4szIn+an3BdXUEVJTR0h1e1sy7pfntKanWUsFOWNK8zSk0CWLmTAHAAAAuNAQ2uCCtPrdvWrwhVRZ5NI914zI9nAAAACAL8VkMqkk16GSXIeuPmHdnI5gRHuaMqda29Pk14GWgDqCUf3poFd/OujNuMZhNWvkoFSIczzQGVGcI7vVfB6fDAAAAEBffKH/Wn/++ec1YsQIOZ1OVVdX6/333z9l/9dff13jxo2T0+nUpZdeql//+tcZ5w3D0LJlyzR48GC5XC7V1NTo888/z+jT2tqqO+64Q/n5+SooKNB9990nvz9zDuiPPvpIX/va1+R0OlVZWalnnnkm4/zLL78sk8mU8XE6nX0eC7LriLdLP3t3jyTp4ZvGs1grAAAABrQ8p02TKgv0F5OHavFN4/TPd03R7x78unY8caN+s+A6PffXV2hBzRjdctlgjSvPk91qViga145jPr3x56P60cbP9F9f2abpP/69xi/boG/+8B3N+ZcP9MyGnfo/2w7ro8NeBULRbD8mAAAAAH2BSpvXXntNCxcu1OrVq1VdXa2VK1eqtrZWu3btUmlpaY/+7733nm6//XYtX75ct9xyi9auXauZM2dq27ZtmjhxoiTpmWee0apVq7RmzRpVVVVp6dKlqq2t1fbt29Ohyh133KFjx45p48aNikQiuueeezRnzhytXbtWkuTz+TR9+nTV1NRo9erV+vjjj3XvvfeqoKBAc+bMSY8nPz9fu3btSh+fOP/zmYwF2fXMhp0KReO6qqpIN04sz/ZwAAAAgKxwWC0aW56nseWZ6+bE4oYOt3Xq84bEWjnp6pxGvzpCUe1tCmhvU0BvbW/IuG5IgUujklOtjSnLTU+7VphjP5+PBQAAAFzUTIZhGH25oLq6WldeeaWee+45SVI8HldlZaXmz5+vxYsX9+h/2223KRAIaP369em2q6++WpMmTdLq1atlGIYqKir0wAMP6MEHH5Qktbe3q6ysTC+//LJmz56tHTt2aMKECdqyZYumTJkiSdqwYYNmzJihw4cPq6KiQi+88IIeeeQR1dfXy25P/FKxePFirVu3Tjt3JtY+efnll7VgwQJ5vd5en+1MxnKiUCikUCiUPvb5fKqsrFR7e7vy8/P78qPFGdh6oE2zXnhPJpP0xrxrNXGIJ9tDAgAAAC4IhmGowRdKhjgd2t3k1+cNianWmv3hk15XnGNPT6/Wfd2csnxHjz+CAwAAANCTz+eTx+M5o9ygT5U24XBYW7du1ZIlS9JtZrNZNTU1qqur6/Wauro6LVy4MKOttrZW69atkyTt27dP9fX1qqmpSZ/3eDyqrq5WXV2dZs+erbq6OhUUFKQDG0mqqamR2WzW5s2bdeutt6qurk7XXXddOrBJfc+KFSvU1tamwsJCSZLf79fw4cMVj8f11a9+VU899ZS+8pWvnPFYTrR8+XI9/vjjZ/ojxJcQjxt6Yv12SdJffHUogQ0AAADQByaTSeUep8o9Tl07piTjnLczrM+7rZmT+hzxdqklEFbLvlZt3teacU2uw5quzOm+dk5lkVsWM2EOAAAA8EX0KbRpbm5WLBZTWVlZRntZWVm6muVE9fX1vfavr69Pn0+1narPiVOvWa1WFRUVZfSpqqrqcY/UucLCQo0dO1b//b//d1122WVqb2/XP/3TP2natGn69NNPNXTo0DMay4mWLFmSEUqlKm1w9v3rn4/qw0Neue0W/bfasdkeDgAAADBgFLjtunJEka4cUZTRHkhOp7a7qSMx3VpjYsq1Ay2d8oei+vMhr/58yJtxjd1q1siSnB7VOVUlOXJYWY8SAAAAOJU+r2lzIZs6daqmTp2aPp42bZrGjx+vn/3sZ3riiSe+0D0dDoccDsfZGiJOojMc1dP/lggG535jtErzWV8IAAAAONdyHFZdOtSjS4dmVrmHojEdaOnU7kZ/xto5e5v8CkXj2lnfoZ31HRnXmE3S8OIcjTqhMmdUaa5yHRfVr6YAAADASfXpv4xLSkpksVjU0JC5YGVDQ4PKy3tfEL68vPyU/VPbhoYGDR48OKPPpEmT0n0aGxsz7hGNRtXa2ppxn96+p/t3nMhms+mKK67Q7t27z3gsyI4Xf79X9b6ghhS4dN+1Vae/AAAAAMA547BadElZni4py5MuPd4eixs63NaZMcXa541+7Wn0qyMU1b7mgPY1B/TbHZm/uw32ODMrc5LBTnEufyAHAACAi0ufQhu73a7Jkydr06ZNmjlzpiQpHo9r06ZNmjdvXq/XTJ06VZs2bdKCBQvSbRs3bkxXvFRVVam8vFybNm1KByM+n0+bN2/Wd77znfQ9vF6vtm7dqsmTJ0uS3n77bcXjcVVXV6f7PPLII4pEIrLZbOnvGTt2bHo9mxPFYjF9/PHHmjFjxhmPBeffsfYurX53jyRpyYxxctqYUgEAAADojyxmk4YX52h4cY5uGH982mnDMNTYEUpW5nSkK3N2NwbU7A/pWHtQx9qD+sPnzRn3K3TbkkFOXkaoU+FxymRi3RwAAAAMPH2uQV+4cKHuuusuTZkyRVdddZVWrlypQCCge+65R5J05513asiQIVq+fLkk6bvf/a6uv/56/fCHP9TNN9+sV199VR988IFefPFFSYnFMBcsWKAnn3xSY8aMUVVVlZYuXaqKiop0MDR+/HjdeOONuv/++7V69WpFIhHNmzdPs2fPVkVFhSTpr//6r/X444/rvvvu00MPPaRPPvlEzz77rH784x+nx/6P//iPuvrqqzV69Gh5vV794Ac/0IEDB/R3f/d3ZzwWnH/PbNilYCSuKcMLdfOlg09/AQAAAIB+xWQyqSzfqbJ8p64ZXZJxztsZzqjMSQU6h9u61NYZ0Zb9bdqyvy3jGrfdkp5mbXRprkYNytWYslwNL3LLajGfz0cDAAAAzqo+hza33XabmpqatGzZMtXX12vSpEnasGGDysoSf0V18OBBmc3H/yN52rRpWrt2rR599FE9/PDDGjNmjNatW6eJEyem+yxatEiBQEBz5syR1+vVtddeqw0bNsjpPL5uySuvvKJ58+bphhtukNls1qxZs7Rq1ar0eY/Ho7feektz587V5MmTVVJSomXLlmnOnDnpPm1tbbr//vtVX1+vwsJCTZ48We+9954mTJjQp7Hg/PnwkFe/+tMRSdKyb03gr+kAAACAAabAbdeUEUWaMqIoo70rHNOeJr/2NGVOtba/OaDOcEwfH2nXx0faM66xWUwaUZyTUZUzalDi47JTsQ8AAID+z2QYhpHtQQwkPp9PHo9H7e3tys/Pz/ZwLmiGYWjWC+9p20GvZn11qH74V5dne0gAAAAAsiwSi+tAS2LdnO6Bzp4mvzrDsV6vMZmkIQWujPVyUp8Ct/08PwEAAAAuNn3JDfpcaQOcL298dEzbDnrlslm06Max2R4OAAAAgH7AZjGnA5fu4nFDx3zBxJo5JwQ6bZ0RHW7r0uG2Lr2zqynjupJcu0amgpxugc5g1s0BAABAFhDaoF8KRmJ6+tc7JEn/9eujVJbP9HQAAAAATs5sNmlIgUtDClz6+tjSjHMt/lDGejm7G/3a0+jX0fagmv1hNftb9f6+1oxrcuwWjUoGOaOS06yNLs3V8GK3bKybAwAAgHOE0Ab90ku/36uj7UFVeJy6/7qR2R4OAAAAgAtYca5DxbkOVY8szmgPhKI9pljb3ejXgZZOBcIxfXS4XR8dzlw3x2o2aURJjkYNyumxbk6Og1+xAQAA8OXwX5Todxp8Qf30nT2SpIduGienjQVDAQAAAJx9OQ6rLhtaoMuGFmS0h6NxHWwNpMOcVJXOnsaAuiKxdNtvPm3IuK7C48yoykltS3LtTLUGAACAM0Jog37nmQ271BWJ6YphBfpPl1dkezgAAAAALjJ2q1mjS/M0ujQvoz21bk5qerXUdGt7m/xq9od1tD2oo+1B/eHz5ozrPC5bujKne6BTWeSWxUyYAwAAgOMIbdCvfHTYq/+97bAkadktE/hrNAAAAAD9Rvd1c66/ZFDGubZAWHua/BnTre1u8utwW5fauyLadtCrbQe9GdfYLWZVlaTCnJx0lc6oQbly2ZlxAAAA4GJEaIN+wzAMPbF+uyTp1iuG6IphhVkeEQAAAACcmcIcu6bkFGnKiKKM9mAkpr1NgYxAZ09TQHub/ApF49rV0KFdDR097jekwHV8vZzSnHSYw1RrAAAAAxuhDfqNX39cry372+S0mbXoxrHZHg4AAAAAfGlOm0UTKvI1oSI/oz0WN3TU25UMcfwZ27bOiI54u3TE26V3P2vKuC411VoizElV5uRoWJFbVov5fD4aAAAAzgFCG/QLwUhMT/16hyTpv1w/SoM9riyPCAAAAADOHYvZpMoityqL3PrGuNKMc62BcHqKtb3JCp09TQEdaus86VRrNotJw4tz0mvnjCxJhDojB+Uo32k7j08GAACAL4PQBv3Cz/+4T0e8XRrsceo/Xzcq28MBAAAAgKwpyrHrqqoiXVXVc6q1/S2BRFVO4/Ep1/Y2BdQViaWDnt982pBxXWmeo8c0ayMH5ajC45LZzFRrAAAA/QmhDbKu0RfUT3+3W5L00I3jWHATAAAAAHrhtFk0rjxf48ozp1qLxw0d8wW1p9sUa6l1dBo7QulP3d6WE+5nTlfkpKZcGzkoRyNLcvm9DAAAIEsIbZB1//TWLgXCMU2qLNB/urwi28MBAAAAgAuK2WzSkAKXhhS4dN0lgzLO+YKRRIDT6M+ozNnfElAwEtf2Yz5tP+brcc8hBS6N7BbkpLbl+U6ZTFTnAAAAnCuENsiqT4606/WthyVJy741gdJ8AAAAADiL8p02Taos0KTKgoz2aCyuQ21dGWHOnmR1jrczoiPeLh3xdukPnzdnXJdjt6gqFeKUHA90qkpyqM4BAAA4CwhtkDWGYeiJ9dtlGNL/O6lCXx1WmO0hAQAAAMBFwWoxq6okR1UlOapRWca51kBYe7tV5expCmhvk18HWjsVCMf0yRGfPjly8uqckSU5Gpmaam1QrgbnO/kDPQAAgDNEaIOs+c2n9dq8r1UOq1mLbhyX7eEAAAAAACQV5dhVlFOkKSOKMtrD0bgOtnYmA51EkLO3+fTVOS6bRSNKchJVOScEOrkO/lkCAACgO/7rCFkRisb0/V/vkCT95+tGakiBK8sjAgAAAACcit1q1ujSXI0uze1xLlWds7cpoD3Nie3eJr8OtHSqKxLTjmM+7ehl7ZzSPEc6wBmZDHZGluRqaKFLVov5fDwWAABAv0Jog6z4xb/v16HWLpXlO/Sfrx+V7eEAAAAAAL6Ek1XndF87Z286zAlob7Nfzf6wGjtCauwI6T/2tmZcZ7OYNKzIraqSXI0alJjGbWRy7ZySXLtMJqZbAwAAAxOhDc67po6Qnnt7tyRpUe045VAODwAAAAADUve1c3TC2jntXRHtbfJrX3MiyNmXnGptf0tAwUhce5Lr6fx2R+Y985zW9Lo5qXunPvx+CQAALnT81wzOux9t3CV/KKrLhnp06xVDsj0cAAAAAEAWeFw2XTGsUFcMK8xoj8cNHfMFMwKdvc2J6daOeLvUEYzqz4fb9efD7T3uWZbvSAY4x6dbqyrJUWWRWzamWwMAABcAQhucV58ebderWw5JkpbdMkFmMyXtAAAAAIDjzGaThhS4NKTApa+NGZRxLhiJ6UBLZ2L9nOZEdU7q0xoIq8EXUoOv53RrFnNqurVEiDOiJEcjk9vB+U5+NwUAAP0GoQ3OG8Mw9OT6HTIM6ZbLBveY6xgAAAAAgFNx2iwaW56nseV5Pc55O8MZIc7e5oD2Jadd64rE0u0ncljNGlHcM8xh/RwAAJANhDY4bzZub1Dd3hbZrWYtvmlctocDAAAAABhACtx2XTHM3mO6NcMw1OALaW/z8enW9jcHtK8loIMtnQpF49rV0KFdDR097pnrsGpEiVtVJbmqKnZrRCrQKc5RYY79fD0aAAC4iBDa4LwIRWP6/q8Tq0fO+dpIDS10Z3lEAAAAAICLgclkUrnHqXKPU9NGlWSci8biOuLt0t7mZJDT7XPE2yV/KKpPjvj0yRFfj/t6XLZkgONOV+aMKE6EOh6X7Xw9HgAAGGAIbXBefLC/TYfbujQoz6HvfH1UtocDAAAAAICsFrOGF+doeHGONDbzXDAS06HWznSIs78luW3uVL0vqPauiP58yKs/H/L2uG9Rjl0jUmFOcY6Gp7du5TsJdAAAwMmZDMMw+nrR888/rx/84Aeqr6/X5Zdfrp/85Ce66qqrTtr/9ddf19KlS7V//36NGTNGK1as0IwZM9LnDcPQY489ppdeekler1fXXHONXnjhBY0ZMybdp7W1VfPnz9cbb7whs9msWbNm6dlnn1Vubm66z0cffaS5c+dqy5YtGjRokObPn69Fixalz7/00kv6l3/5F33yySeSpMmTJ+upp57KGPvdd9+tNWvWZIy/trZWGzZsOKOfjc/nk8fjUXt7u/Lz88/omovF5w0dqvcFeywkCQAAAADAhaQzHNWBls70NGv7k2HOvpaAmjpCp7y2OMeu4cXudFVO930qdAAAGJj6khv0udLmtdde08KFC7V69WpVV1dr5cqVqq2t1a5du1RaWtqj/3vvvafbb79dy5cv1y233KK1a9dq5syZ2rZtmyZOnChJeuaZZ7Rq1SqtWbNGVVVVWrp0qWpra7V9+3Y5nU5J0h133KFjx45p48aNikQiuueeezRnzhytXbs2/dDTp09XTU2NVq9erY8//lj33nuvCgoKNGfOHEnSO++8o9tvv13Tpk2T0+nUihUrNH36dH366acaMmRIesw33nijfvGLX6SPHQ5HX39M6MWYsjyNKeu5WCQAAAAAABcSt92q8YPzNX5wz3908YeiiRAnFeYkw539LZ1q9ofUEgirJRDWtoPeHtcWum0aXpyYai0V5qS2BW6bTCbTeXg6AACQTX2utKmurtaVV16p5557TpIUj8dVWVmp+fPna/HixT3633bbbQoEAlq/fn267eqrr9akSZO0evVqGYahiooKPfDAA3rwwQclSe3t7SorK9PLL7+s2bNna8eOHZowYYK2bNmiKVOmSJI2bNigGTNm6PDhw6qoqNALL7ygRx55RPX19bLbE4sBLl68WOvWrdPOnTt7fZZYLKbCwkI999xzuvPOOyUlKm28Xq/WrVt3Rj+PUCikUOj4X9H4fD5VVlZSaQMAAAAAADJ0BCM60NKZqNJJhjqp/cbTVOjkOa3pECfxydHwosQUbKV5DgIdAAD6sXNWaRMOh7V161YtWbIk3WY2m1VTU6O6urper6mrq9PChQsz2mpra9OhyL59+1RfX6+ampr0eY/Ho+rqatXV1Wn27Nmqq6tTQUFBOrCRpJqaGpnNZm3evFm33nqr6urqdN1116UDm9T3rFixQm1tbSosLOwxts7OTkUiERUVFWW0v/POOyotLVVhYaG++c1v6sknn1RxcXGvz7d8+XI9/vjjJ/mJAQAAAAAAJOQ5bZo4xKOJQzw9zgVC0WSgc7w6Z19LQAdbEmvodASj+vhIuz4+0t7jWpfNomFF7sxAp9it4UU5qihwymoxn4/HAwAAZ0GfQpvm5mbFYjGVlZVltJeVlZ20mqW+vr7X/vX19enzqbZT9Tlx6jWr1aqioqKMPlVVVT3ukTrXW2jz0EMPqaKiIiMwuvHGG/Xtb39bVVVV2rNnjx5++GHddNNNqqurk8Vi6XGPJUuWZIRSqUobAAAAAACAM5XjsGpCRb4mVPT869tgJKaDrYkg52BrojInVbFzxNulrkhMuxo6tKuho8e1VrNJQwpdGlbkTgc7w4pyklu3chx9njkfAACcQxft/zM//fTTevXVV/XOO++k182RpNmzZ6f3L730Ul122WUaNWqU3nnnHd1www097uNwOFjzBgAAAAAAnDNOm0WXlOXpkl7WiY3E4jrS1qX9LclApzlRrXOgtVMHWzsVjsbTAU9vSnId6QCne7VOZZFbg3KZdg0AgPOtT6FNSUmJLBaLGhoaMtobGhpUXl7e6zXl5eWn7J/aNjQ0aPDgwRl9Jk2alO7T2NiYcY9oNKrW1taM+/T2Pd2/I+Wf/umf9PTTT+u3v/2tLrvsslM+88iRI1VSUqLdu3f3GtoAAAAAAABki81i1oiSHI0oyelxLh431NAR1IGWTh1s6dSB1oAOtnbpYDLU8XZG1OwPqdkf0tYDbT2ud9rMyTAnJ7l1aViyUmdooUtOW88ZSQAAwJfTp9DGbrdr8uTJ2rRpk2bOnClJisfj2rRpk+bNm9frNVOnTtWmTZu0YMGCdNvGjRs1depUSVJVVZXKy8u1adOmdEjj8/m0efNmfec730nfw+v1auvWrZo8ebIk6e2331Y8Hld1dXW6zyOPPKJIJCKbzZb+nrFjx2ZMjfbMM8/o+9//vn7zm99krJFzMocPH1ZLS0tGoAQAAAAAANDfmc0mDfa4NNjj0tUje67V294VSYc53YOdQ61dOtbepWAkrs8a/Pqswd/r/cvznRpWlKjKSVTnuFRZmKjYGZRHlQ4AAF+EyTAMoy8XvPbaa7rrrrv0s5/9TFdddZVWrlypX/7yl9q5c6fKysp05513asiQIVq+fLkk6b333tP111+vp59+WjfffLNeffVVPfXUU9q2bZsmTpwoSVqxYoWefvpprVmzRlVVVVq6dKk++ugjbd++PT112U033aSGhgatXr1akUhE99xzj6ZMmaK1a9dKktrb2zV27FhNnz5dDz30kD755BPde++9+vGPf6w5c+akv2fZsmVau3atrrnmmvQz5ebmKjc3V36/X48//rhmzZql8vJy7dmzR4sWLVJHR4c+/vjjM5oGzefzyePxqL29Xfn5PeehBQAAAAAA6O/C0biOeLt0MDnN2qHWRKiTOvaHoqe83mE1a2hyLZ3KIrcqC5PbIpcqi9zKd9rO05MAAJB9fckN+rymzW233aampiYtW7ZM9fX1mjRpkjZs2KCysjJJ0sGDB2U2m9P9p02bprVr1+rRRx/Vww8/rDFjxmjdunXpwEaSFi1apEAgoDlz5sjr9eraa6/Vhg0bMtaaeeWVVzRv3jzdcMMNMpvNmjVrllatWpU+7/F49NZbb2nu3LmaPHmySkpKtGzZsnRgI0kvvPCCwuGw/uIv/iLjmR577DH9wz/8gywWiz766COtWbNGXq9XFRUVmj59up544gnWrQEAAAAAABcNu9WsqpIcVfUy7ZphGPJ2RtLr5hxqTayjc6i1S4faOnXU26VQNK49TQHtaQr0ev8Cty0Z5CSqc4YWuVVZ6NLQQjdTrwEALmp9rrTBqVFpAwAAAAAALmaRWFzHvEEdajse6hxqS1TtHG7tVEsgfNp7DMpzpEOcdLCT3B/sccluNZ/2HgAA9Bd9yQ0Ibc4yQhsAAAAAAICTC4SiOtTWqUOtXelQ53Bblw63JfYD4dgprzebEuvppKpyhibDnSHJfUIdAEB/Q2iTRYQ2AAAAAAAAX0xq6rVDbYkgJ1Glc3z/cFti6rVTMSVDnSEFPQOdoYVuVRQ45bAy/RoA4PwhtMkiQhsAAAAAAIBzwzAMNflDOtSaqMw53NalI96udKXOkTMIdSSpNM+hIYUuVRS4NLTApSGFLg1JbisKXMp32s7D0wAALhaENllEaAMAAAAAAJAdhmGo2R8+IdBJTb/WpSNtXeqKnHr6NUnKc1rTlTrdw5whyU9JrkNms+k8PBEAYCAgtMkiQhsAAAAAAID+yTAMtQbCOuJNBDipKp2j3sT+EW+XvJ2R097HZjFpsMeligJnOsypKEgFO04N9riU47CehycCAFwI+pIb8P8eAAAAAAAAuCiYTCYV5zpUnOvQZUMLeu0TCEXTAU4q2Om+bewIKhIzdLC1UwdbO0/6XR6XLR3iVBS40iHPYI9Lgz1OlXucslnM5+hJAQAXKkIbAAAAAAAAICnHYdUlZXm6pCyv1/ORWFwNvqCOeoM61p4Ic456u3TUG0xX7HQEo2rviqi9K6Idx3y93sdkkgblOjS4wKUKjzMd6pR32y/Nc8rCNGwAcFEhtAEAAAAAAADOkM1i1tBCt4YWuk/axxeM6Fi3EOeot0vH2oPpbX17UOFYXI0dITV2hPTnQ73fx2I2qSzPkQ5yEltnt61LpXkOKnYAYAAhtAEAAAAAAADOonynTfnlNo0t771aJx431BII61h7IsQ5lgp1uu3X+4KKxQ0dTbZL3l7vZTJJJbmORIiTfzzMKfc4VJafaCv3OOW288+AAHAh4G0NAAAAAAAAnEdms0mD8hwalOfQZUN77xOLG2rqCOlYe5fq24PpICdRqZMIdhp8ifV1mjpCauoI6SO1n/Q785zWdICTCnPKkkFPYt+hkhyHzEzHBgBZRWgDAAAAAAAA9DMWs0nlyanQTiYeN9TaGT4e6rQfn34tFerU+4LqDMfUEYyqI+jX543+k97PmgyTyvKdKstPbZ0qTbaV5jtUludUgdsmk4lwBwDOBUIbAAAAAAAA4AJkNptUkutQSa5DE4d4eu1jGIY6QlE1JCt16ruFOfXtITX4EsdN/pCicSMxXVt78JTfa7ea00FOWb5DpXnHw53S5PGgPIcKCXcAoM8IbQAAAAAAAIABymQyJdbYcdo0pqz3NXYkKRqLq8kfSoY6ITV2JMKcRl9IDR0hNSbDnbbOiMLRuA63delwW9cpv9tmMWlQrkODUoFOckq40rzMgKck1y6rxXy2Hx0ALkiENgAAAAAAAMBFzmoxa7DHpcEe1yn7BSMxNXUkQp1GX7JSpyOUDngaO4Jq7AjJ2xlRJGboaHtQR09TuWMySUVuu0pyHem1fkpy7d32k+25DhW67ay7A2BAI7QBAAAAAAAAcEacNosqi9yqLHKfsl8oGlOzP6xGXyLEaewIqakjpKaOVLiTCHia/WHF4oZaAmG1BMLa1dBxyvtazCYV59jTYU5JrkMleXaV5CS3uQ4VJ/eL3FTwALjwENoAAAAAAAAAOKscVouGFLg0pODUlTvxuKHWzrCaOkJq9qeCnW77/pCaO8Jq8ofUGkgEPKkQ6HRMJqnQbVdJrj0Z5CQqeBJhj11FOQ4V5diT+3blOqyswQMg6whtAAAAAAAAAGSF2WxKV8ycTiQWV2sgnA5zmnwhNQcSoU5LIBH0pPZbA2HFDak1EFZrICzJf9r7261mFeckApziXEe3fXty36Hi3EQFT1GuXXmEPADOAUIbAAAAAAAAAP2ezWJWWb5TZfnO0/aNxQ21dYbV7A+pxR9OV+60BMJqTlbytCanZGsNhNUZjikcjetYe1DHTrMGT4rVbFJhTjLESQY8hTm29HFhqs2dCH4K3XY5bZYv+2MAMMAR2gAAAAAAAAAYUCx9qOCRpK5wTC2BRMCTCnNaksFOsz+s1kAo2RZWW2ci5InGjfR0bmfKaTOr0G1XgduuQrdNhTnJbfc2t10FyW2h2648p1VmMxU9wMWC0AYAAAAAAADARc1lt2io3a2hhe4z6h+MxNJTr7V1ho/vB8Jq7QyrLRBJtyWOw4rGDQUjfavmkRIBVL7TqgK3XR6XTQVumwpcNnlcNnncdhWk2tzJNpc9vW+zmL/ojwRAlhDaAAAAAAAAAEAfOG0WVRS4VFHgOqP+hmGoIxSVNxBRW2ci6PF2pvYjagtktqW2neFYcqq3iNo6I30eZ47dovxkwJPvtB3fd1nTbYnjnu1uu4U1e4AsILQBAAAAAAAAgHPIZDIlQhOnTcOKz6yaR5JC0Zi8nRG1d0Xk7YzI2xmWtysiX+q4K5w+372PLxiVJAXCMQXCsT5V9qRYzCblOa2JjyMR6OQ5bcpzWpPPkjju3p7eOqzKdVrlshH8AH1FaAMAAAAAAAAA/ZDDalFZvkVl+c4+XReLG/IlgxxfMLntip5wfDzs8QWj8nVri8YNxeJGMgSKSOr6QuM3m6RcRyLMSWwTYU5632FVrsOWbLMox2FVjt2a2DosynVY5bYn+jltZgIgXBQIbQAAAAAAAABgALGYTSrMsaswx97naw3DUFckpo5UkBOMqiN4fJtq7whG5UsedwQToVBHMKKOUFT+UFSGIcUNJQKhZOXPl2E2qVuoczzQSQU8brtFbrv1hG1y32GR29Ztv1sf1v1Bf/OFQpvnn39eP/jBD1RfX6/LL79cP/nJT3TVVVedtP/rr7+upUuXav/+/RozZoxWrFihGTNmpM8bhqHHHntML730krxer6655hq98MILGjNmTLpPa2ur5s+frzfeeENms1mzZs3Ss88+q9zc3HSfjz76SHPnztWWLVs0aNAgzZ8/X4sWLTrrYwEAAAAAAACAgchkMiUDDWufK3xSDMNQZzgmfyiqjmAixPEHo/KHIiccR9WR7BNIhj2BUDR9bWpfSgRAiYDoywdA3VnNJrlsFjntFrlslm775sSx3SKXzSqX3Zw+77BZ5LRZ5LSZ5bRa5Ehu023JrSN1zmaR02qRzWKiWgin1efQ5rXXXtPChQu1evVqVVdXa+XKlaqtrdWuXbtUWlrao/97772n22+/XcuXL9ctt9yitWvXaubMmdq2bZsmTpwoSXrmmWe0atUqrVmzRlVVVVq6dKlqa2u1fft2OZ2JF8Mdd9yhY8eOaePGjYpEIrrnnns0Z84crV27VpLk8/k0ffp01dTUaPXq1fr444917733qqCgQHPmzDmrYwEAAAAAAAAA9M5kMiUrYKwqy/9y94rHDXVGYulQpzN0PNAJhKMKhGLqDCfCncQnmrkNxdQZSVzXvT0aNyRJ0biRCI5CZzcM6o3ZJNmtiTAnsTX3OHZYzbJbzHLYktvkObvVLJvFLLvFlNgmj23W422pj91qkt2SCImsFnNiazbLajHJak70tVpMsphNsqXbj58nWMouk2EYRl8uqK6u1pVXXqnnnntOkhSPx1VZWan58+dr8eLFPfrfdtttCgQCWr9+fbrt6quv1qRJk7R69WoZhqGKigo98MADevDBByVJ7e3tKisr08svv6zZs2drx44dmjBhgrZs2aIpU6ZIkjZs2KAZM2bo8OHDqqio0AsvvKBHHnlE9fX1stsTZX+LFy/WunXrtHPnzrM2lhOFQiGFQqH0sc/nU2Vlpdrb25Wf/yXfSAAAAAAAAACAsy4UjSkYjqsrEkt8woltsNt+j+Nu21A0rmAkpmByG4rEFIzEE/eNxBWMJq4NRuLZftQ+s5oTgU5qm/ExmWSxJLfJNrPJlAiBurX997uvVJ7Tlu1H6Td8Pp88Hs8Z5QZ9qrQJh8PaunWrlixZkm4zm82qqalRXV1dr9fU1dVp4cKFGW21tbVat26dJGnfvn2qr69XTU1N+rzH41F1dbXq6uo0e/Zs1dXVqaCgIB3YSFJNTY3MZrM2b96sW2+9VXV1dbruuuvSgU3qe1asWKG2tjYVFhaelbGcaPny5Xr88cdP85MDAAAAAAAAAPQXDqtFDqtFHp3bYMEwDIWi8cQnEkvvh6OJgCeccRxXONazLRSJKRwzFInF059w9ITjmKFwNKZIsl84mjpnKBqLKxJPbKNxQ9GYoWg8ca430bihaNxQqNezZ/jcX+Lai12fQpvm5mbFYjGVlZVltJeVlaWrWU5UX1/fa//6+vr0+VTbqfqcOPWa1WpVUVFRRp+qqqoe90idKywsPCtjOdGSJUsygqBUpQ0AAAAAAAAA4OJmMpmSa9xYJFf/qjwxDEOxZEATTYY6kWSgE40lzsWSfTI+hqF48pp48ji1n9q6bJZsP94Fq89r2iCTw+GQw+HI9jAAAAAAAAAAADhjpuS0ZlbylX7F3JfOJSUlslgsamhoyGhvaGhQeXl5r9eUl5efsn9qe7o+jY2NGeej0ahaW1sz+vR2j+7fcTbGAgAAAAAAAAAAcC70KbSx2+2aPHmyNm3alG6Lx+PatGmTpk6d2us1U6dOzegvSRs3bkz3r6qqUnl5eUYfn8+nzZs3p/tMnTpVXq9XW7duTfd5++23FY/HVV1dne7z+9//XpFIJON7xo4dq8LCwrM2FgAAAAAAAAAAgHOhT6GNJC1cuFAvvfSS1qxZox07dug73/mOAoGA7rnnHknSnXfeqSVLlqT7f/e739WGDRv0wx/+UDt37tQ//MM/6IMPPtC8efMkJUqwFixYoCeffFL/+q//qo8//lh33nmnKioqNHPmTEnS+PHjdeONN+r+++/X+++/r3//93/XvHnzNHv2bFVUVEiS/vqv/1p2u1333XefPv30U7322mt69tlnM9abORtjAQAAAAAAAAAAOBf6vKbNbbfdpqamJi1btkz19fWaNGmSNmzYoLKyMknSwYMHZTYfz4KmTZumtWvX6tFHH9XDDz+sMWPGaN26dZo4cWK6z6JFixQIBDRnzhx5vV5de+212rBhg5xOZ7rPK6+8onnz5umGG26Q2WzWrFmztGrVqvR5j8ejt956S3PnztXkyZNVUlKiZcuWac6cOWd9LKdiGIakRIUOAAAAAAAAAAC4uKXyglR+cCom40x64YwdPnxYlZWV2R4GAAAAAAAAAADoRw4dOqShQ4eesg+hzVkWj8d19OhR5eXlyWQyZXs4/YrP51NlZaUOHTqk/Pz8bA8HwEWCdw+AbOH9AyBbeP8AyAbePQCy5UJ4/xiGoY6ODlVUVGTMVNabPk+PhlMzm82nTcoudvn5+f32fzwABi7ePQCyhfcPgGzh/QMgG3j3AMiW/v7+8Xg8Z9Tv1JEOAAAAAAAAAAAAzgtCGwAAAAAAAAAAgH6A0AbnjcPh0GOPPSaHw5HtoQC4iPDuAZAtvH8AZAvvHwDZwLsHQLYMtPePyTAMI9uDAAAAAAAAAAAAuNhRaQMAAAAAAAAAANAPENoAAAAAAAAAAAD0A4Q2AAAAAAAAAAAA/QChDQAAAAAAAAAAQD9AaAMAAAAAAAAAANAPENrgvHj++ec1YsQIOZ1OVVdX6/3338/2kAAMMMuXL9eVV16pvLw8lZaWaubMmdq1a1dGn2AwqLlz56q4uFi5ubmaNWuWGhoasjRiAAPR008/LZPJpAULFqTbePcAOFeOHDmiv/mbv1FxcbFcLpcuvfRSffDBB+nzhmFo2bJlGjx4sFwul2pqavT5559nccQALnSxWExLly5VVVWVXC6XRo0apSeeeEKGYaT78O4BcDb8/ve/17e+9S1VVFTIZDJp3bp1GefP5F3T2tqqO+64Q/n5+SooKNB9990nv99/Hp/iiyG0wTn32muvaeHChXrssce0bds2XX755aqtrVVjY2O2hwZgAHn33Xc1d+5c/cd//Ic2btyoSCSi6dOnKxAIpPt873vf0xtvvKHXX39d7777ro4ePapvf/vbWRw1gIFky5Yt+tnPfqbLLrsso513D4Bzoa2tTddcc41sNpv+7d/+Tdu3b9cPf/hDFRYWpvs888wzWrVqlVavXq3NmzcrJydHtbW1CgaDWRw5gAvZihUr9MILL+i5557Tjh07tGLFCj3zzDP6yU9+ku7DuwfA2RAIBHT55Zfr+eef7/X8mbxr7rjjDn366afauHGj1q9fr9///veaM2fO+XqEL8xkdI/CgXOgurpaV155pZ577jlJUjweV2VlpebPn6/FixdneXQABqqmpiaVlpbq3Xff1XXXXaf29nYNGjRIa9eu1V/8xV9Iknbu3Knx48errq5OV199dZZHDOBC5vf79dWvflU//elP9eSTT2rSpElauXIl7x4A58zixYv17//+7/rDH/7Q63nDMFRRUaEHHnhADz74oCSpvb1dZWVlevnllzV79uzzOVwAA8Qtt9yisrIy/fznP0+3zZo1Sy6XS//zf/5P3j0AzgmTyaRf/epXmjlzpqQz+++cHTt2aMKECdqyZYumTJkiSdqwYYNmzJihw4cPq6KiIluPc1pU2uCcCofD2rp1q2pqatJtZrNZNTU1qqury+LIAAx07e3tkqSioiJJ0tatWxWJRDLeR+PGjdOwYcN4HwH40ubOnaubb7454x0j8e4BcO7867/+q6ZMmaK//Mu/VGlpqa644gq99NJL6fP79u1TfX19xvvH4/Gourqa9w+AL2zatGnatGmTPvvsM0nSn//8Z/3xj3/UTTfdJIl3D4Dz40zeNXV1dSooKEgHNpJUU1Mjs9mszZs3n/cx94U12wPAwNbc3KxYLKaysrKM9rKyMu3cuTNLowIw0MXjcS1YsEDXXHONJk6cKEmqr6+X3W5XQUFBRt+ysjLV19dnYZQABopXX31V27Zt05YtW3qc490D4FzZu3evXnjhBS1cuFAPP/ywtmzZor//+7+X3W7XXXfdlX7H9Pa7GO8fAF/U4sWL5fP5NG7cOFksFsViMX3/+9/XHXfcIUm8ewCcF2fyrqmvr1dpaWnGeavVqqKion7/PiK0AQAMOHPnztUnn3yiP/7xj9keCoAB7tChQ/rud7+rjRs3yul0Zns4AC4i8XhcU6ZM0VNPPSVJuuKKK/TJJ59o9erVuuuuu7I8OgAD1S9/+Uu98sorWrt2rb7yla/oww8/1IIFC1RRUcG7BwDOEqZHwzlVUlIii8WihoaGjPaGhgaVl5dnaVQABrJ58+Zp/fr1+t3vfqehQ4em28vLyxUOh+X1ejP68z4C8GVs3bpVjY2N+upXvyqr1Sqr1ap3331Xq1atktVqVVlZGe8eAOfE4MGDNWHChIy28ePH6+DBg5KUfsfwuxiAs+m//bf/psWLF2v27Nm69NJL9bd/+7f63ve+p+XLl0vi3QPg/DiTd015ebkaGxszzkejUbW2tvb79xGhDc4pu92uyZMna9OmTem2eDyuTZs2aerUqVkcGYCBxjAMzZs3T7/61a/09ttvq6qqKuP85MmTZbPZMt5Hu3bt0sGDB3kfAfjCbrjhBn388cf68MMP058pU6bojjvuSO/z7gFwLlxzzTXatWtXRttnn32m4cOHS5KqqqpUXl6e8f7x+XzavHkz7x8AX1hnZ6fM5sx/TrRYLIrH45J49wA4P87kXTN16lR5vV5t3bo13eftt99WPB5XdXX1eR9zXzA9Gs65hQsX6q677tKUKVN01VVXaeXKlQoEArrnnnuyPTQAA8jcuXO1du1a/d//+3+Vl5eXnp/U4/HI5XLJ4/Hovvvu08KFC1VUVKT8/HzNnz9fU6dO1dVXX53l0QO4UOXl5aXXzkrJyclRcXFxup13D4Bz4Xvf+56mTZump556Sn/1V3+l999/Xy+++KJefPFFSZLJZNKCBQv05JNPasyYMaqqqtLSpUtVUVGhmTNnZnfwAC5Y3/rWt/T9739fw4YN01e+8hX96U9/0o9+9CPde++9knj3ADh7/H6/du/enT7et2+fPvzwQxUVFWnYsGGnfdeMHz9eN954o+6//36tXr1akUhE8+bN0+zZs1VRUZGlpzozJsMwjGwPAgPfc889px/84Aeqr6/XpEmTtGrVqn6faAK4sJhMpl7bf/GLX+juu++WJAWDQT3wwAP6X//rfykUCqm2tlY//elP+31ZLIALy9e//nVNmjRJK1eulMS7B8C5s379ei1ZskSff/65qqqqtHDhQt1///3p84Zh6LHHHtOLL74or9era6+9Vj/96U91ySWXZHHUAC5kHR0dWrp0qX71q1+psbFRFRUVuv3227Vs2TLZ7XZJvHsAnB3vvPOOvvGNb/Rov+uuu/Tyyy+f0bumtbVV8+bN0xtvvCGz2axZs2Zp1apVys3NPZ+P0meENgAAAAAAAAAAAP0Aa9oAAAAAAAAAAAD0A4Q2AAAAAAAAAAAA/QChDQAAAAAAAAAAQD9AaAMAAAAAAAAAANAPENoAAAAAAAAAAAD0A4Q2AAAAAAAAAAAA/QChDQAAAAAAAAAAQD9AaAMAAAAAAAAAANAPENoAAAAAAAAAAAD0A4Q2AAAAAAAAAAAA/QChDQAAAAAAAAAAQD/w/wNsTKL52/TAwQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = CNN(backbone=backbone, pretrained=False)\n",
    "model = TimmSED(\n",
    "            base_model_name=config.base_model_name,\n",
    "            config=config,\n",
    "            pretrained=config.pretrained,\n",
    "            num_classes=config.num_classes,\n",
    "            in_channels=config.in_channels\n",
    "        )\n",
    "\n",
    "\n",
    "rcParams['figure.figsize'] = 20, 2\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr_max, weight_decay=weight_decay)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, cosine_epo)\n",
    "scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n",
    "\n",
    "lrs = []\n",
    "for epoch in range(1, n_epochs):\n",
    "    scheduler_warmup.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "plt.plot(range(len(lrs)), lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "337f1d8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.884741Z",
     "start_time": "2024-05-02T08:55:35.869499Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:24.698226Z",
     "iopub.status.busy": "2024-05-12T08:01:24.697871Z",
     "iopub.status.idle": "2024-05-12T08:01:24.716464Z",
     "shell.execute_reply": "2024-05-12T08:01:24.715531Z"
    },
    "papermill": {
     "duration": 0.034844,
     "end_time": "2024-05-12T08:01:24.718420",
     "exception": false,
     "start_time": "2024-05-12T08:01:24.683576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_fold():\n",
    "    logger = init_logger(log_file=os.path.join(output_folder, exp_name, f\"{fold}.log\"))\n",
    "\n",
    "    logger.info(\"=\" * 90)\n",
    "    logger.info(f\"Fold {fold} Training\")\n",
    "    logger.info(\"=\" * 90)\n",
    "\n",
    "    trn_df = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    val_df = df[df['fold'] == fold].reset_index(drop=True)\n",
    "#     print(trn_df.shape)\n",
    "    logger.info(trn_df.shape)\n",
    "    logger.info(trn_df['primary_label'].value_counts())\n",
    "    logger.info(val_df.shape)\n",
    "    logger.info(val_df['primary_label'].value_counts())\n",
    "\n",
    "\n",
    "    # trn_dataset = BirdDataset(df=trn_df.reset_index(drop=True), transform=transforms_train, add_secondary_labels=True, mode='train')\n",
    "    # v_ds = BirdDataset(df=val_df.reset_index(drop=True), transform=transforms_val, add_secondary_labels=True, mode='valid')\n",
    "    trn_dataset = BirdDataset(df=trn_df.reset_index(drop=True), transform=transforms_train, add_secondary_labels=True)\n",
    "    v_ds = BirdDataset(df=val_df.reset_index(drop=True), transform=transforms_val, add_secondary_labels=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(trn_dataset, shuffle=True, batch_size=batch_size, drop_last=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = torch.utils.data.DataLoader(v_ds, shuffle=False, batch_size=batch_size, drop_last=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    if CNN_:\n",
    "        model = CNN(backbone=backbone, pretrained=True).to(device)\n",
    "    else:\n",
    "        model = TimmSED(\n",
    "                base_model_name=config.base_model_name,\n",
    "                config=config,\n",
    "                pretrained=config.pretrained,\n",
    "                num_classes=config.num_classes,\n",
    "                in_channels=config.in_channels\n",
    "            ).to(device)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=lr_max, weight_decay=weight_decay)\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, cosine_epo)\n",
    "    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "    patience = early_stopping\n",
    "    best_score = 0.0\n",
    "    n_patience = 0\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # if epoch==5: break\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "        scheduler_warmup.step(epoch-1)\n",
    "\n",
    "        train_scores, train_losses_avg = train_one_epoch(model, train_loader, optimizer, scaler)\n",
    "        train_scores_str = metrics_to_string(train_scores, \"Train\")\n",
    "        train_info = f\"Epoch {epoch} - Train loss: {train_losses_avg:.4f}, {train_scores_str}\"\n",
    "        logger.info(train_info)\n",
    "\n",
    "        val_scores, val_losses_avg = valid_one_epoch(model, val_loader)\n",
    "        val_scores_str = metrics_to_string(val_scores, f\"Valid\")\n",
    "        val_info = f\"Epoch {epoch} - Valid loss: {val_losses_avg:.4f}, {val_scores_str}\"\n",
    "        logger.info(val_info)\n",
    "\n",
    "        val_score = val_scores[\"ROC\"]\n",
    "\n",
    "        is_better = val_score > best_score\n",
    "        best_score = max(val_score, best_score)\n",
    "\n",
    "        if is_better:\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"best_loss\": best_score,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "            }\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch} - Save Best Score: {best_score:.4f} Model\\n\")\n",
    "            torch.save(\n",
    "                state,\n",
    "                os.path.join(output_folder, exp_name, f\"{fold}.bin\")\n",
    "            )\n",
    "            n_patience = 0\n",
    "        else:\n",
    "            n_patience += 1\n",
    "            logger.info(\n",
    "                f\"Valid loss didn't improve last {n_patience} epochs.\\n\")\n",
    "\n",
    "        if n_patience >= patience:\n",
    "            logger.info(\n",
    "                \"Early stop, Training End.\\n\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"best_loss\": best_score,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(\n",
    "                state,\n",
    "                os.path.join(output_folder, exp_name, f\"final_{fold}.bin\")\n",
    "            )\n",
    "            break\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d7dde02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:24.745977Z",
     "iopub.status.busy": "2024-05-12T08:01:24.745674Z",
     "iopub.status.idle": "2024-05-12T09:40:26.108359Z",
     "shell.execute_reply": "2024-05-12T09:40:26.107319Z"
    },
    "papermill": {
     "duration": 5941.378901,
     "end_time": "2024-05-12T09:40:26.110693",
     "exception": false,
     "start_time": "2024-05-12T08:01:24.731792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Fold 2 Training\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(19567, 14)\n",
      "primary_label\n",
      "zitcis1    400\n",
      "lirplo     400\n",
      "litgre1    400\n",
      "comgre     400\n",
      "comkin1    400\n",
      "          ... \n",
      "paisto1      5\n",
      "blaeag1      5\n",
      "asiope1      4\n",
      "integr       4\n",
      "niwpig1      4\n",
      "Name: count, Length: 182, dtype: int64\n",
      "(4892, 14)\n",
      "primary_label\n",
      "zitcis1    100\n",
      "lirplo     100\n",
      "comgre     100\n",
      "comkin1    100\n",
      "commoo3    100\n",
      "          ... \n",
      "darter2      1\n",
      "asiope1      1\n",
      "wbbfly1      1\n",
      "integr       1\n",
      "blaeag1      1\n",
      "Name: count, Length: 182, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from local\n",
      "load from local 2\n",
      "323 323\n",
      "Tue May 14 00:31:52 2024 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  6.96it/s, grad=9.32e+3, loss=0.972, lr=1e-5]\n",
      "Epoch 1 - Train loss: 0.9718, Train cmAP_1 : 0.5056, Train cmAP_5 : 0.7110, Train ROC : 0.5267, \n",
      "100%|██████████| 77/77 [00:12<00:00,  6.22it/s, loss=0.215]\n",
      "Epoch 1 - Valid loss: 0.2151, Valid cmAP_1 : 0.1221, Valid cmAP_5 : 0.3257, Valid ROC : 0.5637, \n",
      "Epoch 1 - Save Best Score: 0.5637 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 14 00:32:53 2024 Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:44<00:00,  6.86it/s, grad=538, loss=0.0723, lr=2.8e-5]  \n",
      "Epoch 2 - Train loss: 0.0723, Train cmAP_1 : 0.4584, Train cmAP_5 : 0.6819, Train ROC : 0.5900, \n",
      "100%|██████████| 77/77 [00:13<00:00,  5.86it/s, loss=0.0414]\n",
      "Epoch 2 - Valid loss: 0.0414, Valid cmAP_1 : 0.1908, Valid cmAP_5 : 0.3976, Valid ROC : 0.7718, \n",
      "Epoch 2 - Save Best Score: 0.7718 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 14 00:33:54 2024 Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:47<00:00,  6.46it/s, grad=444, loss=0.0354, lr=4.6e-5]\n",
      "Epoch 3 - Train loss: 0.0354, Train cmAP_1 : 0.3827, Train cmAP_5 : 0.6299, Train ROC : 0.7783, \n",
      "100%|██████████| 77/77 [00:12<00:00,  5.95it/s, loss=0.0267]\n",
      "Epoch 3 - Valid loss: 0.0267, Valid cmAP_1 : 0.3721, Valid cmAP_5 : 0.5649, Valid ROC : 0.8854, \n",
      "Epoch 3 - Save Best Score: 0.8854 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 14 00:34:59 2024 Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  6.94it/s, grad=386, loss=0.0284, lr=6.4e-5]\n",
      "Epoch 4 - Train loss: 0.0284, Train cmAP_1 : 0.5122, Train cmAP_5 : 0.7215, Train ROC : 0.9224, \n",
      "100%|██████████| 77/77 [00:12<00:00,  5.94it/s, loss=0.0207]\n",
      "Epoch 4 - Valid loss: 0.0207, Valid cmAP_1 : 0.4728, Valid cmAP_5 : 0.6505, Valid ROC : 0.9269, \n",
      "Epoch 4 - Save Best Score: 0.9269 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 14 00:36:00 2024 Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  7.05it/s, grad=431, loss=0.0254, lr=8.2e-5]\n",
      "Epoch 5 - Train loss: 0.0254, Train cmAP_1 : 0.4451, Train cmAP_5 : 0.6806, Train ROC : 0.9410, \n",
      "100%|██████████| 77/77 [00:12<00:00,  5.99it/s, loss=0.0182]\n",
      "Epoch 5 - Valid loss: 0.0182, Valid cmAP_1 : 0.5335, Valid cmAP_5 : 0.6972, Valid ROC : 0.9425, \n",
      "Epoch 5 - Save Best Score: 0.9425 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 14 00:37:00 2024 Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 164/305 [00:24<00:24,  5.86it/s, grad=341, loss=0.0246, lr=0.0001]"
     ]
    }
   ],
   "source": [
    "train_fold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1239a098",
   "metadata": {
    "papermill": {
     "duration": 0.256068,
     "end_time": "2024-05-12T09:40:26.630956",
     "exception": false,
     "start_time": "2024-05-12T09:40:26.374888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c86a6b",
   "metadata": {
    "papermill": {
     "duration": 0.280707,
     "end_time": "2024-05-12T09:40:27.168404",
     "exception": false,
     "start_time": "2024-05-12T09:40:26.887697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66832171",
   "metadata": {
    "papermill": {
     "duration": 0.258824,
     "end_time": "2024-05-12T09:40:27.688057",
     "exception": false,
     "start_time": "2024-05-12T09:40:27.429233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8068726,
     "sourceId": 70203,
     "sourceType": "competition"
    },
    {
     "datasetId": 3174266,
     "sourceId": 5502329,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3202296,
     "sourceId": 5560891,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3373324,
     "sourceId": 5866811,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6003.429359,
   "end_time": "2024-05-12T09:40:31.495258",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-12T08:00:28.065899",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
