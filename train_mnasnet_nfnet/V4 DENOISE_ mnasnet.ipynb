{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe653c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:00:31.007333Z",
     "iopub.status.busy": "2024-05-12T08:00:31.006957Z",
     "iopub.status.idle": "2024-05-12T08:01:11.905151Z",
     "shell.execute_reply": "2024-05-12T08:01:11.904046Z"
    },
    "papermill": {
     "duration": 40.912614,
     "end_time": "2024-05-12T08:01:11.907617",
     "exception": false,
     "start_time": "2024-05-12T08:00:30.995003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install warmup_scheduler\n",
    "# !pip install torchlibrosa\n",
    "# !pip install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a76c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cce4df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function mel_frequencies in module librosa.core.convert:\n",
      "\n",
      "mel_frequencies(n_mels: 'int' = 128, *, fmin: 'float' = 0.0, fmax: 'float' = 11025.0, htk: 'bool' = False) -> 'np.ndarray'\n",
      "    Compute an array of acoustic frequencies tuned to the mel scale.\n",
      "    \n",
      "    The mel scale is a quasi-logarithmic function of acoustic frequency\n",
      "    designed such that perceptually similar pitch intervals (e.g. octaves)\n",
      "    appear equal in width over the full hearing range.\n",
      "    \n",
      "    Because the definition of the mel scale is conditioned by a finite number\n",
      "    of subjective psychoaoustical experiments, several implementations coexist\n",
      "    in the audio signal processing literature [#]_. By default, librosa replicates\n",
      "    the behavior of the well-established MATLAB Auditory Toolbox of Slaney [#]_.\n",
      "    According to this default implementation,  the conversion from Hertz to mel is\n",
      "    linear below 1 kHz and logarithmic above 1 kHz. Another available implementation\n",
      "    replicates the Hidden Markov Toolkit [#]_ (HTK) according to the following formula::\n",
      "    \n",
      "        mel = 2595.0 * np.log10(1.0 + f / 700.0).\n",
      "    \n",
      "    The choice of implementation is determined by the ``htk`` keyword argument: setting\n",
      "    ``htk=False`` leads to the Auditory toolbox implementation, whereas setting it ``htk=True``\n",
      "    leads to the HTK implementation.\n",
      "    \n",
      "    .. [#] Umesh, S., Cohen, L., & Nelson, D. Fitting the mel scale.\n",
      "        In Proc. International Conference on Acoustics, Speech, and Signal Processing\n",
      "        (ICASSP), vol. 1, pp. 217-220, 1998.\n",
      "    \n",
      "    .. [#] Slaney, M. Auditory Toolbox: A MATLAB Toolbox for Auditory\n",
      "        Modeling Work. Technical Report, version 2, Interval Research Corporation, 1998.\n",
      "    \n",
      "    .. [#] Young, S., Evermann, G., Gales, M., Hain, T., Kershaw, D., Liu, X.,\n",
      "        Moore, G., Odell, J., Ollason, D., Povey, D., Valtchev, V., & Woodland, P.\n",
      "        The HTK book, version 3.4. Cambridge University, March 2009.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    hz_to_mel\n",
      "    mel_to_hz\n",
      "    librosa.feature.melspectrogram\n",
      "    librosa.feature.mfcc\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    n_mels : int > 0 [scalar]\n",
      "        Number of mel bins.\n",
      "    fmin : float >= 0 [scalar]\n",
      "        Minimum frequency (Hz).\n",
      "    fmax : float >= 0 [scalar]\n",
      "        Maximum frequency (Hz).\n",
      "    htk : bool\n",
      "        If True, use HTK formula to convert Hz to mel.\n",
      "        Otherwise (False), use Slaney's Auditory Toolbox.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    bin_frequencies : ndarray [shape=(n_mels,)]\n",
      "        Vector of ``n_mels`` frequencies in Hz which are uniformly spaced on the Mel\n",
      "        axis.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> librosa.mel_frequencies(n_mels=40)\n",
      "    array([     0.   ,     85.317,    170.635,    255.952,\n",
      "              341.269,    426.586,    511.904,    597.221,\n",
      "              682.538,    767.855,    853.173,    938.49 ,\n",
      "             1024.856,   1119.114,   1222.042,   1334.436,\n",
      "             1457.167,   1591.187,   1737.532,   1897.337,\n",
      "             2071.84 ,   2262.393,   2470.47 ,   2697.686,\n",
      "             2945.799,   3216.731,   3512.582,   3835.643,\n",
      "             4188.417,   4573.636,   4994.285,   5453.621,\n",
      "             5955.205,   6502.92 ,   7101.009,   7754.107,\n",
      "             8467.272,   9246.028,  10096.408,  11025.   ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(librosa.mel_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9403b041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:11.936638Z",
     "iopub.status.busy": "2024-05-12T08:01:11.936282Z",
     "iopub.status.idle": "2024-05-12T08:01:12.912223Z",
     "shell.execute_reply": "2024-05-12T08:01:12.911426Z"
    },
    "papermill": {
     "duration": 0.993152,
     "end_time": "2024-05-12T08:01:12.914460",
     "exception": false,
     "start_time": "2024-05-12T08:01:11.921308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from audiomentations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2896ba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/kaggle/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "416fd425",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.545387Z",
     "start_time": "2024-05-02T08:55:32.908334Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:12.941690Z",
     "iopub.status.busy": "2024-05-12T08:01:12.940911Z",
     "iopub.status.idle": "2024-05-12T08:01:22.276389Z",
     "shell.execute_reply": "2024-05-12T08:01:22.275561Z"
    },
    "papermill": {
     "duration": 9.351354,
     "end_time": "2024-05-12T08:01:22.278668",
     "exception": false,
     "start_time": "2024-05-12T08:01:12.927314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from metrics import calculate_competition_metrics, metrics_to_string, calculate_competition_metrics_no_map\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from torch.optim import AdamW\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "try:\n",
    "    from itertools import  ifilterfalse\n",
    "except ImportError: # py3k\n",
    "    from itertools import  filterfalse as ifilterfalse\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2357b253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.306450Z",
     "iopub.status.busy": "2024-05-12T08:01:22.305944Z",
     "iopub.status.idle": "2024-05-12T08:01:22.322380Z",
     "shell.execute_reply": "2024-05-12T08:01:22.321424Z"
    },
    "papermill": {
     "duration": 0.031879,
     "end_time": "2024-05-12T08:01:22.324247",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.292368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def padded_cmap(solution, submission, padding_factor=5):\n",
    "    solution = solution#.drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission#.drop(['row_id'], axis=1, errors='ignore')\n",
    "    \n",
    "    new_rows = []\n",
    "    for i in range(padding_factor):\n",
    "        new_rows.append([1 for i in range(len(solution.columns))])\n",
    "    new_rows = pd.DataFrame(new_rows)\n",
    "    new_rows.columns = solution.columns\n",
    "    padded_solution = pd.concat([solution, new_rows]).reset_index(drop=True).copy()\n",
    "    padded_submission = pd.concat([submission, new_rows]).reset_index(drop=True).copy()\n",
    "    score = sklearn.metrics.average_precision_score(\n",
    "        padded_solution.values,\n",
    "        padded_submission.values,\n",
    "        average='macro',\n",
    "    )\n",
    "    return score\n",
    "\n",
    "def padded_auc(solution, submission, padding_factor=5):\n",
    "    solution = solution #.drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission #.drop(['row_id'], axis=1, errors='ignore')\n",
    "\n",
    "\n",
    "    solution_sums = solution.sum(axis=0)\n",
    "    scored_columns = list(solution_sums[solution_sums > 0].index.values)\n",
    "#     assert len(scored_columns) > 0\n",
    "\n",
    "    return sklearn.metrics.roc_auc_score(solution[scored_columns].values, submission[scored_columns].values, average='macro')\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    '''\n",
    "    Version of macro-averaged ROC-AUC score that ignores all classes that have no true positive labels.\n",
    "    '''\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "\n",
    "    solution_sums = solution.sum(axis=0)\n",
    "    scored_columns = list(solution_sums[solution_sums > 0].index.values)\n",
    "#     assert len(scored_columns) > 0\n",
    "\n",
    "    return sklearn.metrics.roc_auc_score(solution[scored_columns].values, submission[scored_columns].values, average='macro')\n",
    "\n",
    "def calculate_competition_metrics(gt, preds, target_columns, one_hot=True):\n",
    "    if not one_hot:\n",
    "        ground_truth = np.argmax(gt, axis=1)\n",
    "        gt = np.zeros((ground_truth.size, len(target_columns)))\n",
    "        gt[np.arange(ground_truth.size), ground_truth] = 1\n",
    "    val_df = pd.DataFrame(gt, columns=target_columns)\n",
    "    pred_df = pd.DataFrame(preds, columns=target_columns)\n",
    "    cmAP_1 = padded_cmap(val_df, pred_df, padding_factor=1)\n",
    "    cmAP_5 = padded_cmap(val_df, pred_df, padding_factor=5)\n",
    "    val_df['id'] = [f'id_{i}' for i in range(len(val_df))]\n",
    "    pred_df['id'] = [f'id_{i}' for i in range(len(pred_df))]\n",
    "    train_score = score(val_df, pred_df, row_id_column_name='id')\n",
    "    return {\n",
    "      \"cmAP_1\": cmAP_1,\n",
    "      \"cmAP_5\": cmAP_5,\n",
    "      \"ROC\": train_score,\n",
    "    }\n",
    "def metrics_to_string(scores, key_word):\n",
    "    log_info = \"\"\n",
    "    for key in scores.keys():\n",
    "        log_info = log_info + f\"{key_word} {key} : {scores[key]:.4f}, \"\n",
    "    return log_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7715e97",
   "metadata": {
    "papermill": {
     "duration": 0.012634,
     "end_time": "2024-05-12T08:01:22.349719",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.337085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169871b",
   "metadata": {
    "papermill": {
     "duration": 0.012227,
     "end_time": "2024-05-12T08:01:22.374472",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.362245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Epoch 1 - Train loss: 0.8522, Train cmAP_1 : 0.5357, Train cmAP_5 : 0.7442, \n",
    "Epoch 1 - Valid loss: 0.8485, Valid cmAP_1 : 0.1220, Valid cmAP_5 : 0.3257, Valid mAP : 0.0082, Valid ROC : 0.5372, \n",
    "Epoch 1 - Save Best Score: 0.5372 Model\n",
    "\n",
    "Epoch 2 - Train loss: 0.7673, Train cmAP_1 : 0.5354, Train cmAP_5 : 0.7419, \n",
    "Epoch 2 - Valid loss: 0.6464, Valid cmAP_1 : 0.1235, Valid cmAP_5 : 0.3270, Valid mAP : 0.0129, Valid ROC : 0.5611, \n",
    "Epoch 2 - Save Best Score: 0.5611 Model\n",
    "\n",
    "Epoch 3 - Train loss: 0.3128, Train cmAP_1 : 0.5624, Train cmAP_5 : 0.7448, \n",
    "Epoch 3 - Valid loss: 0.1051, Valid cmAP_1 : 0.0590, Valid cmAP_5 : 0.2511, Valid mAP : 0.0226, Valid ROC : 0.6110, \n",
    "Epoch 3 - Save Best Score: 0.6110 Model\n",
    "\n",
    "Epoch 4 - Train loss: 0.0411, Train cmAP_1 : 0.5409, Train cmAP_5 : 0.7417, \n",
    "Epoch 4 - Valid loss: 0.0401, Valid cmAP_1 : 0.1435, Valid cmAP_5 : 0.3504, Valid mAP : 0.0463, Valid ROC : 0.7263, \n",
    "Epoch 4 - Save Best Score: 0.7263 Model\n",
    "\n",
    "Epoch 5 - Train loss: 0.0350, Train cmAP_1 : 0.5427, Train cmAP_5 : 0.7459, \n",
    "Epoch 5 - Valid loss: 0.0328, Valid cmAP_1 : 0.2460, Valid cmAP_5 : 0.4553, Valid mAP : 0.2485, Valid ROC : 0.8743, \n",
    "Epoch 5 - Save Best Score: 0.8743 Model\n",
    "\n",
    "Epoch 6 - Train loss: 0.0288, Train cmAP_1 : 0.5864, Train cmAP_5 : 0.7732, \n",
    "Epoch 6 - Valid loss: 0.0261, Valid cmAP_1 : 0.3153, Valid cmAP_5 : 0.5258, Valid mAP : 0.3372, Valid ROC : 0.9202, \n",
    "Epoch 6 - Save Best Score: 0.9202 Model\n",
    "\n",
    "Epoch 7 - Train loss: 0.0256, Train cmAP_1 : 0.5644, Train cmAP_5 : 0.7617, \n",
    "Epoch 7 - Valid loss: 0.0274, Valid cmAP_1 : 0.3493, Valid cmAP_5 : 0.5602, Valid mAP : 0.3776, Valid ROC : 0.9380, \n",
    "Epoch 7 - Save Best Score: 0.9380 Model\n",
    "\n",
    "Epoch 8 - Train loss: 0.0236, Train cmAP_1 : 0.5792, Train cmAP_5 : 0.7725, \n",
    "Epoch 8 - Valid loss: 0.0198, Valid cmAP_1 : 0.4676, Valid cmAP_5 : 0.6471, Valid mAP : 0.5536, Valid ROC : 0.9509, \n",
    "Epoch 8 - Save Best Score: 0.9509 Model\n",
    "\n",
    "Epoch 9 - Train loss: 0.0223, Train cmAP_1 : 0.6052, Train cmAP_5 : 0.7826, \n",
    "Epoch 9 - Valid loss: 0.0202, Valid cmAP_1 : 0.4754, Valid cmAP_5 : 0.6594, Valid mAP : 0.5519, Valid ROC : 0.9569, \n",
    "Epoch 9 - Save Best Score: 0.9569 Model\n",
    "\n",
    "Epoch 10 - Train loss: 0.0217, Train cmAP_1 : 0.5950, Train cmAP_5 : 0.7810, \n",
    "Epoch 10 - Valid loss: 0.0198, Valid cmAP_1 : 0.4619, Valid cmAP_5 : 0.6518, Valid mAP : 0.5328, Valid ROC : 0.9592, \n",
    "Epoch 10 - Save Best Score: 0.9592 Model\n",
    "\n",
    "Epoch 11 - Train loss: 0.0202, Train cmAP_1 : 0.6104, Train cmAP_5 : 0.7915, \n",
    "Epoch 11 - Valid loss: 0.0166, Valid cmAP_1 : 0.5612, Valid cmAP_5 : 0.7150, Valid mAP : 0.6656, Valid ROC : 0.9641, \n",
    "Epoch 11 - Save Best Score: 0.9641 Model\n",
    "\n",
    "Epoch 12 - Train loss: 0.0197, Train cmAP_1 : 0.5942, Train cmAP_5 : 0.7841, \n",
    "Epoch 12 - Valid loss: 0.0162, Valid cmAP_1 : 0.5966, Valid cmAP_5 : 0.7349, Valid mAP : 0.6805, Valid ROC : 0.9634, \n",
    "Valid loss didn't improve last 1 epochs.\n",
    "\n",
    "Epoch 13 - Train loss: 0.0192, Train cmAP_1 : 0.5937, Train cmAP_5 : 0.7795, \n",
    "Epoch 13 - Valid loss: 0.0159, Valid cmAP_1 : 0.6153, Valid cmAP_5 : 0.7457, Valid mAP : 0.6893, Valid ROC : 0.9669, \n",
    "Epoch 13 - Save Best Score: 0.9669 Model\n",
    "\n",
    "Epoch 14 - Train loss: 0.0191, Train cmAP_1 : 0.5991, Train cmAP_5 : 0.7903, \n",
    "Epoch 14 - Valid loss: 0.0193, Valid cmAP_1 : 0.5310, Valid cmAP_5 : 0.7047, Valid mAP : 0.5732, Valid ROC : 0.9660, \n",
    "Valid loss didn't improve last 1 epochs.\n",
    "\n",
    "Epoch 15 - Train loss: 0.0180, Train cmAP_1 : 0.6038, Train cmAP_5 : 0.7822, \n",
    "Epoch 15 - Valid loss: 0.0163, Valid cmAP_1 : 0.5753, Valid cmAP_5 : 0.7283, Valid mAP : 0.6613, Valid ROC : 0.9656, \n",
    "Valid loss didn't improve last 2 epochs.\n",
    "\n",
    "Epoch 16 - Train loss: 0.0181, Train cmAP_1 : 0.6067, Train cmAP_5 : 0.7918, \n",
    "Epoch 16 - Valid loss: 0.0168, Valid cmAP_1 : 0.5555, Valid cmAP_5 : 0.7140, Valid mAP : 0.6448, Valid ROC : 0.9613, \n",
    "Valid loss didn't improve last 3 epochs.\n",
    "\n",
    "Epoch 17 - Train loss: 0.0176, Train cmAP_1 : 0.6181, Train cmAP_5 : 0.7918, \n",
    "Epoch 17 - Valid loss: 0.0160, Valid cmAP_1 : 0.5999, Valid cmAP_5 : 0.7436, Valid mAP : 0.6738, Valid ROC : 0.9670, \n",
    "Epoch 17 - Save Best Score: 0.9670 Model\n",
    "\n",
    "Epoch 18 - Train loss: 0.0169, Train cmAP_1 : 0.6040, Train cmAP_5 : 0.7897, \n",
    "Epoch 18 - Valid loss: 0.0174, Valid cmAP_1 : 0.5920, Valid cmAP_5 : 0.7447, Valid mAP : 0.6454, Valid ROC : 0.9690, \n",
    "Epoch 18 - Save Best Score: 0.9690 Model\n",
    "\n",
    "Epoch 19 - Train loss: 0.0162, Train cmAP_1 : 0.6005, Train cmAP_5 : 0.7870, \n",
    "Epoch 19 - Valid loss: 0.0174, Valid cmAP_1 : 0.5855, Valid cmAP_5 : 0.7397, Valid mAP : 0.6386, Valid ROC : 0.9682, \n",
    "Valid loss didn't improve last 1 epochs.\n",
    "\n",
    "Epoch 20 - Train loss: 0.0161, Train cmAP_1 : 0.6355, Train cmAP_5 : 0.8080, \n",
    "Epoch 20 - Valid loss: 0.0151, Valid cmAP_1 : 0.6357, Valid cmAP_5 : 0.7629, Valid mAP : 0.7092, Valid ROC : 0.9683, \n",
    "Valid loss didn't improve last 2 epochs.\n",
    "\n",
    "Epoch 21 - Train loss: 0.0157, Train cmAP_1 : 0.6019, Train cmAP_5 : 0.7856, \n",
    "Epoch 21 - Valid loss: 0.0162, Valid cmAP_1 : 0.5980, Valid cmAP_5 : 0.7464, Valid mAP : 0.6594, Valid ROC : 0.9675, \n",
    "Valid loss didn't improve last 3 epochs.\n",
    "\n",
    "Epoch 22 - Train loss: 0.0160, Train cmAP_1 : 0.5569, Train cmAP_5 : 0.7717, \n",
    "Epoch 22 - Valid loss: 0.0148, Valid cmAP_1 : 0.6402, Valid cmAP_5 : 0.7668, Valid mAP : 0.7204, Valid ROC : 0.9673, \n",
    "Valid loss didn't improve last 4 epochs.\n",
    "\n",
    "Epoch 23 - Train loss: 0.0158, Train cmAP_1 : 0.6211, Train cmAP_5 : 0.8011, \n",
    "Epoch 23 - Valid loss: 0.0150, Valid cmAP_1 : 0.6254, Valid cmAP_5 : 0.7594, Valid mAP : 0.7124, Valid ROC : 0.9642, \n",
    "Valid loss didn't improve last 5 epochs.\n",
    "\n",
    "Epoch 24 - Train loss: 0.0153, Train cmAP_1 : 0.5914, Train cmAP_5 : 0.7817, \n",
    "Epoch 24 - Valid loss: 0.0154, Valid cmAP_1 : 0.6207, Valid cmAP_5 : 0.7590, Valid mAP : 0.6824, Valid ROC : 0.9650, \n",
    "Valid loss didn't improve last 6 epochs.\n",
    "\n",
    "Epoch 25 - Train loss: 0.0143, Train cmAP_1 : 0.6056, Train cmAP_5 : 0.7859, \n",
    "Epoch 25 - Valid loss: 0.0155, Valid cmAP_1 : 0.6094, Valid cmAP_5 : 0.7542, Valid mAP : 0.6769, Valid ROC : 0.9680, \n",
    "Valid loss didn't improve last 7 epochs.\n",
    "\n",
    "Early stop, Training End.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb135ac3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.550548Z",
     "start_time": "2024-05-02T08:55:35.546391Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.400650Z",
     "iopub.status.busy": "2024-05-12T08:01:22.400295Z",
     "iopub.status.idle": "2024-05-12T08:01:22.458884Z",
     "shell.execute_reply": "2024-05-12T08:01:22.458041Z"
    },
    "papermill": {
     "duration": 0.07395,
     "end_time": "2024-05-12T08:01:22.460750",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.386800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_name = 'exp1'\n",
    "# backbone = 'eca_nfnet_l0'\n",
    "seed = 42\n",
    "batch_size =  64\n",
    "num_workers = 12\n",
    "\n",
    "n_epochs = 50\n",
    "warmup_epo = 5\n",
    "cosine_epo = n_epochs - warmup_epo\n",
    "\n",
    "image_size = 256 #128 #256\n",
    "\n",
    "lr_max = 1e-5\n",
    "lr_min = 1e-7\n",
    "weight_decay = 1e-6\n",
    "\n",
    "# mel_spec_params = {\n",
    "#     \"sample_rate\": 32000,\n",
    "#     \"n_mels\": 128,\n",
    "#     \"f_min\": 20,\n",
    "#     \"f_max\": 16000,\n",
    "#     \"n_fft\": 1024,\n",
    "#     \"hop_length\": 320,\n",
    "#     \"normalized\": True,\n",
    "#     \"center\" : True,\n",
    "#     \"pad_mode\" : \"constant\",\n",
    "#     \"norm\" : \"slaney\",\n",
    "#     \"onesided\" : True,\n",
    "#     \"mel_scale\" : \"slaney\"\n",
    "# }\n",
    "\n",
    "mel_spec_params = {\n",
    "    \"sample_rate\": 32000,\n",
    "    \"n_mels\": 128,\n",
    "    \"f_min\": 20,\n",
    "    \"f_max\": 16000,\n",
    "    \"n_fft\": 2048,\n",
    "    \"hop_length\": 512,\n",
    "    \"normalized\": True,\n",
    "    \"center\" : True,\n",
    "    \"pad_mode\" : \"constant\",\n",
    "    \"norm\" : \"slaney\",\n",
    "    \"onesided\" : True,\n",
    "    \"mel_scale\" : \"slaney\"\n",
    "}\n",
    "\n",
    "top_db = 80\n",
    "train_period = 5\n",
    "val_period = 5\n",
    "\n",
    "secondary_coef = 1.0\n",
    "\n",
    "train_duration = train_period * mel_spec_params[\"sample_rate\"]\n",
    "val_duration = val_period * mel_spec_params[\"sample_rate\"]\n",
    "\n",
    "N_FOLD = 5\n",
    "fold = 2\n",
    "\n",
    "use_amp = True\n",
    "max_grad_norm = 10\n",
    "early_stopping = 7\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "output_folder = \"outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(os.path.join(output_folder, exp_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5f73f",
   "metadata": {
    "papermill": {
     "duration": 0.012306,
     "end_time": "2024-05-12T08:01:22.485843",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.473537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Seed Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fced25a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.567584Z",
     "start_time": "2024-05-02T08:55:35.550548Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.512437Z",
     "iopub.status.busy": "2024-05-12T08:01:22.512065Z",
     "iopub.status.idle": "2024-05-12T08:01:22.520280Z",
     "shell.execute_reply": "2024-05-12T08:01:22.519593Z"
    },
    "papermill": {
     "duration": 0.02401,
     "end_time": "2024-05-12T08:01:22.522237",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.498227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5616b57d",
   "metadata": {
    "papermill": {
     "duration": 0.012058,
     "end_time": "2024-05-12T08:01:22.546849",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.534791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a855440",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.624574Z",
     "start_time": "2024-05-02T08:55:35.567584Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.572945Z",
     "iopub.status.busy": "2024-05-12T08:01:22.572620Z",
     "iopub.status.idle": "2024-05-12T08:01:22.814323Z",
     "shell.execute_reply": "2024-05-12T08:01:22.813423Z"
    },
    "papermill": {
     "duration": 0.257192,
     "end_time": "2024-05-12T08:01:22.816514",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.559322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'asbfly': 0, 'ashdro1': 1, 'ashpri1': 2, 'ashwoo2': 3, 'asikoe2': 4, 'asiope1': 5, 'aspfly1': 6, 'aspswi1': 7, 'barfly1': 8, 'barswa': 9, 'bcnher': 10, 'bkcbul1': 11, 'bkrfla1': 12, 'bkskit1': 13, 'bkwsti': 14, 'bladro1': 15, 'blaeag1': 16, 'blakit1': 17, 'blhori1': 18, 'blnmon1': 19, 'blrwar1': 20, 'bncwoo3': 21, 'brakit1': 22, 'brasta1': 23, 'brcful1': 24, 'brfowl1': 25, 'brnhao1': 26, 'brnshr': 27, 'brodro1': 28, 'brwjac1': 29, 'brwowl1': 30, 'btbeat1': 31, 'bwfshr1': 32, 'categr': 33, 'chbeat1': 34, 'cohcuc1': 35, 'comfla1': 36, 'comgre': 37, 'comior1': 38, 'comkin1': 39, 'commoo3': 40, 'commyn': 41, 'compea': 42, 'comros': 43, 'comsan': 44, 'comtai1': 45, 'copbar1': 46, 'crbsun2': 47, 'cregos1': 48, 'crfbar1': 49, 'crseag1': 50, 'dafbab1': 51, 'darter2': 52, 'eaywag1': 53, 'emedov2': 54, 'eucdov': 55, 'eurbla2': 56, 'eurcoo': 57, 'forwag1': 58, 'gargan': 59, 'gloibi': 60, 'goflea1': 61, 'graher1': 62, 'grbeat1': 63, 'grecou1': 64, 'greegr': 65, 'grefla1': 66, 'grehor1': 67, 'grejun2': 68, 'grenig1': 69, 'grewar3': 70, 'grnsan': 71, 'grnwar1': 72, 'grtdro1': 73, 'gryfra': 74, 'grynig2': 75, 'grywag': 76, 'gybpri1': 77, 'gyhcaf1': 78, 'heswoo1': 79, 'hoopoe': 80, 'houcro1': 81, 'houspa': 82, 'inbrob1': 83, 'indpit1': 84, 'indrob1': 85, 'indrol2': 86, 'indtit1': 87, 'ingori1': 88, 'inpher1': 89, 'insbab1': 90, 'insowl1': 91, 'integr': 92, 'isbduc1': 93, 'jerbus2': 94, 'junbab2': 95, 'junmyn1': 96, 'junowl1': 97, 'kenplo1': 98, 'kerlau2': 99, 'labcro1': 100, 'laudov1': 101, 'lblwar1': 102, 'lesyel1': 103, 'lewduc1': 104, 'lirplo': 105, 'litegr': 106, 'litgre1': 107, 'litspi1': 108, 'litswi1': 109, 'lobsun2': 110, 'maghor2': 111, 'malpar1': 112, 'maltro1': 113, 'malwoo1': 114, 'marsan': 115, 'mawthr1': 116, 'moipig1': 117, 'nilfly2': 118, 'niwpig1': 119, 'nutman': 120, 'orihob2': 121, 'oripip1': 122, 'pabflo1': 123, 'paisto1': 124, 'piebus1': 125, 'piekin1': 126, 'placuc3': 127, 'plaflo1': 128, 'plapri1': 129, 'plhpar1': 130, 'pomgrp2': 131, 'purher1': 132, 'pursun3': 133, 'pursun4': 134, 'purswa3': 135, 'putbab1': 136, 'redspu1': 137, 'rerswa1': 138, 'revbul': 139, 'rewbul': 140, 'rewlap1': 141, 'rocpig': 142, 'rorpar': 143, 'rossta2': 144, 'rufbab3': 145, 'ruftre2': 146, 'rufwoo2': 147, 'rutfly6': 148, 'sbeowl1': 149, 'scamin3': 150, 'shikra1': 151, 'smamin1': 152, 'sohmyn1': 153, 'spepic1': 154, 'spodov': 155, 'spoowl1': 156, 'sqtbul1': 157, 'stbkin1': 158, 'sttwoo1': 159, 'thbwar1': 160, 'tibfly3': 161, 'tilwar1': 162, 'vefnut1': 163, 'vehpar1': 164, 'wbbfly1': 165, 'wemhar1': 166, 'whbbul2': 167, 'whbsho3': 168, 'whbtre1': 169, 'whbwag1': 170, 'whbwat1': 171, 'whbwoo2': 172, 'whcbar1': 173, 'whiter2': 174, 'whrmun': 175, 'whtkin2': 176, 'woosan': 177, 'wynlau1': 178, 'yebbab1': 179, 'yebbul3': 180, 'zitcis1': 181}\n"
     ]
    }
   ],
   "source": [
    "ROOT = \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/birdclef-2024\"\n",
    "\n",
    "df = pd.read_csv(f'{ROOT}/train_metadata.csv')\n",
    "df[\"path\"] = f\"{ROOT}/train_audio/\" + df[\"filename\"]\n",
    "df[\"rating\"] = np.clip(df[\"rating\"] / df[\"rating\"].max(), 0.1, 1.0)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLD, random_state=seed, shuffle=True)\n",
    "df['fold'] = -1\n",
    "for ifold, (train_idx, val_idx) in enumerate(skf.split(X=df, y=df[\"primary_label\"].values)):\n",
    "    df.loc[val_idx, 'fold'] = ifold\n",
    "\n",
    "sub = pd.read_csv(f\"{ROOT}/sample_submission.csv\")\n",
    "target_columns = sub.columns.tolist()[1:]\n",
    "num_classes = len(target_columns)\n",
    "bird2id = {b: i for i, b in enumerate(target_columns)}\n",
    "print(bird2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e246d",
   "metadata": {
    "papermill": {
     "duration": 0.012283,
     "end_time": "2024-05-12T08:01:22.841622",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.829339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f29a25f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.63072Z",
     "start_time": "2024-05-02T08:55:35.625578Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.868563Z",
     "iopub.status.busy": "2024-05-12T08:01:22.868198Z",
     "iopub.status.idle": "2024-05-12T08:01:22.894735Z",
     "shell.execute_reply": "2024-05-12T08:01:22.893788Z"
    },
    "papermill": {
     "duration": 0.042423,
     "end_time": "2024-05-12T08:01:22.896620",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.854197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_melspec(X, eps=1e-6):\n",
    "    mean = X.mean((1, 2), keepdim=True)\n",
    "    std = X.std((1, 2), keepdim=True)\n",
    "    Xstd = (X - mean) / (std + eps)\n",
    "\n",
    "    norm_min, norm_max = (\n",
    "        Xstd.min(-1)[0].min(-1)[0],\n",
    "        Xstd.max(-1)[0].max(-1)[0],\n",
    "    )\n",
    "    fix_ind = (norm_max - norm_min) > eps * torch.ones_like(\n",
    "        (norm_max - norm_min)\n",
    "    )\n",
    "    V = torch.zeros_like(Xstd)\n",
    "    if fix_ind.sum():\n",
    "        V_fix = Xstd[fix_ind]\n",
    "        norm_max_fix = norm_max[fix_ind, None, None]\n",
    "        norm_min_fix = norm_min[fix_ind, None, None]\n",
    "        V_fix = torch.max(\n",
    "            torch.min(V_fix, norm_max_fix),\n",
    "            norm_min_fix,\n",
    "        )\n",
    "        V_fix = (V_fix - norm_min_fix) / (norm_max_fix - norm_min_fix)\n",
    "        V[fix_ind] = V_fix\n",
    "    return V\n",
    "\n",
    "\n",
    "def SpectralNoiseReduction(audio_data, sr, min_length_sec=5):\n",
    "    # Skip processing if the length of the audio data is less than the specified minimum length in seconds\n",
    "    if len(audio_data) < sr * min_length_sec:\n",
    "        return audio_data\n",
    "\n",
    "    # Calculate the transition of noise levels across the audio data using a window size of 3 seconds and an overlap of 1.5 seconds\n",
    "    hop_length = int(sr * 1.5)  # 1.5 seconds overlap\n",
    "    win_length = int(sr * 3)    # 3 seconds window size\n",
    "    rms = librosa.feature.rms(y=audio_data, frame_length=win_length, hop_length=hop_length)\n",
    "\n",
    "    # Identify the time with the smallest noise level\n",
    "    noise_sec = 1  # noise reference length in seconds\n",
    "    min_rms_idx = np.argmin(rms)  # index of the minimum RMS value\n",
    "    start_idx = min_rms_idx * hop_length\n",
    "    end_idx = start_idx + sr * noise_sec  # Extract 1 second of data around the time of minimum noise\n",
    "\n",
    "    # Adjust the indices to make sure they are within the bounds of the audio data\n",
    "    start_idx = max(0, start_idx)  # Ensure start index is not negative\n",
    "    end_idx = min(len(audio_data), end_idx)  # Ensure end index does not exceed the length of the audio data\n",
    "\n",
    "    # Use the extracted data as the reference noise data\n",
    "    noise_data = audio_data[start_idx:end_idx]\n",
    "\n",
    "    # Perform noise reduction\n",
    "    return nr.reduce_noise(y=audio_data, sr=sr, y_noise=noise_data)\n",
    "\n",
    "def read_wav(path):\n",
    "    wav, org_sr = torchaudio.load(path, normalize=True)\n",
    "    wav = SpectralNoiseReduction(wav,sr=org_sr)\n",
    "    wav = torchaudio.functional.resample(wav, orig_freq=org_sr, new_freq=mel_spec_params[\"sample_rate\"])\n",
    "    return wav\n",
    "\n",
    "\n",
    "def crop_start_wav(wav, duration_):\n",
    "    while wav.size(-1) < duration_:\n",
    "        wav = torch.cat([wav, wav], dim=1)\n",
    "    wav = wav[:, :duration_]\n",
    "    return wav\n",
    "\n",
    "def crop_random_wav(wav, duration_):\n",
    "    while wav.size(-1) < duration_:\n",
    "        wav = torch.cat([wav, wav], dim=1)\n",
    "    start = np.random.randint(wav.shape[1]-duration_)\n",
    "    wav = wav[:, start:start+duration_]\n",
    "    return wav\n",
    "\n",
    "def random_power(images, power=1.5, c=0.7):\n",
    "    images = images - images.min()\n",
    "    images = images / (images.max() + 0.0000001)\n",
    "    images = images ** (random.random() * power + c)\n",
    "    return images\n",
    "\n",
    "class BirdDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform=None, add_secondary_labels=True, mode=\"train\"):\n",
    "        self.df = df\n",
    "        self.bird2id = bird2id\n",
    "        self.num_classes = num_classes\n",
    "        self.secondary_coef = secondary_coef\n",
    "        self.add_secondary_labels = add_secondary_labels\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(**mel_spec_params)\n",
    "        self.db_transform = torchaudio.transforms.AmplitudeToDB(stype='power', top_db=top_db)\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            self.wave_transforms = A.Compose(\n",
    "                [\n",
    "#                     OneOf([\n",
    "#                         Gain(min_gain_in_db=-15, max_gain_in_db=15, p=0.8),\n",
    "#                         GainTransition(min_gain_in_db=-15, max_gain_in_db=15, p=0.8),\n",
    "#                     ]),\n",
    "#                     OneOf(\n",
    "#                         [\n",
    "#                             NoiseInjection(p=1, max_noise_level=0.04),\n",
    "#                             GaussianNoise(p=1, min_snr=5, max_snr=20),\n",
    "#                             PinkNoise(p=1, min_snr=5, max_snr=20),\n",
    "#                             AddGaussianNoise(min_amplitude=0.0001, max_amplitude=0.03, p=0.5),\n",
    "#                             AddGaussianSNR(min_snr_in_db=5, max_snr_in_db=15, p=0.5),\n",
    "#                         ],\n",
    "#                         p=0.3,\n",
    "#                     ),\n",
    "                    AddBackgroundNoise(\n",
    "                        sounds_path=\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/input/backgroud_noise/archive/birdclef2021_nocall\", min_snr_in_db=0, max_snr_in_db=2, p=0.5\n",
    "                    ),\n",
    "                    A.Normalize(p=1),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.wave_transforms = Compose(\n",
    "                [\n",
    "                    Normalize(p=1),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def prepare_target(self, primary_label, secondary_labels):\n",
    "        secondary_labels = eval(secondary_labels)\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if primary_label != 'nocall':\n",
    "            primary_label = self.bird2id[primary_label]\n",
    "            target[primary_label] = 1.0\n",
    "            if self.add_secondary_labels:\n",
    "                for s in secondary_labels:\n",
    "                    if s != \"\" and s in self.bird2id.keys():\n",
    "                        target[self.bird2id[s]] = self.secondary_coef\n",
    "        target = torch.from_numpy(target).float()\n",
    "        return target\n",
    "    \n",
    "    def prepare_spec(self, path):\n",
    "        wav = read_wav(path)\n",
    "        if self.mode=='train':\n",
    "            wav = crop_start_wav(wav, train_duration)\n",
    "        else:\n",
    "            wav = crop_start_wav(wav, train_duration)\n",
    "        if self.wave_transforms:\n",
    "            ttt = self.wave_transforms(wav[0, :].numpy(), sample_rate=32000)\n",
    "            print(ttt)\n",
    "            wav[0, :] = torch.tensor(ttt).float() #self.wave_transforms(wav[0, :], sample_rate=32000)\n",
    "        tmp = self.mel_transform(wav)\n",
    "        if self.mode==\"train\":\n",
    "            tmp[0, :] = random_power(tmp[0, :], power=3, c=0.5)\n",
    "#         print(tmp.shape)\n",
    "        mel_spectrogram = normalize_melspec(self.db_transform(tmp))\n",
    "        mel_spectrogram = mel_spectrogram * 255\n",
    "        mel_spectrogram = mel_spectrogram.expand(3, -1, -1).permute(1, 2, 0).numpy()\n",
    "        return mel_spectrogram\n",
    "\n",
    "#     def prepare_spec(self, path):\n",
    "#         wav = read_wav(path)\n",
    "#         wav = crop_start_wav(wav, train_duration)\n",
    "#         mel_spectrogram = normalize_melspec(self.db_transform(self.mel_transform(wav)))\n",
    "#         mel_spectrogram = mel_spectrogram * 255\n",
    "#         mel_spectrogram = mel_spectrogram.expand(3, -1, -1).permute(1, 2, 0).numpy()\n",
    "#         return mel_spectrogram\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df[\"path\"].iloc[idx]\n",
    "        primary_label = self.df[\"primary_label\"].iloc[idx]\n",
    "        secondary_labels = self.df[\"secondary_labels\"].iloc[idx]\n",
    "        rating = self.df[\"rating\"].iloc[idx]\n",
    "\n",
    "        spec = self.prepare_spec(path)\n",
    "        target = self.prepare_target(primary_label, secondary_labels)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            res = self.transform(image=spec)\n",
    "            spec = res['image'].astype(np.float32)\n",
    "        else:\n",
    "            spec = spec.astype(np.float32)\n",
    "\n",
    "        spec = spec.transpose(2, 0, 1)\n",
    "\n",
    "        return {\"spec\": spec, \"target\": target, 'rating': rating}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0c40a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_melspec(X, eps=1e-6):\n",
    "    mean = X.mean((1, 2), keepdim=True)\n",
    "    std = X.std((1, 2), keepdim=True)\n",
    "    Xstd = (X - mean) / (std + eps)\n",
    "\n",
    "    norm_min, norm_max = (\n",
    "        Xstd.min(-1)[0].min(-1)[0],\n",
    "        Xstd.max(-1)[0].max(-1)[0],\n",
    "    )\n",
    "    fix_ind = (norm_max - norm_min) > eps * torch.ones_like(\n",
    "        (norm_max - norm_min)\n",
    "    )\n",
    "    V = torch.zeros_like(Xstd)\n",
    "    if fix_ind.sum():\n",
    "        V_fix = Xstd[fix_ind]\n",
    "        norm_max_fix = norm_max[fix_ind, None, None]\n",
    "        norm_min_fix = norm_min[fix_ind, None, None]\n",
    "        V_fix = torch.max(\n",
    "            torch.min(V_fix, norm_max_fix),\n",
    "            norm_min_fix,\n",
    "        )\n",
    "        V_fix = (V_fix - norm_min_fix) / (norm_max_fix - norm_min_fix)\n",
    "        V[fix_ind] = V_fix\n",
    "    return V\n",
    "\n",
    "\n",
    "def read_wav(path):\n",
    "    wav, org_sr = torchaudio.load(path, normalize=True)\n",
    "    wav = torchaudio.functional.resample(wav, orig_freq=org_sr, new_freq=mel_spec_params[\"sample_rate\"])\n",
    "    return wav\n",
    "\n",
    "\n",
    "def crop_start_wav(wav, duration_):\n",
    "    while wav.size(-1) < duration_:\n",
    "        wav = torch.cat([wav, wav], dim=1)\n",
    "    wav = wav[:, :duration_]\n",
    "    return wav\n",
    "\n",
    "\n",
    "class BirdDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform=None, add_secondary_labels=True):\n",
    "        self.df = df\n",
    "        self.bird2id = bird2id\n",
    "        self.num_classes = num_classes\n",
    "        self.secondary_coef = secondary_coef\n",
    "        self.add_secondary_labels = add_secondary_labels\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(**mel_spec_params)\n",
    "        self.db_transform = torchaudio.transforms.AmplitudeToDB(stype='power', top_db=top_db)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def prepare_target(self, primary_label, secondary_labels):\n",
    "        secondary_labels = eval(secondary_labels)\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if primary_label != 'nocall':\n",
    "            primary_label = self.bird2id[primary_label]\n",
    "            target[primary_label] = 1.0\n",
    "            if self.add_secondary_labels:\n",
    "                for s in secondary_labels:\n",
    "                    if s != \"\" and s in self.bird2id.keys():\n",
    "                        target[self.bird2id[s]] = self.secondary_coef\n",
    "        target = torch.from_numpy(target).float()\n",
    "        return target\n",
    "    \n",
    "    def remove_below_300Hz(self, mel_spectrogram, sr):\n",
    "        \n",
    "        # 计算Mel频谱图对应的频率\n",
    "        mel_freqs = librosa.mel_frequencies(n_mels=mel_spectrogram.shape[0], fmin=0, fmax=sr/2)\n",
    "        \n",
    "        # 找到低于300Hz的频率对应的索引\n",
    "        idx_to_remove = np.where(mel_freqs < 300)[0]\n",
    "        \n",
    "        # 将低于300Hz的部分替换为最小值\n",
    "        mel_spectrogram_filtered = np.copy(mel_spectrogram)\n",
    "        mel_spectrogram_filtered[idx_to_remove, :] = np.min(mel_spectrogram)\n",
    "        \n",
    "        return mel_spectrogram_filtered\n",
    "    def prepare_spec(self, path):\n",
    "        wav = read_wav(path)\n",
    "        wav = crop_start_wav(wav, train_duration)\n",
    "        mel_spectrogram = normalize_melspec(self.db_transform(self.mel_transform(wav)))\n",
    "        mel_spectrogram = mel_spectrogram * 255\n",
    "        mel_spectrogram = mel_spectrogram.expand(3, -1, -1).permute(1, 2, 0).numpy()\n",
    "        return mel_spectrogram\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df[\"path\"].iloc[idx]\n",
    "        primary_label = self.df[\"primary_label\"].iloc[idx]\n",
    "        secondary_labels = self.df[\"secondary_labels\"].iloc[idx]\n",
    "        rating = self.df[\"rating\"].iloc[idx]\n",
    "\n",
    "        spec = self.prepare_spec(path)\n",
    "        target = self.prepare_target(primary_label, secondary_labels)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            res = self.transform(image=spec)\n",
    "            spec = res['image'].astype(np.float32)\n",
    "        else:\n",
    "            spec = spec.astype(np.float32)\n",
    "\n",
    "        spec = spec.transpose(2, 0, 1)\n",
    "\n",
    "        return {\"spec\": spec, \"target\": target, 'rating': rating}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80681e",
   "metadata": {
    "papermill": {
     "duration": 0.012246,
     "end_time": "2024-05-12T08:01:22.921605",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.909359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df0c52df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.948162Z",
     "iopub.status.busy": "2024-05-12T08:01:22.947478Z",
     "iopub.status.idle": "2024-05-12T08:01:22.951718Z",
     "shell.execute_reply": "2024-05-12T08:01:22.950791Z"
    },
    "papermill": {
     "duration": 0.019548,
     "end_time": "2024-05-12T08:01:22.953599",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.934051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CNN_ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "325ad2e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.638517Z",
     "start_time": "2024-05-02T08:55:35.63072Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:22.979453Z",
     "iopub.status.busy": "2024-05-12T08:01:22.979172Z",
     "iopub.status.idle": "2024-05-12T08:01:22.990401Z",
     "shell.execute_reply": "2024-05-12T08:01:22.989550Z"
    },
    "papermill": {
     "duration": 0.02635,
     "end_time": "2024-05-12T08:01:22.992297",
     "exception": false,
     "start_time": "2024-05-12T08:01:22.965947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeM(torch.nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = torch.nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, ch, h, w = x.shape\n",
    "        x = torch.nn.functional.avg_pool2d(x.clamp(min=self.eps).pow(self.p), (x.size(-2), x.size(-1))).pow(\n",
    "            1.0 / self.p)\n",
    "        x = x.view(bs, ch)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, backbone, pretrained):\n",
    "        super().__init__()\n",
    "\n",
    "        out_indices = (3, 4)\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone,\n",
    "            features_only=True,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=3,\n",
    "            num_classes=num_classes,\n",
    "            out_indices=out_indices,\n",
    "        )\n",
    "        feature_dims = self.backbone.feature_info.channels()\n",
    "        print(f\"feature dims: {feature_dims}\")\n",
    "\n",
    "        self.global_pools = torch.nn.ModuleList([GeM() for _ in out_indices])\n",
    "        self.mid_features = np.sum(feature_dims)\n",
    "        self.neck = torch.nn.BatchNorm1d(self.mid_features)\n",
    "        self.head = torch.nn.Linear(self.mid_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        ms = self.backbone(x)\n",
    "        h = torch.cat([global_pool(m) for m, global_pool in zip(ms, self.global_pools)], dim=1)\n",
    "        x = self.neck(h)\n",
    "        x = self.head(x)\n",
    "#         print(x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b5a23a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.018966Z",
     "iopub.status.busy": "2024-05-12T08:01:23.018683Z",
     "iopub.status.idle": "2024-05-12T08:01:23.056797Z",
     "shell.execute_reply": "2024-05-12T08:01:23.055941Z"
    },
    "papermill": {
     "duration": 0.054001,
     "end_time": "2024-05-12T08:01:23.058736",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.004735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def init_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Conv2d\") != -1:\n",
    "        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        model.weight.data.normal_(1.0, 0.02)\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"GRU\") != -1:\n",
    "        for weight in model.parameters():\n",
    "            if len(weight.size()) > 1:\n",
    "                nn.init.orghogonal_(weight.data)\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        model.weight.data.normal_(0, 0.01)\n",
    "        model.bias.data.zero_()\n",
    "\n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    output = F.interpolate(\n",
    "        framewise_output.unsqueeze(1),\n",
    "        size=(frames_num, framewise_output.size(2)),\n",
    "        align_corners=True,\n",
    "        mode=\"bilinear\").squeeze(1)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class TimmSED(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            base_model_name: str,\n",
    "            config=None,\n",
    "            pretrained=False,\n",
    "            num_classes=24,\n",
    "            in_channels=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        self.spec_augmenter = SpecAugmentation(\n",
    "            time_drop_width=64 // 2,\n",
    "            time_stripes_num=2,\n",
    "            freq_drop_width=8 // 2,\n",
    "            freq_stripes_num=2\n",
    "        )\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(self.config.n_mels)\n",
    "\n",
    "        base_model = timm.create_model(\n",
    "            base_model_name,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=in_channels,\n",
    "        )\n",
    "\n",
    "        layers = list(base_model.children())[:-2]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        if \"eca_nfnet_l0\" == base_model_name:\n",
    "            in_features = base_model.num_features\n",
    "        elif hasattr(base_model, \"fc\"):\n",
    "            in_features = base_model.fc.in_features\n",
    "        else:\n",
    "            in_features = base_model.classifier.in_features\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n",
    "        self.att_block = AttBlockV2(\n",
    "            in_features, num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        # self.init_weight()\n",
    "        if len(self.config.local_pretrain_path) > 0:\n",
    "\n",
    "            print(\"load from local\")\n",
    "            state_dict = self.state_dict()\n",
    "            avg_state_dict = {}\n",
    "\n",
    "            for model_path in self.config.local_pretrain_path:\n",
    "\n",
    "                if model_path[-3:] == \"pth\":\n",
    "                    model_state_dict = torch.load(model_path)[\"model\"]\n",
    "                elif model_path[-3:] == \"bin\":\n",
    "                    model_state_dict = torch.load(model_path, map_location='cuda:0')\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                # model_state_dict = torch.load(model_path)[\"model\"]\n",
    "                backbone_keys = [key for key in model_state_dict.keys()]\n",
    "                print(\"load from local 2\")\n",
    "                for backbone_key in backbone_keys:\n",
    "                    base_model_key = backbone_key\n",
    "\n",
    "                    if base_model_key not in avg_state_dict:\n",
    "                        avg_state_dict[base_model_key] = model_state_dict[backbone_key] / \\\n",
    "                                                            len(self.config.local_pretrain_path)\n",
    "                    else:\n",
    "                        avg_state_dict[base_model_key] += model_state_dict[backbone_key] / \\\n",
    "                                                         len(self.config.local_pretrain_path)\n",
    "\n",
    "            print(len(state_dict.keys()), len(avg_state_dict.keys()))\n",
    "            for key, key_ in zip(state_dict.keys(), avg_state_dict.keys()):\n",
    "#                 print(key, key_)\n",
    "#                 if 'att_block' or 'bn0' in key:\n",
    "                if 'att_block' in key:\n",
    "                    # print(key)\n",
    "                    continue\n",
    "                state_dict[key] = avg_state_dict[key_]\n",
    "\n",
    "            self.load_state_dict(state_dict)\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # x = input_data  # (batch_size, 3, time_steps, mel_bins)\n",
    "        x = input_data[:, [0], :, :]  # (batch_size, 1, time_steps, mel_bins)\n",
    "        x = x.transpose(2, 3)\n",
    "        # print(x.shape, 'in')\n",
    "\n",
    "        frames_num = x.shape[2]\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        if self.training:\n",
    "            if random.random() < 0.25:\n",
    "                x = self.spec_augmenter(x)\n",
    "\n",
    "        x = x.transpose(2, 3)\n",
    "\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # Aggregate in frequency axis\n",
    "        x = torch.mean(x, dim=2)\n",
    "\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        \n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        interpolate_ratio = frames_num // segmentwise_output.size(1)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n",
    "        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"segmentwise_output\": segmentwise_output,\n",
    "            \"clipwise_output\": clipwise_output,\n",
    "            \"logit\": logit,\n",
    "            \"framewise_logit\": framewise_logit.max(dim=1)[0],\n",
    "            \"segmentwise_logit\": segmentwise_logit.max(dim=1)[0],            \n",
    "        }\n",
    "        \n",
    "        # segmentwise_logit = segmentwise_output? logit=clipwise_output? framewise_logit=framewise_output?\n",
    "        return output_dict\n",
    "        \n",
    "        \n",
    "#         torch.sigmoid(preds['logit'])\n",
    "#         segmentwise_output_with_max, _ = segmentwise_output.max(dim=1)\n",
    "#         logit = torch.sigmoid(logit)\n",
    "#         clipwise_output = clipwise_output\n",
    "#         print(segmentwise_output_with_max.shape)\n",
    "#         print(clipwise_output.shape)\n",
    "#         print(logit.shape)\n",
    "#         return logit #segmentwise_output_with_max# (segmentwise_output_with_max+logit+clipwise_output)/3\n",
    "#         print(torch.sigmoid(logit).shape)\n",
    "        \n",
    "        \n",
    "#         return output_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c2a92",
   "metadata": {
    "papermill": {
     "duration": 0.012125,
     "end_time": "2024-05-12T08:01:23.083445",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.071320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89772f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.109961Z",
     "iopub.status.busy": "2024-05-12T08:01:23.109631Z",
     "iopub.status.idle": "2024-05-12T08:01:23.118790Z",
     "shell.execute_reply": "2024-05-12T08:01:23.117919Z"
    },
    "papermill": {
     "duration": 0.024788,
     "end_time": "2024-05-12T08:01:23.120764",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.095976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sigmoid_focal_loss(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    alpha: float = 0.25,\n",
    "    gamma: float = 2,\n",
    "    reduction: str = \"none\",\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
    "\n",
    "    Args:\n",
    "        inputs (Tensor): A float tensor of arbitrary shape.\n",
    "                The predictions for each example.\n",
    "        targets (Tensor): A float tensor with the same shape as inputs. Stores the binary\n",
    "                classification label for each element in inputs\n",
    "                (0 for the negative class and 1 for the positive class).\n",
    "        alpha (float): Weighting factor in range (0,1) to balance\n",
    "                positive vs negative examples or -1 for ignore. Default: ``0.25``.\n",
    "        gamma (float): Exponent of the modulating factor (1 - p_t) to\n",
    "                balance easy vs hard examples. Default: ``2``.\n",
    "        reduction (string): ``'none'`` | ``'mean'`` | ``'sum'``\n",
    "                ``'none'``: No reduction will be applied to the output.\n",
    "                ``'mean'``: The output will be averaged.\n",
    "                ``'sum'``: The output will be summed. Default: ``'none'``.\n",
    "    Returns:\n",
    "        Loss tensor with the reduction option applied.\n",
    "    \"\"\"\n",
    "    # Original implementation from https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/focal_loss.py\n",
    "\n",
    "\n",
    "    p = torch.sigmoid(inputs)\n",
    "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "    p_t = p * targets + (1 - p) * (1 - targets)\n",
    "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
    "\n",
    "    if alpha >= 0:\n",
    "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        loss = alpha_t * loss\n",
    "\n",
    "    # Check reduction option and return loss accordingly\n",
    "    if reduction == \"none\":\n",
    "        pass\n",
    "    elif reduction == \"mean\":\n",
    "        loss = loss.mean()\n",
    "    elif reduction == \"sum\":\n",
    "        loss = loss.sum()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid Value for arg 'reduction': '{reduction} \\n Supported reduction modes: 'none', 'mean', 'sum'\"\n",
    "        )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "732bb63f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.645087Z",
     "start_time": "2024-05-02T08:55:35.638517Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.146894Z",
     "iopub.status.busy": "2024-05-12T08:01:23.146585Z",
     "iopub.status.idle": "2024-05-12T08:01:23.154236Z",
     "shell.execute_reply": "2024-05-12T08:01:23.153367Z"
    },
    "papermill": {
     "duration": 0.023005,
     "end_time": "2024-05-12T08:01:23.156211",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.133206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLossBCE(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            alpha: float = 0.25,\n",
    "            gamma: float = 2,\n",
    "            reduction: str = \"mean\",\n",
    "            bce_weight: float = 1.0,\n",
    "            focal_weight: float = 1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.bce = torch.nn.BCEWithLogitsLoss(reduction=reduction)\n",
    "        self.bce_weight = bce_weight\n",
    "        self.focal_weight = focal_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        focall_loss = sigmoid_focal_loss(\n",
    "            inputs=logits,\n",
    "            targets=targets,\n",
    "            alpha=self.alpha,\n",
    "            gamma=self.gamma,\n",
    "            reduction=self.reduction,\n",
    "        )\n",
    "        bce_loss = self.bce(logits, targets.float())\n",
    "        return self.bce_weight * bce_loss + self.focal_weight * focall_loss\n",
    "\n",
    "\n",
    "criterion = FocalLossBCE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9419a907",
   "metadata": {
    "papermill": {
     "duration": 0.012077,
     "end_time": "2024-05-12T08:01:23.180744",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.168667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Init Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "656a0357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.652735Z",
     "start_time": "2024-05-02T08:55:35.645087Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.207008Z",
     "iopub.status.busy": "2024-05-12T08:01:23.206680Z",
     "iopub.status.idle": "2024-05-12T08:01:23.214947Z",
     "shell.execute_reply": "2024-05-12T08:01:23.213991Z"
    },
    "papermill": {
     "duration": 0.023685,
     "end_time": "2024-05-12T08:01:23.216925",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.193240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_logger(log_file='train.log'):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b20f4",
   "metadata": {
    "papermill": {
     "duration": 0.012363,
     "end_time": "2024-05-12T08:01:23.241926",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.229563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train and Val Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa038469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.660572Z",
     "start_time": "2024-05-02T08:55:35.652735Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.270485Z",
     "iopub.status.busy": "2024-05-12T08:01:23.269405Z",
     "iopub.status.idle": "2024-05-12T08:01:23.300105Z",
     "shell.execute_reply": "2024-05-12T08:01:23.299044Z"
    },
    "papermill": {
     "duration": 0.046671,
     "end_time": "2024-05-12T08:01:23.302224",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.255553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    data2 = data[indices]\n",
    "    targets2 = targets[indices]\n",
    "\n",
    "    lam = torch.FloatTensor([np.random.beta(alpha, alpha)])\n",
    "    data = data * lam + data2 * (1 - lam)\n",
    "    targets = targets * lam + targets2 * (1 - lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix(data, targets, alpha):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
    "    data[:, :, bbx1:bbx2, bby1:bby2] = data[indices, :, bbx1:bbx2, bby1:bby2]\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
    "    targets = targets * lam + shuffled_targets * (1 - lam)\n",
    "#     new_targets = [targets, shuffled_targets, lam]\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler=None,epoch=0):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    gt = []\n",
    "    preds = []\n",
    "    bar = tqdm(loader, total=len(loader))\n",
    "    for batch in bar:\n",
    "        optimizer.zero_grad()\n",
    "        spec = batch['spec']\n",
    "        target = batch['target']\n",
    "        \n",
    "#         print(spec.shape)\n",
    "        if epoch<=40:\n",
    "            if np.random.rand() < 0.5:\n",
    "                spec, target = mixup(spec, target, 0.5)\n",
    "            else:\n",
    "                spec, target = cutmix(spec, target, 0.5)\n",
    "\n",
    "        spec = spec.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(spec)\n",
    "                if CNN_:\n",
    "                    loss = criterion(logits, target)\n",
    "                else:\n",
    "                    loss_1 = criterion(logits['logit'], target)\n",
    "                    loss_2 = criterion(logits['framewise_logit'], target)\n",
    "                    loss_3 = criterion(logits['segmentwise_logit'], target)\n",
    "    #                 loss_4 = criterion(logits['clipwise_output'], target)\n",
    "                    loss = (loss_1+loss_2+loss_3)/3\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits = model(spec)\n",
    "            if CNN_:\n",
    "                loss = criterion(logits, target)\n",
    "            else:\n",
    "                loss_1 = criterion(logits['logit'], target)\n",
    "                loss_2 = criterion(logits['framewise_logit'], target)\n",
    "                loss_3 = criterion(logits['segmentwise_logit'], target)\n",
    "                loss = (loss_1+loss_2+loss_3)/3\n",
    "            \n",
    "            loss.backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.update(loss.item(), batch[\"spec\"].size(0))\n",
    "        bar.set_postfix(\n",
    "            loss=losses.avg,\n",
    "            grad=grad_norm.item(),\n",
    "            lr=optimizer.param_groups[0][\"lr\"]\n",
    "        )\n",
    "        gt.append(target.cpu().detach().numpy())\n",
    "        if CNN_:\n",
    "            preds.append(logits.sigmoid().cpu().detach().numpy())\n",
    "        else:\n",
    "            preds.append(((logits['logit']+logits['framewise_logit']+logits['segmentwise_logit'])/3).sigmoid().cpu().detach().numpy())\n",
    "        \n",
    "#         break\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "#     print(gt, preds.shape, target_columns)\n",
    "\n",
    "    gt = np.array(gt, dtype=np.int32)\n",
    "    scores = calculate_competition_metrics(gt, preds, target_columns)\n",
    "\n",
    "    return scores, losses.avg\n",
    "\n",
    "\n",
    "def valid_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    bar = tqdm(loader, total=len(loader))\n",
    "    gt = []\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in bar:\n",
    "            spec = batch['spec'].to(device)\n",
    "            target = batch['target'].to(device)\n",
    "\n",
    "            logits = model(spec)\n",
    "            if CNN_:\n",
    "                loss = criterion(logits, target)\n",
    "            else:\n",
    "                loss_1 = criterion(logits['logit'], target)\n",
    "                loss_2 = criterion(logits['framewise_logit'], target)\n",
    "                loss_3 = criterion(logits['segmentwise_logit'], target)\n",
    "                loss = (loss_1+loss_2+loss_3)/3\n",
    "\n",
    "            losses.update(loss.item(), batch[\"spec\"].size(0))\n",
    "\n",
    "            gt.append(target.cpu().detach().numpy())\n",
    "            if CNN_:\n",
    "                preds.append(logits.sigmoid().cpu().detach().numpy())\n",
    "            else:\n",
    "                preds.append(((logits['logit']+logits['framewise_logit']+logits['segmentwise_logit'])/3).sigmoid().cpu().detach().numpy())\n",
    "        \n",
    "            bar.set_postfix(loss=losses.avg)\n",
    "#             break\n",
    "\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "#     print(gt)\n",
    "#     print(gt, preds.shape, target_columns)\n",
    "    gt = np.array(gt, dtype=np.int32)\n",
    "    scores = calculate_competition_metrics(gt, preds, target_columns)\n",
    "    return scores, losses.avg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f9986",
   "metadata": {
    "papermill": {
     "duration": 0.012291,
     "end_time": "2024-05-12T08:01:23.327540",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.315249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "564ee056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.674443Z",
     "start_time": "2024-05-02T08:55:35.66805Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.356017Z",
     "iopub.status.busy": "2024-05-12T08:01:23.355134Z",
     "iopub.status.idle": "2024-05-12T08:01:23.363402Z",
     "shell.execute_reply": "2024-05-12T08:01:23.362464Z"
    },
    "papermill": {
     "duration": 0.024923,
     "end_time": "2024-05-12T08:01:23.365386",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.340463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix Warmup Bug\n",
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfc8314",
   "metadata": {
    "papermill": {
     "duration": 0.012343,
     "end_time": "2024-05-12T08:01:23.390457",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.378114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transformation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aafb3f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.417300Z",
     "iopub.status.busy": "2024-05-12T08:01:23.416930Z",
     "iopub.status.idle": "2024-05-12T08:01:23.422177Z",
     "shell.execute_reply": "2024-05-12T08:01:23.421262Z"
    },
    "papermill": {
     "duration": 0.020951,
     "end_time": "2024-05-12T08:01:23.424271",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.403320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "mean = (0.485, 0.456, 0.406)  # RGB\n",
    "std = (0.229, 0.224, 0.225)  # RGB\n",
    "\n",
    "transforms_train = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "#     A.Resize(128, 256),\n",
    "    # A.CoarseDropout(max_height=int(128 * 0.375), max_width=int(128 * 0.375), max_holes=1, p=0.7),\n",
    "    A.XYMasking(\n",
    "                p=0.3,\n",
    "                num_masks_x=(1, 3),\n",
    "                num_masks_y=(1, 3),\n",
    "                mask_x_length=(1, 10),\n",
    "                mask_y_length=(1, 20),\n",
    "            ) ,\n",
    "    A.Normalize(mean,std)\n",
    "])\n",
    "\n",
    "transforms_val = A.Compose([\n",
    "#     A.Resize(128, 256),\n",
    "    A.Normalize(mean,std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b1cf27",
   "metadata": {
    "papermill": {
     "duration": 0.01261,
     "end_time": "2024-05-12T08:01:23.451021",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.438411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scheduler Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0582e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.load(\"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/Train mnasnet/outputs/exp1/hc+rgb_2_9699.bin\")[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a78383a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(a,\"rgb9699.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f45799d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.478668Z",
     "iopub.status.busy": "2024-05-12T08:01:23.478342Z",
     "iopub.status.idle": "2024-05-12T08:01:23.484427Z",
     "shell.execute_reply": "2024-05-12T08:01:23.483714Z"
    },
    "papermill": {
     "duration": 0.022396,
     "end_time": "2024-05-12T08:01:23.486367",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.463971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    base_model_name = 'mnasnet_100'\n",
    "    pretrained = False\n",
    "    num_classes = 182\n",
    "    in_channels = 1\n",
    "    n_mels = 128\n",
    "    local_pretrain_path = [\n",
    "#         \"/kaggle/input/mnasnet/fold-0_0.8900275134065998.bin\"\n",
    "        #   \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/pretrain_models/mnasnet_2.bin\"\n",
    "          \"/home/simon/disk1/Simon/Code/kaggle_competion_list/Birdclef/birdclef-2024/Train mnasnet/rgb9682.bin\"\n",
    "        # \"/kaggle/input/spnasnet-128-320/fold-0_0.8834222108826184.bin\",\n",
    "#         \"/kaggle/input/spnasnet-128-320/fold-1_0.8951362703845499.bin\",\n",
    "#         \"/kaggle/input/spnasnet-128-320/fold-2_0.8902828133741624.bin\",\n",
    "#         \"/kaggle/input/spnasnet-128-320/fold-3_0.886560187250359.bin\",\n",
    "    ]\n",
    "    \n",
    "config = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22a6e147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.869499Z",
     "start_time": "2024-05-02T08:55:35.674443Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:23.513349Z",
     "iopub.status.busy": "2024-05-12T08:01:23.512534Z",
     "iopub.status.idle": "2024-05-12T08:01:24.667899Z",
     "shell.execute_reply": "2024-05-12T08:01:24.666953Z"
    },
    "papermill": {
     "duration": 1.171127,
     "end_time": "2024-05-12T08:01:24.669992",
     "exception": false,
     "start_time": "2024-05-12T08:01:23.498865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from local\n",
      "load from local 2\n",
      "323 323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7e6b551b9ff0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = CNN(backbone=backbone, pretrained=False)\n",
    "model = TimmSED(\n",
    "            base_model_name=config.base_model_name,\n",
    "            config=config,\n",
    "            pretrained=config.pretrained,\n",
    "            num_classes=config.num_classes,\n",
    "            in_channels=config.in_channels\n",
    "        )\n",
    "\n",
    "\n",
    "rcParams['figure.figsize'] = 20, 2\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr_max, weight_decay=weight_decay)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, cosine_epo)\n",
    "scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n",
    "\n",
    "lrs = []\n",
    "for epoch in range(1, n_epochs):\n",
    "    scheduler_warmup.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "plt.plot(range(len(lrs)), lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "337f1d8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:55:35.884741Z",
     "start_time": "2024-05-02T08:55:35.869499Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:24.698226Z",
     "iopub.status.busy": "2024-05-12T08:01:24.697871Z",
     "iopub.status.idle": "2024-05-12T08:01:24.716464Z",
     "shell.execute_reply": "2024-05-12T08:01:24.715531Z"
    },
    "papermill": {
     "duration": 0.034844,
     "end_time": "2024-05-12T08:01:24.718420",
     "exception": false,
     "start_time": "2024-05-12T08:01:24.683576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_fold():\n",
    "    logger = init_logger(log_file=os.path.join(output_folder, exp_name, f\"{fold}.log\"))\n",
    "\n",
    "    logger.info(\"=\" * 90)\n",
    "    logger.info(f\"Fold {fold} Training\")\n",
    "    logger.info(\"=\" * 90)\n",
    "\n",
    "    trn_df = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    val_df = df[df['fold'] == fold].reset_index(drop=True)\n",
    "#     print(trn_df.shape)\n",
    "    logger.info(trn_df.shape)\n",
    "    logger.info(trn_df['primary_label'].value_counts())\n",
    "    logger.info(val_df.shape)\n",
    "    logger.info(val_df['primary_label'].value_counts())\n",
    "\n",
    "\n",
    "    # trn_dataset = BirdDataset(df=trn_df.reset_index(drop=True), transform=transforms_train, add_secondary_labels=True, mode='train')\n",
    "    # v_ds = BirdDataset(df=val_df.reset_index(drop=True), transform=transforms_val, add_secondary_labels=True, mode='valid')\n",
    "    trn_dataset = BirdDataset(df=trn_df.reset_index(drop=True), transform=transforms_train, add_secondary_labels=True)\n",
    "    v_ds = BirdDataset(df=val_df.reset_index(drop=True), transform=transforms_val, add_secondary_labels=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(trn_dataset, shuffle=True, batch_size=batch_size, drop_last=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = torch.utils.data.DataLoader(v_ds, shuffle=False, batch_size=batch_size, drop_last=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    if CNN_:\n",
    "        model = CNN(backbone=backbone, pretrained=True).to(device)\n",
    "    else:\n",
    "        model = TimmSED(\n",
    "                base_model_name=config.base_model_name,\n",
    "                config=config,\n",
    "                pretrained=config.pretrained,\n",
    "                num_classes=config.num_classes,\n",
    "                in_channels=config.in_channels\n",
    "            ).to(device)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=lr_max, weight_decay=weight_decay)\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, cosine_epo)\n",
    "    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "    patience = early_stopping\n",
    "    best_score = 0.0\n",
    "    n_patience = 0\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # if epoch==5: break\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "        scheduler_warmup.step(epoch-1)\n",
    "\n",
    "        train_scores, train_losses_avg = train_one_epoch(model, train_loader, optimizer, scaler,epoch)\n",
    "        train_scores_str = metrics_to_string(train_scores, \"Train\")\n",
    "        train_info = f\"Epoch {epoch} - Train loss: {train_losses_avg:.4f}, {train_scores_str}\"\n",
    "        logger.info(train_info)\n",
    "\n",
    "        val_scores, val_losses_avg = valid_one_epoch(model, val_loader)\n",
    "        val_scores_str = metrics_to_string(val_scores, f\"Valid\")\n",
    "        val_info = f\"Epoch {epoch} - Valid loss: {val_losses_avg:.4f}, {val_scores_str}\"\n",
    "        logger.info(val_info)\n",
    "\n",
    "        val_score = val_scores[\"ROC\"]\n",
    "\n",
    "        is_better = val_score > best_score\n",
    "        best_score = max(val_score, best_score)\n",
    "\n",
    "        if is_better:\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"best_loss\": best_score,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "            }\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch} - Save Best Score: {best_score:.4f} Model\\n\")\n",
    "            torch.save(\n",
    "                state,\n",
    "                os.path.join(output_folder, exp_name, f\"{fold}.bin\")\n",
    "            )\n",
    "            n_patience = 0\n",
    "        else:\n",
    "            n_patience += 1\n",
    "            logger.info(\n",
    "                f\"Valid loss didn't improve last {n_patience} epochs.\\n\")\n",
    "\n",
    "        if n_patience >= patience:\n",
    "            logger.info(\n",
    "                \"Early stop, Training End.\\n\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"best_loss\": best_score,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(\n",
    "                state,\n",
    "                os.path.join(output_folder, exp_name, f\"final_{fold}.bin\")\n",
    "            )\n",
    "            break\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2378a61",
   "metadata": {},
   "source": [
    "base  0.9704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d7dde02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T08:01:24.745977Z",
     "iopub.status.busy": "2024-05-12T08:01:24.745674Z",
     "iopub.status.idle": "2024-05-12T09:40:26.108359Z",
     "shell.execute_reply": "2024-05-12T09:40:26.107319Z"
    },
    "papermill": {
     "duration": 5941.378901,
     "end_time": "2024-05-12T09:40:26.110693",
     "exception": false,
     "start_time": "2024-05-12T08:01:24.731792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Fold 2 Training\n",
      "==========================================================================================\n",
      "(19567, 14)\n",
      "primary_label\n",
      "zitcis1    400\n",
      "lirplo     400\n",
      "litgre1    400\n",
      "comgre     400\n",
      "comkin1    400\n",
      "          ... \n",
      "paisto1      5\n",
      "blaeag1      5\n",
      "asiope1      4\n",
      "integr       4\n",
      "niwpig1      4\n",
      "Name: count, Length: 182, dtype: int64\n",
      "(4892, 14)\n",
      "primary_label\n",
      "zitcis1    100\n",
      "lirplo     100\n",
      "comgre     100\n",
      "comkin1    100\n",
      "commoo3    100\n",
      "          ... \n",
      "darter2      1\n",
      "asiope1      1\n",
      "wbbfly1      1\n",
      "integr       1\n",
      "blaeag1      1\n",
      "Name: count, Length: 182, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from local\n",
      "load from local 2\n",
      "323 323\n",
      "Wed May 15 23:06:43 2024 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  7.02it/s, grad=9.94e+3, loss=0.88, lr=1e-5] \n",
      "Epoch 1 - Train loss: 0.8799, Train cmAP_1 : 0.5163, Train cmAP_5 : 0.7286, Train ROC : 0.8287, \n",
      "100%|██████████| 77/77 [00:13<00:00,  5.88it/s, loss=0.193]\n",
      "Epoch 1 - Valid loss: 0.1930, Valid cmAP_1 : 0.5268, Valid cmAP_5 : 0.6873, Valid ROC : 0.9097, \n",
      "Epoch 1 - Save Best Score: 0.9097 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:07:44 2024 Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:42<00:00,  7.19it/s, grad=584, loss=0.0634, lr=2.8e-5]  \n",
      "Epoch 2 - Train loss: 0.0634, Train cmAP_1 : 0.5310, Train cmAP_5 : 0.7404, Train ROC : 0.8425, \n",
      "100%|██████████| 77/77 [00:12<00:00,  6.30it/s, loss=0.0228]\n",
      "Epoch 2 - Valid loss: 0.0228, Valid cmAP_1 : 0.5321, Valid cmAP_5 : 0.6923, Valid ROC : 0.9328, \n",
      "Epoch 2 - Save Best Score: 0.9328 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:08:42 2024 Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:44<00:00,  6.93it/s, grad=423, loss=0.0279, lr=4.6e-5]\n",
      "Epoch 3 - Train loss: 0.0279, Train cmAP_1 : 0.5456, Train cmAP_5 : 0.7408, Train ROC : 0.9514, \n",
      "100%|██████████| 77/77 [00:12<00:00,  6.23it/s, loss=0.0196]\n",
      "Epoch 3 - Valid loss: 0.0196, Valid cmAP_1 : 0.5636, Valid cmAP_5 : 0.7168, Valid ROC : 0.9452, \n",
      "Epoch 3 - Save Best Score: 0.9452 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:09:43 2024 Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:46<00:00,  6.56it/s, grad=414, loss=0.0258, lr=6.4e-5]\n",
      "Epoch 4 - Train loss: 0.0258, Train cmAP_1 : 0.5482, Train cmAP_5 : 0.7578, Train ROC : 0.9589, \n",
      "100%|██████████| 77/77 [00:13<00:00,  5.88it/s, loss=0.0183]\n",
      "Epoch 4 - Valid loss: 0.0183, Valid cmAP_1 : 0.5904, Valid cmAP_5 : 0.7353, Valid ROC : 0.9538, \n",
      "Epoch 4 - Save Best Score: 0.9538 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:10:47 2024 Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:44<00:00,  6.92it/s, grad=399, loss=0.0243, lr=8.2e-5]\n",
      "Epoch 5 - Train loss: 0.0243, Train cmAP_1 : 0.5423, Train cmAP_5 : 0.7508, Train ROC : 0.9684, \n",
      "100%|██████████| 77/77 [00:12<00:00,  5.99it/s, loss=0.0175]\n",
      "Epoch 5 - Valid loss: 0.0175, Valid cmAP_1 : 0.5999, Valid cmAP_5 : 0.7418, Valid ROC : 0.9575, \n",
      "Epoch 5 - Save Best Score: 0.9575 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:11:48 2024 Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  7.09it/s, grad=357, loss=0.0237, lr=0.0001]\n",
      "Epoch 6 - Train loss: 0.0237, Train cmAP_1 : 0.5198, Train cmAP_5 : 0.7321, Train ROC : 0.9587, \n",
      "100%|██████████| 77/77 [00:12<00:00,  6.10it/s, loss=0.0162]\n",
      "Epoch 6 - Valid loss: 0.0162, Valid cmAP_1 : 0.6170, Valid cmAP_5 : 0.7529, Valid ROC : 0.9605, \n",
      "Epoch 6 - Save Best Score: 0.9605 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:12:48 2024 Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  6.99it/s, grad=1.04e+3, loss=0.0228, lr=0.0001]\n",
      "Epoch 7 - Train loss: 0.0228, Train cmAP_1 : 0.5220, Train cmAP_5 : 0.7326, Train ROC : 0.9702, \n",
      "100%|██████████| 77/77 [00:13<00:00,  5.84it/s, loss=0.0159]\n",
      "Epoch 7 - Valid loss: 0.0159, Valid cmAP_1 : 0.6241, Valid cmAP_5 : 0.7574, Valid ROC : 0.9631, \n",
      "Epoch 7 - Save Best Score: 0.9631 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:13:49 2024 Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:45<00:00,  6.70it/s, grad=707, loss=0.0226, lr=9.98e-5]    \n",
      "Epoch 8 - Train loss: 0.0226, Train cmAP_1 : 0.5266, Train cmAP_5 : 0.7350, Train ROC : 0.9670, \n",
      "100%|██████████| 77/77 [00:12<00:00,  5.94it/s, loss=0.0158]\n",
      "Epoch 8 - Valid loss: 0.0158, Valid cmAP_1 : 0.6271, Valid cmAP_5 : 0.7598, Valid ROC : 0.9634, \n",
      "Epoch 8 - Save Best Score: 0.9634 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:14:52 2024 Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  6.99it/s, grad=905, loss=0.0229, lr=9.96e-5]    \n",
      "Epoch 9 - Train loss: 0.0229, Train cmAP_1 : 0.5924, Train cmAP_5 : 0.7823, Train ROC : 0.9729, \n",
      "100%|██████████| 77/77 [00:12<00:00,  6.01it/s, loss=0.0153]\n",
      "Epoch 9 - Valid loss: 0.0153, Valid cmAP_1 : 0.6326, Valid cmAP_5 : 0.7629, Valid ROC : 0.9655, \n",
      "Epoch 9 - Save Best Score: 0.9655 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:15:52 2024 Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:44<00:00,  6.91it/s, grad=726, loss=0.0224, lr=9.93e-5]    \n",
      "Epoch 10 - Train loss: 0.0224, Train cmAP_1 : 0.5760, Train cmAP_5 : 0.7708, Train ROC : 0.9775, \n",
      "100%|██████████| 77/77 [00:12<00:00,  5.98it/s, loss=0.0155]\n",
      "Epoch 10 - Valid loss: 0.0155, Valid cmAP_1 : 0.6312, Valid cmAP_5 : 0.7626, Valid ROC : 0.9650, \n",
      "Valid loss didn't improve last 1 epochs.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:16:53 2024 Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  6.99it/s, grad=678, loss=0.0226, lr=9.89e-5]    \n",
      "Epoch 11 - Train loss: 0.0226, Train cmAP_1 : 0.5743, Train cmAP_5 : 0.7641, Train ROC : 0.9779, \n",
      "100%|██████████| 77/77 [00:12<00:00,  6.08it/s, loss=0.0157]\n",
      "Epoch 11 - Valid loss: 0.0157, Valid cmAP_1 : 0.6320, Valid cmAP_5 : 0.7633, Valid ROC : 0.9649, \n",
      "Valid loss didn't improve last 2 epochs.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:17:53 2024 Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  7.02it/s, grad=679, loss=0.0224, lr=9.84e-5]    \n",
      "Epoch 12 - Train loss: 0.0224, Train cmAP_1 : 0.5963, Train cmAP_5 : 0.7789, Train ROC : 0.9801, \n",
      "100%|██████████| 77/77 [00:12<00:00,  6.01it/s, loss=0.0154]\n",
      "Epoch 12 - Valid loss: 0.0154, Valid cmAP_1 : 0.6380, Valid cmAP_5 : 0.7675, Valid ROC : 0.9661, \n",
      "Epoch 12 - Save Best Score: 0.9661 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:18:54 2024 Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  7.00it/s, grad=636, loss=0.0215, lr=9.79e-5]    \n",
      "Epoch 13 - Train loss: 0.0215, Train cmAP_1 : 0.5380, Train cmAP_5 : 0.7479, Train ROC : 0.9702, \n",
      "100%|██████████| 77/77 [00:13<00:00,  5.74it/s, loss=0.0149]\n",
      "Epoch 13 - Valid loss: 0.0149, Valid cmAP_1 : 0.6449, Valid cmAP_5 : 0.7716, Valid ROC : 0.9674, \n",
      "Epoch 13 - Save Best Score: 0.9674 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:19:55 2024 Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  7.00it/s, grad=1.54e+3, loss=0.0215, lr=9.72e-5]\n",
      "Epoch 14 - Train loss: 0.0215, Train cmAP_1 : 0.5827, Train cmAP_5 : 0.7773, Train ROC : 0.9756, \n",
      "100%|██████████| 77/77 [00:13<00:00,  5.67it/s, loss=0.0149]\n",
      "Epoch 14 - Valid loss: 0.0149, Valid cmAP_1 : 0.6456, Valid cmAP_5 : 0.7724, Valid ROC : 0.9687, \n",
      "Epoch 14 - Save Best Score: 0.9687 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:20:56 2024 Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  7.03it/s, grad=1.27e+3, loss=0.0213, lr=9.65e-5]\n",
      "Epoch 15 - Train loss: 0.0213, Train cmAP_1 : 0.5657, Train cmAP_5 : 0.7677, Train ROC : 0.9723, \n",
      "100%|██████████| 77/77 [00:12<00:00,  6.20it/s, loss=0.0151]\n",
      "Epoch 15 - Valid loss: 0.0151, Valid cmAP_1 : 0.6435, Valid cmAP_5 : 0.7702, Valid ROC : 0.9678, \n",
      "Valid loss didn't improve last 1 epochs.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:21:56 2024 Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:47<00:00,  6.46it/s, grad=1.14e+3, loss=0.0214, lr=9.57e-5]\n",
      "Epoch 16 - Train loss: 0.0214, Train cmAP_1 : 0.5512, Train cmAP_5 : 0.7558, Train ROC : 0.9792, \n",
      "100%|██████████| 77/77 [00:12<00:00,  6.11it/s, loss=0.0149]\n",
      "Epoch 16 - Valid loss: 0.0149, Valid cmAP_1 : 0.6476, Valid cmAP_5 : 0.7737, Valid ROC : 0.9687, \n",
      "Valid loss didn't improve last 2 epochs.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:23:00 2024 Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:44<00:00,  6.80it/s, grad=1.89e+3, loss=0.0205, lr=9.48e-5]\n",
      "Epoch 17 - Train loss: 0.0205, Train cmAP_1 : 0.5471, Train cmAP_5 : 0.7516, Train ROC : 0.9747, \n",
      "100%|██████████| 77/77 [00:12<00:00,  6.00it/s, loss=0.0148]\n",
      "Epoch 17 - Valid loss: 0.0148, Valid cmAP_1 : 0.6483, Valid cmAP_5 : 0.7738, Valid ROC : 0.9686, \n",
      "Valid loss didn't improve last 3 epochs.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:24:02 2024 Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:43<00:00,  6.98it/s, grad=1.19e+3, loss=0.0213, lr=9.38e-5]\n",
      "Epoch 18 - Train loss: 0.0213, Train cmAP_1 : 0.5617, Train cmAP_5 : 0.7604, Train ROC : 0.9754, \n",
      "100%|██████████| 77/77 [00:13<00:00,  5.82it/s, loss=0.0148]\n",
      "Epoch 18 - Valid loss: 0.0148, Valid cmAP_1 : 0.6512, Valid cmAP_5 : 0.7757, Valid ROC : 0.9685, \n",
      "Valid loss didn't improve last 4 epochs.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:25:03 2024 Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:44<00:00,  6.79it/s, grad=1.05e+3, loss=0.0206, lr=9.28e-5]\n",
      "Epoch 19 - Train loss: 0.0206, Train cmAP_1 : 0.5160, Train cmAP_5 : 0.7307, Train ROC : 0.9847, \n",
      "100%|██████████| 77/77 [00:12<00:00,  5.98it/s, loss=0.015] \n",
      "Epoch 19 - Valid loss: 0.0150, Valid cmAP_1 : 0.6510, Valid cmAP_5 : 0.7753, Valid ROC : 0.9682, \n",
      "Valid loss didn't improve last 5 epochs.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:26:05 2024 Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:45<00:00,  6.76it/s, grad=3.31e+3, loss=0.0204, lr=9.16e-5]\n",
      "Epoch 20 - Train loss: 0.0204, Train cmAP_1 : 0.5729, Train cmAP_5 : 0.7677, Train ROC : 0.9806, \n",
      "100%|██████████| 77/77 [00:13<00:00,  5.88it/s, loss=0.0144]\n",
      "Epoch 20 - Valid loss: 0.0144, Valid cmAP_1 : 0.6574, Valid cmAP_5 : 0.7795, Valid ROC : 0.9692, \n",
      "Epoch 20 - Save Best Score: 0.9692 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:27:07 2024 Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:44<00:00,  6.85it/s, grad=4.07e+3, loss=0.0112, lr=9.05e-5]\n",
      "Epoch 21 - Train loss: 0.0112, Train cmAP_1 : 0.6973, Train cmAP_5 : 0.7563, Train ROC : 0.9890, \n",
      "100%|██████████| 77/77 [00:13<00:00,  5.72it/s, loss=0.0142]\n",
      "Epoch 21 - Valid loss: 0.0142, Valid cmAP_1 : 0.6627, Valid cmAP_5 : 0.7826, Valid ROC : 0.9701, \n",
      "Epoch 21 - Save Best Score: 0.9701 Model\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 23:28:09 2024 Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 211/305 [00:32<00:09,  9.79it/s, grad=3.85e+3, loss=0.011, lr=8.92e-5] "
     ]
    }
   ],
   "source": [
    "train_fold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1239a098",
   "metadata": {
    "papermill": {
     "duration": 0.256068,
     "end_time": "2024-05-12T09:40:26.630956",
     "exception": false,
     "start_time": "2024-05-12T09:40:26.374888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchlibrosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c86a6b",
   "metadata": {
    "papermill": {
     "duration": 0.280707,
     "end_time": "2024-05-12T09:40:27.168404",
     "exception": false,
     "start_time": "2024-05-12T09:40:26.887697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torchlibrosa.SpecAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66832171",
   "metadata": {
    "papermill": {
     "duration": 0.258824,
     "end_time": "2024-05-12T09:40:27.688057",
     "exception": false,
     "start_time": "2024-05-12T09:40:27.429233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8068726,
     "sourceId": 70203,
     "sourceType": "competition"
    },
    {
     "datasetId": 3174266,
     "sourceId": 5502329,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3202296,
     "sourceId": 5560891,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3373324,
     "sourceId": 5866811,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6003.429359,
   "end_time": "2024-05-12T09:40:31.495258",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-12T08:00:28.065899",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
